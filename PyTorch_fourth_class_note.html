
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>第二章 神经网络 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    
    <link rel="prev" href="pytorch_first_second_and_third_class_notes.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="pytorch_first_second_and_third_class_notes.html">
            
                <a href="pytorch_first_second_and_third_class_notes.html">
            
                    
                    第一章 深度学习
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3" data-path="PyTorch_fourth_class_note.html">
            
                <a href="PyTorch_fourth_class_note.html">
            
                    
                    第二章 神经网络
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >第二章 神经网络</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="&#x7B2C;&#x4E8C;&#x7AE0;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;">&#x7B2C;&#x4E8C;&#x7AE0;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</h1>
<ul>
<li>&#x4ECB;&#x7ECD;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x3001;&#x975E;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x548C;&#x5F3A;&#x5316;&#x5B66;&#x4E60;</li>
<li>&#x638C;&#x63E1;&#x7EBF;&#x6027;&#x6A21;&#x578B;&#x548C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;</li>
<li>&#x638C;&#x63E1;logistic&#x56DE;&#x5F52;</li>
<li>&#x638C;&#x63E1;&#x591A;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x6DF1;&#x5EA6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</li>
<li>&#x7406;&#x89E3;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;</li>
<li>&#x7406;&#x89E3;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x7684;&#x539F;&#x7406;</li>
</ul>
<h2 id="&#x4ECB;&#x7ECD;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x3001;&#x975E;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x548C;&#x5F3A;&#x5316;&#x5B66;&#x4E60;">&#x4ECB;&#x7ECD;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x3001;&#x975E;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x548C;&#x5F3A;&#x5316;&#x5B66;&#x4E60;</h2>
<ul>
<li>&#x76D1;&#x7763;&#x5B66;&#x4E60;&#xFF1A;&#x5BF9;&#x5DF2;&#x6709;&#x6807;&#x8BB0;&#x7684;&#x8BAD;&#x7EC3;&#x6837;&#x672C;&#x8FDB;&#x884C;&#x5B66;&#x4E60;&#xFF0C;&#x7136;&#x540E;&#x5BF9;&#x6837;&#x672C;&#x5916;&#x7684;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x6807;&#x8BB0;&#x9884;&#x6D4B;</li>
<li>&#x975E;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#xFF1A;&#x5BF9;&#x6CA1;&#x6709;&#x6807;&#x8BB0;&#x7684;&#x8BAD;&#x7EC3;&#x6837;&#x672C;&#x8FDB;&#x884C;&#x5B66;&#x4E60;&#xFF0C;&#x53D1;&#x73B0;&#x5176;&#x4E2D;&#x7684;&#x7ED3;&#x6784;&#x6027;&#x77E5;&#x8BC6;</li>
<li>&#x5F3A;&#x5316;&#x5B66;&#x4E60;&#xFF1A;&#x53EF;&#x4EE5;&#x7406;&#x89E3;&#x6210;&#x4E3A;&#x4E00;&#x4E2A;&#x673A;&#x5668;&#x4EBA;&#x4E0D;&#x65AD;&#x4F9D;&#x636E;&#x73AF;&#x5883;&#x505A;&#x51B3;&#x7B56;&#xFF0C;&#x7136;&#x540E;&#x73AF;&#x5883;&#x6839;&#x636E;&#x51B3;&#x7B56;&#x8FDB;&#x884C;&#x5956;&#x52B1;&#x6216;&#x8005;&#x60E9;&#x7F5A;&#xFF0C;&#x673A;&#x5668;&#x4EBA;&#x5C31;&#x6839;&#x636E;&#x73AF;&#x5883;&#x7ED9;&#x4E88;&#x7684;&#x53CD;&#x9988;&#x6765;&#x5B66;&#x4E60;&#x7684;&#x65B9;&#x5F0F;&#x3002;</li>
</ul>
<h2 id="&#x7EBF;&#x6027;&#x6A21;&#x578B;&#x548C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;">&#x7EBF;&#x6027;&#x6A21;&#x578B;&#x548C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;</h2>
<ul>
<li>&#x7EBF;&#x6027;&#x6A21;&#x578B;&#xFF1A;
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mrow><mi>h</mi><mi>a</mi><mi>t</mi></mrow><mo>=</mo><mi>w</mi><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y_i{hat} = wx_i + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord textstyle uncramped"><span class="mord mathit">h</span><span class="mord mathit">a</span><span class="mord mathit">t</span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">+</span><span class="mord mathit">b</span></span></span></span></li>
<li>&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#xFF1A;
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>=</mo><mi>w</mi><mo>&#x2212;</mo><mi>&#x3B1;</mi><mo>&#x2217;</mo><mfrac><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup><mi>w</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">w = w - \alpha*\frac{\partial^{}loss}{\partial^{}w}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8801079999999999em;"></span><span class="strut bottom" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">&#x2212;</span><span class="mord mathit" style="margin-right:0.0037em;">&#x3B1;</span><span class="mbin">&#x2217;</span><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.286em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord scriptscriptstyle cramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit mtight" style="margin-right:0.02691em;">w</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.431em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle uncramped mtight"><span class="mord scriptscriptstyle uncramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit mtight" style="margin-right:0.01968em;">l</span><span class="mord mathit mtight">o</span><span class="mord mathit mtight">s</span><span class="mord mathit mtight">s</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span><ul>
<li>$\alpha$&#x662F;&#x5B66;&#x4E60;&#x7387;</li>
<li>&#x5B66;&#x4E60;&#x7387;&#x592A;&#x5C0F;&#x4F1A;&#x5BFC;&#x81F4;&#x4E0B;&#x964D;&#x975E;&#x5E38;&#x7F13;&#x6162;&#xFF0C;&#x5B66;&#x4E60;&#x7387;&#x592A;&#x5927;&#x4F1A;&#x5BFC;&#x81F4;&#x8DF3;&#x52A8;&#x975E;&#x5E38;&#x660E;&#x663E;</li>
</ul>
</li>
</ul>
<p>&#x6240;&#x4EE5;&#x5BF9;&#x4E8E;&#xFF08;1&#xFF09;&#x5F0F;&#x771F;&#x6B63;&#x7684;&#x66F4;&#x65B0;&#x516C;&#x5F0F;&#x662F;&#xFF1A;</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>=</mo><mi>w</mi><mo>&#x2212;</mo><mi>&#x3B1;</mi><mo>&#x2217;</mo><mfrac><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup><mi>f</mi><mo>(</mo><mi>w</mi><mo separator="true">,</mo><mi>b</mi><mo>)</mo></mrow><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup><mi>w</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">w = w - \alpha*\frac{\partial^{}f(w, b)}{\partial^{}w}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.01em;"></span><span class="strut bottom" style="height:1.355em;vertical-align:-0.345em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">&#x2212;</span><span class="mord mathit" style="margin-right:0.0037em;">&#x3B1;</span><span class="mbin">&#x2217;</span><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.286em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord scriptscriptstyle cramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit mtight" style="margin-right:0.02691em;">w</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.485em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.431em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle uncramped mtight"><span class="mord scriptscriptstyle uncramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathit mtight" style="margin-right:0.02691em;">w</span><span class="mpunct mtight">,</span><span class="mord mathit mtight">b</span><span class="mclose mtight">)</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi><mo>=</mo><mi>b</mi><mo>&#x2212;</mo><mi>&#x3B1;</mi><mo>&#x2217;</mo><mfrac><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup><mi>f</mi><mo>(</mo><mi>w</mi><mo separator="true">,</mo><mi>b</mi><mo>)</mo></mrow><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup><mi>b</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">b = b - \alpha*\frac{\partial^{}f(w, b)}{\partial^{}b}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.01em;"></span><span class="strut bottom" style="height:1.355em;vertical-align:-0.345em;"></span><span class="base textstyle uncramped"><span class="mord mathit">b</span><span class="mrel">=</span><span class="mord mathit">b</span><span class="mbin">&#x2212;</span><span class="mord mathit" style="margin-right:0.0037em;">&#x3B1;</span><span class="mbin">&#x2217;</span><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.286em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord scriptscriptstyle cramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit mtight">b</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.485em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.431em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle uncramped mtight"><span class="mord scriptscriptstyle uncramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit mtight" style="margin-right:0.10764em;">f</span><span class="mopen mtight">(</span><span class="mord mathit mtight" style="margin-right:0.02691em;">w</span><span class="mpunct mtight">,</span><span class="mord mathit mtight">b</span><span class="mclose mtight">)</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span></li>
</ul>
<h3 id="&#x4F7F;&#x7528;pytorch&#x5B9E;&#x73B0;&#x7EBF;&#x6027;&#x6A21;&#x578B;&#x548C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;">&#x4F7F;&#x7528;PyTorch&#x5B9E;&#x73B0;&#x7EBF;&#x6027;&#x6A21;&#x578B;&#x548C;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;</h3>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable

torch.manual_seed(<span class="hljs-number">2017</span>) <span class="hljs-comment"># &#x8BBE;&#x5B9A;&#x968F;&#x673A;&#xFF0C;&#x5229;&#x4E8E;&#x7ED3;&#x679C;&#x518D;&#x73B0;</span>
</code></pre>
<pre><code>&lt;torch._C.Generator at 0x7fbb0e340170&gt;
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x8BFB;&#x5165;&#x6570;&#x636E;x &#x548C; y</span>
x_train = np.array([[<span class="hljs-number">3.3</span>], [<span class="hljs-number">4.4</span>], [<span class="hljs-number">5.5</span>], [<span class="hljs-number">6.71</span>], [<span class="hljs-number">6.93</span>], [<span class="hljs-number">4.168</span>], [<span class="hljs-number">9.779</span>], 
                   [<span class="hljs-number">6.182</span>], [<span class="hljs-number">7.59</span>], [<span class="hljs-number">2.168</span>], [<span class="hljs-number">7.042</span>], [<span class="hljs-number">10.791</span>], [<span class="hljs-number">5.313</span>], 
                   [<span class="hljs-number">7.997</span>], [<span class="hljs-number">3.1</span>]], dtype=np.float32)
y_train = np.array([[<span class="hljs-number">1.7</span>], [<span class="hljs-number">2.76</span>], [<span class="hljs-number">2.09</span>], [<span class="hljs-number">3.19</span>], [<span class="hljs-number">1.694</span>], [<span class="hljs-number">1.573</span>], [<span class="hljs-number">3.366</span>],
                   [<span class="hljs-number">2.596</span>], [<span class="hljs-number">2.53</span>], [<span class="hljs-number">1.221</span>], [<span class="hljs-number">2.827</span>], [<span class="hljs-number">3.465</span>], [<span class="hljs-number">1.65</span>],
                   [<span class="hljs-number">2.904</span>], [<span class="hljs-number">1.3</span>]], dtype=np.float32)
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x753B;&#x51FA;&#x56FE;&#x50CF;</span>
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline

plt.plot(x_train, y_train, <span class="hljs-string">&apos;bo&apos;</span>)
</code></pre>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fbb049604a8&gt;]
</code></pre><p><img src="output_6_1.png" alt="png"></p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5C06;&#x6570;&#x636E;&#x8F6C;&#x5316;&#x6210;Tensor</span>
x_train = torch.Tensor(x_train)
y_train = torch.Tensor(y_train)

<span class="hljs-comment"># &#x5B9A;&#x4E49;&#x53C2;&#x6570;W &#x548C; b</span>
w = Variable(torch.randn(<span class="hljs-number">1</span>), requires_grad=<span class="hljs-keyword">True</span>) <span class="hljs-comment"># &#x968F;&#x5373;&#x521D;&#x59CB;&#x5316;</span>
b = Variable(torch.zeros(<span class="hljs-number">1</span>), requires_grad=<span class="hljs-keyword">True</span>) <span class="hljs-comment"># &#x4F7F;&#x7528;0&#x521D;&#x59CB;&#x5316;</span>
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x6784;&#x5EFA;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x6A21;&#x578B;</span>
x_train = Variable(x_train)
y_train = Variable(y_train)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">linear_model</span><span class="hljs-params">(x)</span>:</span>
  <span class="hljs-keyword">return</span> x * w + b
</code></pre>
<pre><code class="lang-python">y = linear_model(x_train)
</code></pre>
<p>&#x7ECF;&#x8FC7;&#x4E0A;&#x9762;&#x7684;&#x6B65;&#x9AA4;&#x5C31;&#x5B9A;&#x4E49;&#x597D;&#x4E86;&#x7EBF;&#x6027;&#x6A21;&#x578B;&#xFF0C;&#x5728;&#x8FDB;&#x884C;&#x53C2;&#x6570;&#x66F4;&#x65B0;&#x4E4B;&#x524D;&#xFF0C;&#x53EF;&#x4EE5;&#x5148;&#x770B;&#x770B;&#x6A21;&#x578B;&#x7684;&#x8F93;&#x51FA;&#x7ED3;&#x679C;</p>
<pre><code class="lang-python">plt.plot(x_train.data.numpy(), y_train.data.numpy(), <span class="hljs-string">&apos;bo&apos;</span>, label=<span class="hljs-string">&apos;real&apos;</span>)
plt.plot(x_train.data.numpy(), y.data.numpy(), <span class="hljs-string">&apos;ro&apos;</span>, label=<span class="hljs-string">&apos;estimated&apos;</span>)
plt.legend()
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fbb04937f60&gt;
</code></pre><p><img src="output_11_1.png" alt="png"></p>
<p>&#x8FD9;&#x4E2A;&#x65F6;&#x5019;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x8BA1;&#x7B97;&#x8BEF;&#x5DEE;&#xFF1A;
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>n</mi></mrow></mfrac><msubsup><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo>(</mo><msub><mover accent="true"><mrow><mi>y</mi></mrow><mo>^</mo></mover><mi>i</mi></msub><mo>&#x2212;</mo><msub><mi>y</mi><mi>i</mi></msub><msup><mo>)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{1}{n}\sum_{i=1}^n(\hat{y}_i - y_i)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.845108em;"></span><span class="strut bottom" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="base textstyle uncramped"><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">n</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mop"><span class="mop op-symbol small-op" style="top:-0.0000050000000000050004em;">&#x2211;</span><span class="msupsub"><span class="vlist"><span style="top:0.30001em;margin-left:0em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">i</span><span class="mrel mtight">=</span><span class="mord mathrm mtight">1</span></span></span></span><span style="top:-0.364em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathit mtight">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="mord textstyle cramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span><span style="top:0em;margin-left:0.11112em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="accent-body"><span>^</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">&#x2212;</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span></p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BA1;&#x7B97;&#x8BEF;&#x5DEE;</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_loss</span><span class="hljs-params">(y_, y)</span>:</span>
  <span class="hljs-keyword">return</span> torch.mean((y_- y_train) **<span class="hljs-number">2</span>)

loss = get_loss(y, y_train)

print(loss)
</code></pre>
<pre><code>tensor(153.3531, grad_fn=&lt;MeanBackward0&gt;)
</code></pre><p>&#x5B9A;&#x4E49;&#x597D;&#x4E86;&#x8BEF;&#x5DEE;&#x51FD;&#x6570;&#xFF0C;&#x63A5;&#x4E0B;&#x6765;&#x5C31;&#x662F;&#x8BA1;&#x7B97;w&#x548C;b&#x7684;&#x68AF;&#x5EA6;&#xFF0C;&#x8FD9;&#x65F6;&#x5F97;&#x76CA;&#x4E8E;Pyorch&#x7684;&#x81EA;&#x52A8;&#x6C42;&#x5BFC;</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup></mrow><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup><mi>w</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn></mrow><mrow><mi>n</mi></mrow></mfrac><msubsup><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo>(</mo><mi>w</mi><mo>&#x2217;</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo>&#x2212;</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial^{}}{\partial^{}w} = \frac{2}{n}\sum_{i=1}^n(w*x_i + b -y_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8801079999999999em;"></span><span class="strut bottom" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="base textstyle uncramped"><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.286em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord scriptscriptstyle cramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit mtight" style="margin-right:0.02691em;">w</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.431em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle uncramped mtight"><span class="mord scriptscriptstyle uncramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">n</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathrm mtight">2</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mop"><span class="mop op-symbol small-op" style="top:-0.0000050000000000050004em;">&#x2211;</span><span class="msupsub"><span class="vlist"><span style="top:0.30001em;margin-left:0em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">i</span><span class="mrel mtight">=</span><span class="mord mathrm mtight">1</span></span></span></span><span style="top:-0.364em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathit mtight">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">&#x2217;</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">+</span><span class="mord mathit">b</span><span class="mbin">&#x2212;</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span></span></span></span>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup></mrow><mrow><msup><mi mathvariant="normal">&#x2202;</mi><mrow></mrow></msup><mi>b</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn></mrow><mrow><mi>n</mi></mrow></mfrac><msubsup><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo>(</mo><mi>w</mi><mo>&#x2217;</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo>&#x2212;</mo><msub><mi>y</mi><mi>i</mi></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial^{}}{\partial^{}b} = \frac{2}{n}\sum_{i=1}^n(w*x_i + b -y_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8801079999999999em;"></span><span class="strut bottom" style="height:1.2251079999999999em;vertical-align:-0.345em;"></span><span class="base textstyle uncramped"><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.286em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord scriptscriptstyle cramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit mtight">b</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right:0.05556em;">&#x2202;</span><span class="msupsub"><span class="vlist"><span style="top:-0.431em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle uncramped mtight"><span class="mord scriptscriptstyle uncramped mtight"></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mrel">=</span><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">n</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathrm mtight">2</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mop"><span class="mop op-symbol small-op" style="top:-0.0000050000000000050004em;">&#x2211;</span><span class="msupsub"><span class="vlist"><span style="top:0.30001em;margin-left:0em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">i</span><span class="mrel mtight">=</span><span class="mord mathrm mtight">1</span></span></span></span><span style="top:-0.364em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathit mtight">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">&#x2217;</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">+</span><span class="mord mathit">b</span><span class="mbin">&#x2212;</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span></span></span></span></p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x81EA;&#x52A8;&#x6C42;&#x5BFC;</span>
loss.backward()
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x67E5;&#x770B;w &#x548C; b &#x7684;&#x68AF;&#x5EA6;</span>
print(w.grad)
print(b.grad)
</code></pre>
<pre><code>tensor([161.0054])
tensor([22.8733])
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x66F4;&#x65B0;&#x4E00;&#x904D;&#x53C2;&#x6570;</span>
w.data = w.data - <span class="hljs-number">1e-2</span> * w.grad.data
b.data = b.data - <span class="hljs-number">1e-2</span> * b.grad.data
</code></pre>
<p>&#x66F4;&#x65B0;&#x5B8C;&#x6210;&#x540E;&#xFF0C;&#x518D;&#x6B21;&#x67E5;&#x770B;&#x6A21;&#x578B;&#x8F93;&#x51FA;&#x7ED3;&#x679C;</p>
<pre><code class="lang-python">y = linear_model(x_train)
plt.plot(x_train.data.numpy(), y_train.data.numpy(), <span class="hljs-string">&apos;bo&apos;</span>, label=<span class="hljs-string">&apos;real&apos;</span>)
plt.plot(x_train.data.numpy(), y.data.numpy(), <span class="hljs-string">&apos;ro&apos;</span>, label=<span class="hljs-string">&apos;estimated&apos;</span>)
plt.legend()
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fbb048a2be0&gt;
</code></pre><p><img src="output_19_1.png" alt="png"></p>
<p>&#x4ECE;&#x4E0A;&#x9762;&#x7684;&#x4F8B;&#x5B50;&#x53EF;&#x4EE5;&#x770B;&#x51FA;&#xFF0C;&#x66F4;&#x65B0;&#x4E4B;&#x540E;&#x7EA2;&#x8272;&#x7684;&#x70B9;&#x4E0E;&#x84DD;&#x8272;&#x7684;&#x70B9;&#x63A5;&#x8FD1;&#x4E86;&#x4E00;&#x70B9;&#xFF0C;&#x7136;&#x800C;&#x8FD8;&#x662F;&#x6CA1;&#x6709;&#x62DF;&#x5408;&#x84DD;&#x8272;&#x70B9;&#x7684;&#x771F;&#x5B9E;&#x503C;&#xFF0C;&#x6240;&#x4EE5;&#x8981;&#x7ECF;&#x8FC7;&#x591A;&#x6B21;&#x8BAD;&#x7EC3;</p>
<pre><code class="lang-python"><span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>):
  y = linear_model(x_train)
  loss = get_loss(y, y_train)

  w.grad.zero_() <span class="hljs-comment"># &#x68AF;&#x5EA6;&#x5F52;&#x96F6;&#xFF0C;&#x9632;&#x6B62;&#x53E0;&#x52A0;</span>
  b.grad.zero_()

  loss.backward()

  w.data = w.data - <span class="hljs-number">1e-2</span> * w.grad.data
  b.data = b.data - <span class="hljs-number">1e-2</span> * b.grad.data
  print(<span class="hljs-string">&apos;ecpoch:{}, loss:{}&apos;</span>.format(e, loss.item()))
</code></pre>
<pre><code>ecpoch:0, loss:3.1355104446411133
ecpoch:1, loss:0.3550477921962738
ecpoch:2, loss:0.30292215943336487
ecpoch:3, loss:0.3012879490852356
ecpoch:4, loss:0.30059143900871277
ecpoch:5, loss:0.29991573095321655
ecpoch:6, loss:0.2992437779903412
ecpoch:7, loss:0.29857534170150757
ecpoch:8, loss:0.29791030287742615
ecpoch:9, loss:0.2972486615180969
</code></pre><pre><code class="lang-python">y = linear_model(x_train)
plt.plot(x_train.data.numpy(), y_train.data.numpy(), <span class="hljs-string">&apos;bo&apos;</span>, label=<span class="hljs-string">&apos;real&apos;</span>)
plt.plot(x_train.data.numpy(), y.data.numpy(), <span class="hljs-string">&apos;ro&apos;</span>, label=<span class="hljs-string">&apos;estimated&apos;</span>)
plt.legend()
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fbb04896208&gt;
</code></pre><p><img src="output_22_1.png" alt="png"></p>
<p>&#x7ECF;&#x8FC7;10&#x6B21;&#x7684;&#x8BAD;&#x7EC3;&#xFF0C;&#x53D1;&#x73B0;&#x7EA2;&#x8272;&#x7684;&#x9884;&#x6D4B;&#x7ED3;&#x679C;&#x5DF2;&#x7ECF;&#x6BD4;&#x8F83;&#x53F7;&#x7684;&#x62DF;&#x5408;&#x4E86;&#x84DD;&#x8272;&#x7684;&#x771F;&#x5B9E;&#x503C;&#x3002;</p>
<h2 id="&#x591A;&#x9879;&#x5F0F;&#x56DE;&#x5F52;&#x6A21;&#x578B;">&#x591A;&#x9879;&#x5F0F;&#x56DE;&#x5F52;&#x6A21;&#x578B;</h2>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-comment"># &#x5B9A;&#x4E49;&#x4E00;&#x4E2A;&#x591A;&#x53D8;&#x91CF;&#x51FD;&#x6570;</span>
w_target = np.array([<span class="hljs-number">0.5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2.4</span>]) <span class="hljs-comment"># &#x5B9A;&#x4E49;&#x53C2;&#x6570;</span>
b_target = np.array([<span class="hljs-number">0.9</span>]) <span class="hljs-comment"># &#x5B9A;&#x4E49;&#x53C2;&#x6570;</span>

f_des = <span class="hljs-string">&apos;y = {:.2f} + {:.2f} * x + {:.2f} * x^2 {:.2f} * x^3&apos;</span>.format(
    b_target[<span class="hljs-number">0</span>], w_target[<span class="hljs-number">0</span>], w_target[<span class="hljs-number">1</span>], w_target[<span class="hljs-number">2</span>]) <span class="hljs-comment"># &#x6253;&#x5370;&#x51FD;&#x6570;&#x7684;&#x5F0F;&#x5B50;</span>

print(f_des)
</code></pre>
<pre><code>y = 0.90 + 0.50 * x + 3.00 * x^2 2.40 * x^3
</code></pre><p>&#x53EF;&#x4EE5;&#x5148;&#x770B;&#x4E00;&#x4E0B;&#x51FD;&#x6570;&#x7684;&#x66F2;&#x7EBF;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x753B;&#x51FA;&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x7684;&#x66F2;&#x7EBF;</span>
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt


x_sample = np.arange(<span class="hljs-number">-3</span>, <span class="hljs-number">3.1</span>, <span class="hljs-number">0.1</span>)
y_sample = b_target[<span class="hljs-number">0</span>] + w_target[<span class="hljs-number">0</span>] * x_sample + w_target[<span class="hljs-number">1</span>] * x_sample ** <span class="hljs-number">2</span> + w_target[<span class="hljs-number">2</span>] * x_sample ** <span class="hljs-number">3</span>

plt.plot(x_sample, y_sample, label=<span class="hljs-string">&apos;real curve&apos;</span>)
plt.legend()
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fbb04855160&gt;
</code></pre><p><img src="output_27_1.png" alt="png"></p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x6784;&#x5EFA;&#x6570;&#x636E;x&#x548C;y</span>
<span class="hljs-comment"># x&#x662F;&#x4E00;&#x4E2A;&#x5982;&#x4E0B;&#x77E9;&#x9635;[x, x^2, x^3]</span>
<span class="hljs-comment"># y&#x662F;&#x51FD;&#x6570;&#x7684;&#x7ED3;&#x679C;[y]</span>
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
<span class="hljs-keyword">import</span> torch

x_train = np.stack([x_sample ** i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>)], axis=<span class="hljs-number">1</span>)
x_train = torch.from_numpy(x_train).float() <span class="hljs-comment"># &#x8F6C;&#x6362;&#x6210; float tensor</span>
<span class="hljs-comment"># print(x_train)</span>

y_train = torch.from_numpy(y_sample).float().unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># &#x8F6C;&#x6362;&#x6210; float tensor</span>
<span class="hljs-comment"># print(y_train)</span>
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5B9A;&#x4E49;&#x53C2;&#x6570;&#x548C;&#x6A21;&#x578B;</span>
w = Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>), requires_grad=<span class="hljs-keyword">True</span>)
b = Variable(torch.zeros(<span class="hljs-number">1</span>), requires_grad=<span class="hljs-keyword">True</span>)

<span class="hljs-comment"># &#x5C06; x &#x548C; y &#x8F6C;&#x6362;&#x6210;Variable</span>
x_train = Variable(x_train)
y_train = Variable(y_train)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">multi_linear</span><span class="hljs-params">(x)</span>:</span>
  <span class="hljs-keyword">return</span> torch.mm(x, w) + b
</code></pre>
<p>&#x53EF;&#x4EE5;&#x753B;&#x51FA;&#x66F4;&#x65B0;&#x4E4B;&#x524D;&#x7684;&#x6A21;&#x578B;&#x548C;&#x771F;&#x5B9E;&#x6A21;&#x578B;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x6BD4;</p>
<pre><code class="lang-python">y_pred = multi_linear(x_train)

plt.plot(x_train.data.numpy()[:, <span class="hljs-number">0</span>], y_pred.data.numpy(), label=<span class="hljs-string">&apos;fitting curve&apos;</span>, color=<span class="hljs-string">&apos;r&apos;</span>)
plt.plot(x_train.data.numpy()[:, <span class="hljs-number">0</span>], y_sample, label=<span class="hljs-string">&apos;real curve&apos;</span>, color=<span class="hljs-string">&apos;b&apos;</span>)
</code></pre>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fbb047c4898&gt;]
</code></pre><p><img src="output_31_1.png" alt="png"></p>
<p>&#x53EF;&#x4EE5;&#x53D1;&#x73B0;&#xFF0C;&#x8FD9;&#x4E24;&#x6761;&#x66F2;&#x7EBF;&#x4E4B;&#x95F4;&#x5B58;&#x5728;&#x7740;&#x6BD4;&#x8F83;&#x5927;&#x7684;&#x5DEE;&#x5F02;&#xFF0C;&#x63A5;&#x4E0B;&#x6765;&#x89E3;&#x91CA;&#x8BA1;&#x7B97;&#x4ED6;&#x4EEC;&#x4E4B;&#x95F4;&#x7684;&#x8BEF;&#x5DEE;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BA1;&#x7B97;&#x8BEF;&#x5DEE;&#x548C;&#x4E4B;&#x524D;&#x533B;&#x9662;&#x7EBF;&#x6027;&#x6A21;&#x578B;&#x7684;&#x8BEF;&#x5DEE;&#x76F8;&#x540C;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4E4B;&#x524D;&#x5B9A;&#x4E49;&#x7684;get_loss</span>
loss = get_loss(y_pred, y_train)
print(loss)
</code></pre>
<pre><code>tensor(413.9844, grad_fn=&lt;MeanBackward0&gt;)
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x81EA;&#x52A8;&#x6C42;&#x5BFC;</span>
loss.backward()
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x67E5;&#x770B;&#x4E00;&#x4E0B; w &#x548C; b &#x7684;&#x68AF;&#x5EA6;</span>
print(w.grad)
print(b.grad)
</code></pre>
<pre><code>tensor([[ -34.1391],
        [-146.6133],
        [-215.9149]])
tensor([-27.0838])
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x66F4;&#x65B0;&#x53C2;&#x6570;</span>
lr = <span class="hljs-number">0.001</span> <span class="hljs-comment"># &#x5B9A;&#x4E49;&#x5B66;&#x4E60;&#x7387;</span>
w.data = w.data - lr * w.grad
b.data = b.data - lr * b.grad
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x753B;&#x51FA;&#x66F4;&#x65B0;&#x4E00;&#x6B21;&#x53C2;&#x6570;&#x4E4B;&#x540E;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x4E0E;&#x524D;&#x9762;&#x5BF9;&#x6BD4;</span>
y_pred = multi_linear(x_train)

plt.plot(x_train.data.numpy()[:, <span class="hljs-number">0</span>], y_pred.data.numpy(), label=<span class="hljs-string">&apos;fitting curve&apos;</span>, color=<span class="hljs-string">&apos;r&apos;</span>)
plt.plot(x_train.data.numpy()[:, <span class="hljs-number">0</span>], y_sample, label=<span class="hljs-string">&apos;real curve&apos;</span>, color=<span class="hljs-string">&apos;b&apos;</span>)
</code></pre>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fbb047a0a90&gt;]
</code></pre><p><img src="output_37_1.png" alt="png"></p>
<p><strong>&#x611F;&#x89C9;&#x66F4;&#x65B0;&#x4E00;&#x6B21;&#x53D8;&#x5316;&#x4E0D;&#x662F;&#x5F88;&#x5927;&#xFF0C;&#x63A5;&#x7740;&#x8FED;&#x4EE3;100&#x6B21;</strong></p>
<pre><code class="lang-python"><span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):
  y_pred = multi_linear(x_train)
  loss = get_loss(y_pred, y_train)

  w.grad.data.zero_()
  b.grad.data.zero_()
  loss.backward()

  w.data = w.data - lr * w.grad.data
  b.data = b.data - lr * b.grad

  <span class="hljs-comment"># &#x6CA1;20&#x6B21;&#x6253;&#x5370;&#x4E00;&#x6B21;loss</span>
  <span class="hljs-keyword">if</span> (e+<span class="hljs-number">1</span>) % <span class="hljs-number">20</span> == <span class="hljs-number">0</span>:
    print(<span class="hljs-string">&apos;epoch:{}, loss:{:.5f}&apos;</span>.format(e+<span class="hljs-number">1</span>, loss.item()))
</code></pre>
<pre><code>epoch:20, loss:73.67843
epoch:40, loss:17.97096
epoch:60, loss:4.94101
epoch:80, loss:1.87171
epoch:100, loss:1.12812
</code></pre><p>&#x770B;&#x66F4;&#x65B0;100&#x6B21;&#x4E4B;&#x540E;&#x7684;&#x4E24;&#x6761;&#x66F2;&#x7EBF;&#x62DF;&#x5408;&#x7A0B;&#x5EA6;&#xFF0C;loss&#x5DF2;&#x7ECF;&#x5F88;&#x5C0F;&#x4E86;&#xFF0C;&#x62DF;&#x5408;&#x6210;&#x90FD;&#x5F88;&#x9AD8;&#x7A0B;&#x5EA6;</p>
<pre><code class="lang-python">y_pred = multi_linear(x_train)

plt.plot(x_train.data.numpy()[:, <span class="hljs-number">0</span>], y_pred.data.numpy(), label=<span class="hljs-string">&apos;fitting curve&apos;</span>, color=<span class="hljs-string">&apos;r&apos;</span>)
plt.plot(x_train.data.numpy()[:, <span class="hljs-number">0</span>], y_sample, label=<span class="hljs-string">&apos;real curve&apos;</span>, color=<span class="hljs-string">&apos;b&apos;</span>)
</code></pre>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fbb0475ae10&gt;]
</code></pre><p><img src="output_41_1.png" alt="png"></p>
<h2 id="logistic-&#x56DE;&#x5F52;&#x6A21;&#x578B;">logistic &#x56DE;&#x5F52;&#x6A21;&#x578B;</h2>
<p>&#x901A;&#x8FC7;&#x4E0B;&#x9762;&#x4F8B;&#x5B50;&#x5B66;&#x4E60;logistic&#x56DE;&#x5F52;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BBE;&#x5B9A;&#x968F;&#x673A;&#x79CD;&#x5B50;</span>
torch.manual_seed(<span class="hljs-number">2017</span>)
</code></pre>
<pre><code>&lt;torch._C.Generator at 0x7fbb0e340170&gt;
</code></pre><p>&#x4ECE;data.txt&#x8BFB;&#x5165;&#x6570;&#x636E;&#xFF0C;&#x8BFB;&#x5165;&#x6570;&#x636E;&#x70B9;&#x4E4B;&#x540E;&#x6839;&#x636E;&#x4E0D;&#x540C;&#x7684;label&#x5C06;&#x6570;&#x636E;&#x70B9;&#x5206;&#x4E3A;&#x7EA2;&#x8272;&#x548C;&#x84DD;&#x8272;&#xFF0C;&#x5E76;&#x4E14;&#x753B;&#x56FE;&#x5C55;&#x73B0;</p>
<p><strong>&#x5176;&#x4E2D;split()&#x51FD;&#x6570;&#x7684;&#x7528;&#x6CD5;</strong></p>
<p>split()&#xFF1A;&#x8BED;&#x6CD5;&#xFF1A;str.split(str=&quot;&quot;,num=string.count(str))[n]</p>
<ul>
<li>&#x62C6;&#x5206;&#x5B57;&#x7B26;&#x4E32;&#x3002;&#x901A;&#x8FC7;&#x5236;&#x5B9A;&#x5206;&#x9694;&#x7B26;&#x5C06;&#x5B57;&#x7B26;&#x4E32;&#x8FDB;&#x884C;&#x5207;&#x7247;&#xFF0C;&#x5E76;&#x8FD4;&#x56DE;&#x5206;&#x5272;&#x540E;&#x7684;&#x5B57;&#x7B26;&#x4E32;&#x5217;&#x8868;[list]</li>
<li>&#x53C2;&#x6570;&#xFF1A;<ul>
<li>str&#xFF1A;&#x5206;&#x9694;&#x7B26;&#xFF0C;&#x9ED8;&#x8BA4;&#x4E3A;&#x7A7A;&#x683C;&#xFF0C;&#x4F46;&#x4E0D;&#x80FD;&#x4E3A;&#x7A7A;(&quot;&quot;)</li>
<li>num: &#x8868;&#x793A;&#x5206;&#x5272;&#x6B21;&#x6570;&#x3002;&#x5982;&#x679C;&#x6307;&#x5B9A;num&#xFF0C;&#x5219;&#x5206;&#x5272;&#x6210;n+1&#x4E2A;&#x5B50;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x5E76;&#x53EF;&#x5C06;&#x6BCF;&#x4E2A;&#x5B57;&#x7B26;&#x4E32;&#x8D4B;&#x7ED9;&#x65B0;&#x7684;&#x53D8;&#x91CF;</li>
<li>[n]: &#x9009;&#x53D6;&#x7B2C;n&#x4E2A;&#x5206;&#x7247;&#xFF0C;&#x5373;&#x7B2C;n&#x4E2A;&#x5B57;&#x7B26;&#x4E32;&#xFF0C;&#x4ECE;0&#x5F00;&#x59CB;&#x7B97;&#x3002;</li>
</ul>
</li>
</ul>
<p><strong>&#x793A;&#x4F8B;&#xFF1A;</strong></p>
<p>  u = &apos;www.google.com&apos;</p>
<p>  print u.split(&apos;.&apos;) --&gt; [&apos;www&apos;,&apos;google&apos;,&apos;com&apos;]</p>
<p>  print u.split(&apos;.&apos;,1)--&gt;[&apos;www&apos;,&apos;google.com&apos;]</p>
<p>  print u.split(&apos;.&apos;,2)[1]--&gt;google</p>
<p>  u1,u2,u3 = u.split(&apos;.&apos;) </p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4ECE; data.txt&#x8BFB;&#x5165;&#x6570;&#x636E;</span>
<span class="hljs-keyword">with</span> open(<span class="hljs-string">&apos;./data.txt&apos;</span>, <span class="hljs-string">&apos;r&apos;</span>) <span class="hljs-keyword">as</span> f:
  data_list = [i.split(<span class="hljs-string">&apos;\n&apos;</span>)[<span class="hljs-number">0</span>].split(<span class="hljs-string">&apos;,&apos;</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> f.readlines()]
  data = [(float(i[<span class="hljs-number">0</span>]), float(i[<span class="hljs-number">1</span>]), float(i[<span class="hljs-number">2</span>])) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data_list]

<span class="hljs-comment"># &#x6807;&#x51C6;&#x5316;&#x6570;&#x636E;</span>
x0_max = max([i[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data])
x1_max = max([i[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data])
data = [(i[<span class="hljs-number">0</span>]/x0_max, i[<span class="hljs-number">1</span>]/x1_max, i[<span class="hljs-number">2</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data]

x0 = list(filter(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">-1</span>] == <span class="hljs-number">0.0</span>, data)) <span class="hljs-comment"># &#x9009;&#x62E9;&#x7B2C;&#x4E00;&#x7C7B;&#x70B9;&#xFF0C;lambda&#x533F;&#x540D;&#x51FD;&#x6570;</span>
x1 = list(filter(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-number">-1</span>] == <span class="hljs-number">1.0</span>, data)) <span class="hljs-comment"># &#x9009;&#x62E9;&#x7B2C;&#x4E8C;&#x7C7B;&#x70B9;</span>

plot_x0 = [i[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x0]
plot_y0 = [i[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x0]
plot_x1 = [i[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x1]
plot_y1 = [i[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x1]

plt.plot(plot_x0, plot_y0, <span class="hljs-string">&apos;ro&apos;</span>, label=<span class="hljs-string">&apos;x_0&apos;</span>)
plt.plot(plot_x1, plot_y1, <span class="hljs-string">&apos;bo&apos;</span>, label=<span class="hljs-string">&apos;x_1&apos;</span>)
plt.legend(loc=<span class="hljs-string">&apos;best&apos;</span>)
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fbb04a7eac8&gt;
</code></pre><p><img src="output_46_1.png" alt="png"></p>
<p>&#x5C06;&#x6570;&#x636E;&#x8F6C;&#x6362;&#x6210;Numpy&#x7684;&#x7C7B;&#x578B;&#xFF0C;&#x63A5;&#x7740;&#x8F6C;&#x6362;&#x5230;Tensor&#x4E3A;&#x4E4B;&#x540E;&#x7684;&#x8BAD;&#x7EC3;&#x505A;&#x51C6;&#x5907;</p>
<pre><code class="lang-python">np_data = np.array(data, dtype=<span class="hljs-string">&apos;float32&apos;</span>) <span class="hljs-comment"># &#x8F6C;&#x6362;&#x6210; numpy array</span>
x_data = torch.from_numpy(np_data[:, <span class="hljs-number">0</span>:<span class="hljs-number">2</span>]) <span class="hljs-comment"># &#x8F6C;&#x6362;&#x6210;Tensot&#xFF0C; &#x5927;&#x5C0F;&#x662F;[100, 2]</span>
y_data = torch.from_numpy(np_data[:, <span class="hljs-number">-1</span>]).unsqueeze(<span class="hljs-number">1</span>) <span class="hljs-comment"># &#x8F6C;&#x6362;&#x6210;Tensor&#xFF0C; &#x5927;&#x5C0F;&#x662F;[100, 1]</span>
</code></pre>
<p>&#x5B9E;&#x73B0;Sigmoid&#x51FD;&#x6570;&#xFF0C;Sigmoid&#x51FD;&#x6570;&#x7684;&#x516C;&#x5F0F;&#x4E3A;&#xFF1A;
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>&#x2212;</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">f(x) = \frac{1}{1 + e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.845108em;"></span><span class="strut bottom" style="height:1.2484389999999999em;vertical-align:-0.403331em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathrm mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathit mtight">e</span><span class="msupsub"><span class="vlist"><span style="top:-0.286em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord scriptscriptstyle cramped mtight"><span class="mord mtight">&#x2212;</span><span class="mord mathit mtight">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span>
&#x753B;&#x51FA;sigmoid&#x51FD;&#x6570;&#xFF0C;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x503C;&#x8D8A;&#x5927;&#xFF0C;&#x7ECF;&#x8FC7;sigmoid&#x51FD;&#x6570;&#x5468;&#x540E;&#x8D8A;&#x9760;&#x8FD1;1&#xFF0C;&#x503C;&#x8D8A;&#x5C0F;&#x8D8A;&#x9760;&#x8FD1;0</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5B9A;&#x4E49;sigmoid&#x51FD;&#x6570;</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sigmoid</span><span class="hljs-params">(x)</span>:</span>
  <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x))

<span class="hljs-comment"># &#x753B;&#x51FA;sigmoid&#x51FD;&#x6570;&#x56FE;&#x50CF;</span>
plot_x = np.arange(<span class="hljs-number">-10</span>, <span class="hljs-number">10.01</span>, <span class="hljs-number">0.01</span>)
plot_y = sigmoid(plot_x)

plt.plot(plot_x, plot_y, <span class="hljs-string">&apos;r&apos;</span>)
</code></pre>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fbb048e6be0&gt;]
</code></pre><p><img src="output_50_1.png" alt="png"></p>
<pre><code class="lang-python">x_data = Variable(x_data)
y_data = Variable(y_data)
</code></pre>
<p>&#x5176;&#x5B9E;&#x5728;PyTorch&#x4E2D;&#xFF0C;&#x5E76;&#x4E0D;&#x9700;&#x8981;&#x624B;&#x52A8;&#x5B9E;&#x73B0;sigmoid&#x51FD;&#x6570;&#xFF0C;PyTorch&#x4E2D;&#x5DF2;&#x7ECF;&#x7528;&#x5E95;&#x5C42;&#x7684;C++&#x8BED;&#x8A00;&#x5199;&#x597D;&#x4E86;&#x4E00;&#x4E9B;&#x5E38;&#x7528;&#x7684;&#x51FD;&#x6570;&#xFF0C;&#x4E0D;&#x4EC5;&#x65B9;&#x4FBF;&#x800C;&#x4E14;&#x8FD0;&#x884C;&#x7684;&#x719F;&#x8BFB;&#x8F83;&#x5FEB;
&#x901A;&#x8FC7;<code>torch.nn.functional as F</code>&#x6765;&#x5BFC;&#x5165;&#x4F7F;&#x7528;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F

<span class="hljs-comment"># &#x5B9A;&#x4E49;logistic&#x56DE;&#x5F52;&#x6A21;&#x578B;</span>
w = Variable(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>), requires_grad=<span class="hljs-keyword">True</span>)
b = Variable(torch.zeros(<span class="hljs-number">1</span>), requires_grad=<span class="hljs-keyword">True</span>)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">logistic_regression</span><span class="hljs-params">(x)</span>:</span>
  <span class="hljs-keyword">return</span> F.sigmoid(torch.mm(x, w) + b)
</code></pre>
<p>&#x518D;&#x66F4;&#x65B0;&#x4E4B;&#x524D;&#xFF0C;&#x53EF;&#x4EE5;&#x5148;&#x753B;&#x51FA;&#x5206;&#x7C7B;&#x56FE;&#x7684;&#x6548;&#x679C;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x753B;&#x51FA;&#x66F4;&#x65B0;&#x524D;&#x7684;&#x7ED3;&#x679C;</span>
w0 = w[<span class="hljs-number">0</span>].data[<span class="hljs-number">0</span>]
w1 = w[<span class="hljs-number">1</span>].data[<span class="hljs-number">0</span>]
b0 = b.data[<span class="hljs-number">0</span>]

plot_x = np.arange(<span class="hljs-number">0.2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.01</span>)
plot_y = (-w0 * plot_x - b0) / w1

plt.plot(plot_x, plot_y, <span class="hljs-string">&apos;g&apos;</span>, label=<span class="hljs-string">&apos;cutting line&apos;</span>)
plt.plot(plot_x0, plot_y0, <span class="hljs-string">&apos;ro&apos;</span>, label=<span class="hljs-string">&apos;x_0&apos;</span>)
plt.plot(plot_x1, plot_y1, <span class="hljs-string">&apos;bo&apos;</span>, label=<span class="hljs-string">&apos;x_1&apos;</span>)
plt.legend(loc=<span class="hljs-string">&apos;best&apos;</span>)
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fbb04573d30&gt;
</code></pre><p><img src="output_55_1.png" alt="png"></p>
<p>&#x53EF;&#x4EE5;&#x770B;&#x51FA;&#x5206;&#x7C7B;&#x6548;&#x679C;&#x57FA;&#x672C;&#x662F;&#x6DF7;&#x4E71;&#x7684;&#xFF0C;&#x8BA1;&#x7B97;loss&#xFF1A;
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>&#x2212;</mo><mo>(</mo><mi>y</mi><mo>&#x2217;</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo>(</mo><mover accent="true"><mrow><mi>y</mi></mrow><mo>^</mo></mover><mo>)</mo><mo>+</mo><mo>(</mo><mn>1</mn><mo>&#x2212;</mo><mi>y</mi><mo>)</mo><mo>&#x2217;</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo>(</mo><mn>1</mn><mo>&#x2212;</mo><mover accent="true"><mrow><mi>y</mi></mrow><mo>^</mo></mover><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">loss=-(y*log(\hat{y})+(1-y)*log(1-\hat{y}))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit">s</span><span class="mord mathit">s</span><span class="mrel">=</span><span class="mord">&#x2212;</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mbin">&#x2217;</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="mord textstyle cramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span><span style="top:0em;margin-left:0.11112em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="accent-body"><span>^</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose">)</span><span class="mbin">+</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">&#x2212;</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mbin">&#x2217;</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">&#x2212;</span><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="mord textstyle cramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span><span style="top:0em;margin-left:0.11112em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="accent-body"><span>^</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BA1;&#x7B97;loss</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">binary_loss</span><span class="hljs-params">(y_pred, y)</span>:</span>
  logits = (y * y_pred.clamp(<span class="hljs-number">1e-12</span>).log() + (<span class="hljs-number">1</span> - y) * (<span class="hljs-number">1</span> - y_pred).clamp(<span class="hljs-number">1e-12</span>).log()).mean()
  <span class="hljs-keyword">return</span> -logits
</code></pre>
<p>&#x6CE8;&#x610F;.clamp() &#x548C; .log()</p>
<ul>
<li>.clamp(): &#x9650;&#x5B9A;&#x8F93;&#x5165;&#xFF08;input&#xFF09;&#x7684;Tensor&#x503C;&#x5728;[min, max]&#x4E4B;&#x95F4;&#xFF0C;&#x7136;&#x540E;&#x8F93;&#x51FA;&#xFF08;output&#xFF09;Tensor
&#x53C2;&#x6570;:<ul>
<li>input: &#x8F93;&#x5165;&#x7684;Tensor</li>
<li>min: &#x4E0B;&#x9650;</li>
<li>max: &#x4E0A;&#x9650;</li>
<li>out: &#x8F93;&#x51FA;[Tensor, optional]</li>
</ul>
</li>
<li>.log():&#x8FD4;&#x56DE;&#x81EA;&#x7136;&#x5BF9;&#x6570;&#x503C;&#xFF0C;&#x9ED8;&#x8BA4;&#x5E95;&#x4E3A;e</li>
</ul>
<pre><code class="lang-python">y_pred = logistic_regression(x_data)
loss = binary_loss(y_pred, y_data)
print(loss)
</code></pre>
<pre><code>tensor(0.6412, grad_fn=&lt;NegBackward&gt;)


/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)
</code></pre><p>&#x5F97;&#x5230;loss&#x4E4B;&#x540E;&#xFF0C;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x66F4;&#x65B0;&#x53C2;&#x6570;&#xFF0C;&#x8FD9;&#x91CC;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x81EA;&#x52A8;&#x6C42;&#x5BFC;&#x5F97;&#x5230;&#x53C2;&#x6570;&#x7684;&#x5BFC;&#x6570;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x81EA;&#x52A8;&#x6C42;&#x5BFC;&#x5E76;&#x66F4;&#x65B0;&#x53C2;&#x6570;</span>
loss.backward()
w.data = w.data - <span class="hljs-number">0.1</span> * w.grad.data
b.data = b.data - <span class="hljs-number">0.1</span> * b.grad.data

<span class="hljs-comment"># &#x7B97;&#x51FA;&#x4E00;&#x6B21;&#x66F4;&#x65B0;&#x4E4B;&#x540E;&#x7684;loss</span>
y_pred = logistic_regression(x_data)
loss = binary_loss(y_pred, y_data)
print(loss)
</code></pre>
<pre><code>tensor(0.6407, grad_fn=&lt;NegBackward&gt;)


/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)
</code></pre><ul>
<li><p>&#x4E0A;&#x9762;&#x7684;&#x53C2;&#x6570;&#x66F4;&#x65B0;&#x65B9;&#x5F0F;&#x5176;&#x5B9E;&#x662F;&#x7E41;&#x7410;&#x7684;&#x91CD;&#x590D;&#x64CD;&#x4F5C;&#xFF0C;&#x5982;&#x679C;&#x6211;&#x4EEC;&#x7684;&#x53C2;&#x6570;&#x5F88;&#x591A;&#xFF0C;&#x6BD4;&#x5982;&#x6709;100&#x4E2A;&#xFF0C;&#x90A3;&#x4E48;&#x9700;&#x8981;&#x5199;100&#x884C;&#x6765;&#x66F4;&#x65B0;&#x53C2;&#x6570;&#xFF0C;&#x4E3A;&#x4E86;&#x65B9;&#x4FBF;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5199;&#x6210;&#x4E00;&#x4E2A;&#x51FD;&#x6570;&#x6765;&#x66F4;&#x65B0;&#xFF0C;&#x5176;&#x5B9E;PyTorch&#x5DF2;&#x7ECF;&#x5C01;&#x88C5;&#x597D;&#x4E86;&#x51FD;&#x6570;&#x6765;&#x505A;&#x8FD9;&#x4EF6;&#x4E8B;&#xFF0C;&#x8FD9;&#x5C31;&#x662F;PyTorch&#x4E2D;&#x7684;&#x4F18;&#x5316;&#x5668;<code>`torch.optim</code></p>
</li>
<li><p>&#x4F7F;&#x7528;<code>torch.optim</code>&#x9700;&#x8981;&#x53E6;&#x5916;&#x4E00;&#x4E2A;&#x6570;&#x636E;&#x7C7B;&#x578B;&#xFF0C; &#x5C31;&#x662F;<code>nn.parameter</code>&#xFF0C;&#x8FD9;&#x672C;&#x8D28;&#x4E0A;&#x548C;Variable&#x662F;&#x4E00;&#x6837;&#x7684;&#xFF0C;&#x53EA;&#x4E0D;&#x8FC7;<code>nn.parameter</code> &#x9ED8;&#x8BA4;&#x662F;&#x8981;&#x6C42;&#x68AF;&#x5EA6;&#x7684;&#xFF0C;&#x800C;Variable&#x9ED8;&#x8BA4;&#x662F;&#x4E0D;&#x6C42;&#x68AF;&#x5EA6;&#x7684;</p>
</li>
<li><p>&#x4F7F;&#x7528;<code>torch.optim.SGD</code>&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x66F4;&#x65B0;&#x53C2;&#x6570;&#xFF0C; PyTorch&#x4E2D;&#x7684;&#x4F18;&#x5316;&#x5668;&#x6709;&#x66F4;&#x591A;&#x7684;&#x4F18;&#x5316;&#x7B97;&#x6CD5;</p>
</li>
<li><p>&#x5C06;&#x53C2;&#x6570; w &#x548C; b &#x653E;&#x5230;<code>torch.optim.SGD</code>&#x4E2D;&#x4E4B;&#x540E;&#xFF0C;&#x8BF4;&#x660E;&#x4E00;&#x4E0B;&#x5B66;&#x4E60;&#x7387;&#x7684;&#x5927;&#x5C0F;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;<code>optimizer.strp()</code>&#x6765;&#x66F4;&#x65B0;&#x4E86;&#xFF0C;&#x6BD4;&#x5982;&#x4E0B;&#x9762;&#x5C06;&#x53C2;&#x6570;&#x4F20;&#x8FDB;&#x4F18;&#x5316;&#x5668;&#xFF0C;&#x5B66;&#x4E60;&#x7387;&#x8BBE;&#x7F6E;&#x4E3A;1.0</p>
</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4F7F;&#x7528; torch.optim &#x66F4;&#x65B0;&#x53C2;&#x6570;</span>
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
w = nn.Parameter(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>))
n = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>))

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">logistic_regression</span><span class="hljs-params">(x)</span>:</span>
  <span class="hljs-keyword">return</span> F.sigmoid(torch.mm(x, w) + b)

optimizer = torch.optim.SGD([w, b], lr=<span class="hljs-number">1.</span>)
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8FDB;&#x884C; 1000 &#x6B21;&#x66F4;&#x65B0;</span>
<span class="hljs-keyword">import</span> time

start = time.time()
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):
  <span class="hljs-comment"># &#x524D;&#x5411;&#x4F20;&#x64AD;forward pass</span>
  y_pred = logistic_regression(x_data)

  <span class="hljs-comment"># loss</span>
  loss = binary_loss(y_pred, y_data)

  <span class="hljs-comment"># &#x53CD;&#x5411;&#x4F20;&#x64AD;backward pass</span>
  optimizer.zero_grad() <span class="hljs-comment"># &#x4F7F;&#x7528;&#x4F18;&#x5316;&#x5668;&#x6765;&#x66F4;&#x65B0;&#x68AF;&#x5EA6;&#x5F52;0</span>
  loss.backward()
  optimizer.step() <span class="hljs-comment"># &#x4F7F;&#x7528;&#x4F18;&#x5316;&#x5668;&#x6765;&#x66F4;&#x65B0;&#x53C2;&#x6570;</span>

  <span class="hljs-comment"># &#x8BA1;&#x7B97;&#x51C6;&#x786E;&#x7387;</span>
  mask = y_pred.ge(<span class="hljs-number">0.5</span>).float()
  acc = (mask == y_data).sum().item() / y_data.shape[<span class="hljs-number">0</span>]
  <span class="hljs-keyword">if</span> (e+<span class="hljs-number">1</span>) % <span class="hljs-number">200</span> == <span class="hljs-number">0</span>:
    print(<span class="hljs-string">&apos;epoch:{}, Loss:{:.5f}, Acc:{:.5f}&apos;</span>.format(e+<span class="hljs-number">1</span>, loss.item(), acc))

during = time.time() - start
print()
print(<span class="hljs-string">&quot;During Time:{:.3f}s&quot;</span>.format(during))
</code></pre>
<pre><code>/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)


epoch:200, Loss:0.39724, Acc:0.92000
epoch:400, Loss:0.32456, Acc:0.92000
epoch:600, Loss:0.29064, Acc:0.91000
epoch:800, Loss:0.27077, Acc:0.91000
epoch:1000, Loss:0.25764, Acc:0.90000

During Time:0.637s
</code></pre><p>&#x4F7F;&#x7528;&#x4F18;&#x5316;&#x5668;&#x4E4B;&#x540E;&#x66F4;&#x65B0;&#x53C2;&#x6570;&#x975E;&#x5E38;&#x7B80;&#x5355;&#xFF0C;&#x53EA;&#x9700;&#x8981;&#x5728;&#x81EA;&#x52A8;&#x6C42;&#x5BFC;&#x4E4B;&#x524D;&#x4F7F;&#x7528;<code>optimizer.zero_grad()</code>&#x6765;&#x5F52;<code>0</code>&#x68AF;&#x5EA6;&#xFF0C;&#x7136;&#x540E;&#x4F7F;&#x7528;<code>optimizer.step()</code>&#x66F4;&#x65B0;&#x53C2;&#x6570;&#x5C31;&#x53EF;&#x4EE5;&#x4E86;</p>
<p>&#x7ECF;&#x8FC7;1000&#x6B21;&#x7684;&#x66F4;&#x65B0;&#x4E4B;&#x540E;&#xFF0C;&#x753B;&#x51FA;&#x66F4;&#x65B0;&#x4E4B;&#x540E;&#x7684;&#x7ED3;&#x679C;</p>
<pre><code class="lang-python">w0 = w[<span class="hljs-number">0</span>].data[<span class="hljs-number">0</span>]
w1 = w[<span class="hljs-number">1</span>].data[<span class="hljs-number">0</span>]
b0 = b.data[<span class="hljs-number">0</span>]

plot_x = np.arange(<span class="hljs-number">0.2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.01</span>)
plot_y = (-w0 * plot_x - b0) / w1

plt.plot(plot_x, plot_y, <span class="hljs-string">&apos;g&apos;</span>, label=<span class="hljs-string">&apos;cutting line&apos;</span>)
plt.plot(plot_x0, plot_y0, <span class="hljs-string">&apos;ro&apos;</span>, label=<span class="hljs-string">&apos;x_0&apos;</span>)
plt.plot(plot_x1, plot_y1, <span class="hljs-string">&apos;bo&apos;</span>, label=<span class="hljs-string">&apos;x_1&apos;</span>)
plt.legend(loc=<span class="hljs-string">&apos;best&apos;</span>)
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fbb044ced68&gt;
</code></pre><p><img src="output_66_1.png" alt="png"></p>
<p>&#x66F4;&#x65B0;&#x4E4B;&#x540E;&#x6A21;&#x578B;&#x5DF2;&#x7ECF;&#x80FD;&#x591F;&#x57FA;&#x672C;&#x5C06;&#x4E24;&#x7C7B;&#x70B9;&#x5206;&#x5F00;&#x4E86;</p>
<p>&#x524D;&#x9762;&#x4F7F;&#x7528;&#x81EA;&#x5DF1;&#x5199;&#x7684;loss&#x51FD;&#x6570;&#xFF0C;&#x5176;&#x5B9E;&#x5728;PyTorch&#x4E2D;&#x4E5F;&#x6709;&#x5DF2;&#x7ECF;&#x5C01;&#x88C5;&#x597D;&#x5E38;&#x89C1;&#x7684;loss&#x51FD;&#x6570;&#xFF0C;&#x4F8B;&#x5982;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x4E2D;&#x7684;loss&#x662F;<code>nn.MSE()</code>, &#x800C;Logistic&#x56DE;&#x5F52;&#x7684;&#x4E8C;&#x5206;&#x7C7B;loss&#x662F;<code>nn.BCEWithLogitsLoss()</code>, &#x5173;&#x4E8E;&#x66F4;&#x591A;loss&#x67E5;&#x770B;<a href="pytorch.org/docs/0.3.0/nn.html#loss-functions">&#x6587;&#x6863;</a></p>
<p>&#x53E6;&#x5916;&#xFF0C;PyTorch&#x51FA;&#x4E8E;&#x7A33;&#x5B9A;&#x6027;&#x8003;&#x8651;&#xFF0C;&#x5C06;&#x6A21;&#x578B;&#x7684;Sigmoid&#x64CD;&#x4F5C;&#x548C;&#x6700;&#x540E;&#x7684;loss&#x90FD;&#x5728;<code>nn.BCEWithLogitsLoss()</code>&#xFF0C;&#x6240;&#x4EE5;&#x4F7F;&#x7528;PyTorch&#x81EA;&#x5E26;&#x7684;loss&#x5C31;&#x4E0D;&#x9700;&#x8981;&#x518D;&#x52A0;&#x4E0A;Sigmoid&#x64CD;&#x4F5C;&#x4E86;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4F7F;&#x7528;&#x81EA;&#x5E26;&#x7684;loss</span>
criterion = nn.BCEWithLogitsLoss() <span class="hljs-comment"># &#x5C06; sigmoid &#x548C; loss &#x5199;&#x5728;&#x4E00;&#x5C42;&#xFF0C;&#x6709;&#x66F4;&#x5FEB;&#x7684;&#x901F;&#x5EA6;&#x3001;&#x66F4;&#x597D;&#x7684;&#x7A33;&#x5B9A;&#x6027;</span>

w = nn.Parameter(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>))
b = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>))

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">logistic_reg</span><span class="hljs-params">(x)</span>:</span>
  <span class="hljs-keyword">return</span> torch.mm(x, w) + b

optimizer = torch.optim.SGD([w, b], <span class="hljs-number">1.</span>)

y_pred = logistic_reg(x_data)
loss = criterion(y_pred, y_data)
print(loss.data)
</code></pre>
<pre><code>tensor(0.6363)
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x540C;&#x6837;&#x8FDB;&#x884C; 1000 &#x6B21;&#x66F4;&#x65B0;</span>
start = time.time()
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">1000</span>):
  <span class="hljs-comment"># &#x524D;&#x5411;&#x4F20;&#x64AD;forward pass</span>
  y_pred = logistic_reg(x_data)

  <span class="hljs-comment"># loss</span>
  loss = criterion(y_pred, y_data)

  <span class="hljs-comment"># &#x53CD;&#x5411;&#x4F20;&#x64AD;backward pass</span>
  optimizer.zero_grad() <span class="hljs-comment"># &#x4F7F;&#x7528;&#x4F18;&#x5316;&#x5668;&#x6765;&#x66F4;&#x65B0;&#x68AF;&#x5EA6;&#x5F52;0</span>
  loss.backward()
  optimizer.step() <span class="hljs-comment"># &#x4F7F;&#x7528;&#x4F18;&#x5316;&#x5668;&#x6765;&#x66F4;&#x65B0;&#x53C2;&#x6570;</span>

  <span class="hljs-comment"># &#x8BA1;&#x7B97;&#x51C6;&#x786E;&#x7387;</span>
  mask = y_pred.ge(<span class="hljs-number">0.5</span>).float()
  acc = (mask == y_data).sum().item() / y_data.shape[<span class="hljs-number">0</span>]
  <span class="hljs-keyword">if</span> (e+<span class="hljs-number">1</span>) % <span class="hljs-number">200</span> == <span class="hljs-number">0</span>:
    print(<span class="hljs-string">&apos;epoch:{}, Loss:{:.5f}, Acc:{:.5f}&apos;</span>.format(e+<span class="hljs-number">1</span>, loss.item(), acc))

during = time.time() - start
print()
print(<span class="hljs-string">&quot;During Time:{:.3f}s&quot;</span>.format(during))
</code></pre>
<pre><code>epoch:200, Loss:0.39538, Acc:0.88000
epoch:400, Loss:0.32407, Acc:0.87000
epoch:600, Loss:0.29039, Acc:0.87000
epoch:800, Loss:0.27061, Acc:0.87000
epoch:1000, Loss:0.25753, Acc:0.88000

During Time:0.498s
</code></pre><pre><code class="lang-python">w0 = w[<span class="hljs-number">0</span>].data[<span class="hljs-number">0</span>]
w1 = w[<span class="hljs-number">1</span>].data[<span class="hljs-number">0</span>]
b0 = b.data[<span class="hljs-number">0</span>]

plot_x = np.arange(<span class="hljs-number">0.2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0.01</span>)
plot_y = (-w0 * plot_x - b0) / w1

plt.plot(plot_x, plot_y, <span class="hljs-string">&apos;g&apos;</span>, label=<span class="hljs-string">&apos;cutting line&apos;</span>)
plt.plot(plot_x0, plot_y0, <span class="hljs-string">&apos;ro&apos;</span>, label=<span class="hljs-string">&apos;x_0&apos;</span>)
plt.plot(plot_x1, plot_y1, <span class="hljs-string">&apos;bo&apos;</span>, label=<span class="hljs-string">&apos;x_1&apos;</span>)
plt.legend(loc=<span class="hljs-string">&apos;best&apos;</span>)
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fbb0444bda0&gt;
</code></pre><p><img src="output_70_1.png" alt="png"></p>
<p>&#x53EF;&#x4EE5;&#x770B;&#x51FA;&#xFF0C;&#x4F7F;&#x7528;&#x4E86;PyTorch&#x81EA;&#x5E26;&#x7684;loss&#x4E4B;&#x540E;&#xFF0C;&#x901F;&#x5EA6;&#x6709;&#x4E00;&#x5B9A;&#x7684;&#x4E0A;&#x5347;&#xFF0C;&#x8FD9;&#x53EA;&#x662F;&#x4E00;&#x4E2A;&#x5C0F;&#x7F51;&#x7EDC;&#xFF0C;&#x5BF9;&#x4E8E;&#x5927;&#x7F51;&#x7EDC;&#xFF0C;&#x4F7F;&#x7528;&#x81EA;&#x5E26;&#x7684;loss&#x901F;&#x5EA6;&#x548C;&#x7A33;&#x5B9A;&#x6027;&#x90FD;&#x4F1A;&#x6709;&#x8F83;&#x5927;&#x7684;&#x63D0;&#x9AD8;&#x3002;</p>
<h3 id="&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x76F8;&#x5173;&#x95EE;&#x9898;">&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x76F8;&#x5173;&#x95EE;&#x9898;</h3>
<p>&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4F7F;&#x7528;&#x7684;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x90FD;&#x662F;&#x975E;&#x7EBF;&#x6027;&#x7684;&#xFF0C;&#x6BCF;&#x4E2A;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x90FD;&#x8F93;&#x5165;&#x4E00;&#x4E2A;&#x503C;&#xFF0C;&#x7136;&#x540E;&#x505A;&#x4E00;&#x79CD;&#x7279;&#x5B9A;&#x7684;&#x6570;&#x5B66;&#x8FD0;&#x7B97;&#x5F97;&#x5230;&#x4E00;&#x4E2A;&#x7ED3;&#x679C;</p>
<ul>
<li>&#x6FC0;&#x6D3B;&#x51FD;&#x6570;<ul>
<li>sigmoid&#xFF1A;
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>&#x3B1;</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>&#x2212;</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha(x)=\frac{1}{1+e^{-x}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.845108em;"></span><span class="strut bottom" style="height:1.2484389999999999em;vertical-align:-0.403331em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.0037em;">&#x3B1;</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathrm mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathit mtight">e</span><span class="msupsub"><span class="vlist"><span style="top:-0.286em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord scriptscriptstyle cramped mtight"><span class="mord mtight">&#x2212;</span><span class="mord mathit mtight">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span></li>
<li>tanh
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mn>2</mn><mi>&#x3B1;</mi><mo>(</mo><mn>2</mn><mi>x</mi><mo>)</mo><mo>&#x2212;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">tanh(x)=2\alpha(2x)-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">t</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mord mathit">h</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathrm">2</span><span class="mord mathit" style="margin-right:0.0037em;">&#x3B1;</span><span class="mopen">(</span><span class="mord mathrm">2</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mbin">&#x2212;</span><span class="mord mathrm">1</span></span></span></span></li>
<li>ReLU
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">ReLU(x) = max(0, x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.00773em;">R</span><span class="mord mathit">e</span><span class="mord mathit">L</span><span class="mord mathit" style="margin-right:0.10903em;">U</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span><span class="mopen">(</span><span class="mord mathrm">0</span><span class="mpunct">,</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span></li>
</ul>
</li>
</ul>
<p>&#x4E0B;&#x9762;&#x4F1A;&#x91CD;&#x70B9;&#x8BB2;ReLU&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#xFF0C;&#x56E0;&#x4E3A;&#x73B0;&#x5728;&#x795E;&#x7ECF;&#x7F51;&#x8DEF;&#x4E2D;90%&#x7684;&#x60C5;&#x51B5;&#x90FD;&#x662F;&#x4F7F;&#x7528;&#x8FD9;&#x4E2A;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x3002;&#x4E00;&#x822C;&#x4E00;&#x4E2A;&#x4E00;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x516C;&#x5F0F;&#x5C31;&#x662F;&#xFF1A;$y=max(0, wx+b)$,&#x4E00;&#x4E2A;&#x4E24;&#x5C42;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5C31;&#x662F;
$y=w_2max(0, w_1x+b_1)+b_2$&#xFF0C;&#x975E;&#x5E38;&#x7B80;&#x5355;&#x5374;&#x5F88;&#x6709;&#x6548;&#x3002;</p>
<h3 id="&#x4E3A;&#x4EC0;&#x4E48;&#x8981;&#x4F7F;&#x7528;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;">&#x4E3A;&#x4EC0;&#x4E48;&#x8981;&#x4F7F;&#x7528;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;</h3>
<p>&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x5728;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#x975E;&#x5E38;&#x91CD;&#x8981;&#x3002;&#x4ECE;&#x4EBA;&#x8111;&#x795E;&#x7ECF;&#x5143;&#x7684;&#x89D2;&#x5EA6;&#x7406;&#x89E3;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#xFF0C;&#x56E0;&#x4E3A;&#x795E;&#x7ECF;&#x5143;&#x9700;&#x8981;&#x901A;&#x8FC7;&#x6FC0;&#x6D3B;&#x624D;&#x80FD;&#x5411;&#x540E;&#x4F20;&#x9012;&#xFF0C;&#x6240;&#x4EE5;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#x9700;&#x8981;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x3002;&#x4ECE;&#x6570;&#x5B66;&#x7684;&#x89D2;&#x5EA6;&#x7406;&#x89E3;&#xFF1A;</p>
<p>&#x6BD4;&#x5982;&#x4E00;&#x4E2A;&#x4E24;&#x5C42;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x4F7F;&#x7528;A&#x8868;&#x793A;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#xFF0C;&#x90A3;&#x4E48;
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>w</mi><mn>2</mn></msub><mi>A</mi><mo>(</mo><msub><mi>w</mi><mn>1</mn></msub><mi>x</mi><mo>)</mo><msub><mi>w</mi><mn>1</mn></msub><mi>x</mi></mrow><annotation encoding="application/x-tex">y=w_2A(w_1x)w_1x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit">A</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit">x</span></span></span></span>
&#x5982;&#x679C;&#x4E0D;&#x9002;&#x7528;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#xFF0C;&#x90A3;&#x4E48;&#x7ED3;&#x679C;&#x5C31;&#x662F;&#xFF1A;
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>w</mi><mn>2</mn></msub><mo>(</mo><msub><mi>w</mi><mn>1</mn></msub><mi>x</mi><mo>)</mo><mo>=</mo><mo>(</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>w</mi><mn>1</mn></msub><mo>)</mo><mi>x</mi><mo>=</mo><mover accent="true"><mrow><mi>w</mi></mrow><mo>&#x2C7;</mo></mover><mi>x</mi></mrow><annotation encoding="application/x-tex">y=w_2(w_1x)=(w_2w_1)x=\check{w}x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mrel">=</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span><span class="mord mathit">x</span><span class="mrel">=</span><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="mord textstyle cramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span></span></span><span style="top:0em;margin-left:0.16668em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="accent-body"><span>&#x2C7;</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mord mathit">x</span></span></span></span></p>
<p>&#x53EF;&#x4EE5;&#x770B;&#x51FA;&#xFF0C;&#x5C06;&#x4E24;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x53C2;&#x6570;&#x5408;&#x5E76;&#x5728;&#x4E00;&#x8D77;&#x6709;$\check{w}$&#x8868;&#x793A;&#xFF0C;&#x4E24;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5C31;&#x53D8;&#x6210;&#x4E86;&#x4E00;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x53EA;&#x4E0D;&#x8FC7;&#x53C2;&#x6570;&#x53D8;&#x6210;&#x4E86;&#x65B0;&#x7684;$\check{w}$&#xFF0C;&#x6240;&#x4EE5;&#x5982;&#x679C;&#x4E0D;&#x9002;&#x7528;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#xFF0C;&#x4E0D;&#x7BA1;&#x591A;&#x5C11;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;$y=w_n&#xB7;&#xB7;&#xB7;w_2w_1x$&#xFF0C;&#x90FD;&#x4F1A;&#x53D8;&#x6210;&#x4E86;&#x5355;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x6240;&#x4EE5;&#x5728;&#x6BCF;&#x4E00;&#x5C42;&#x90FD;&#x5FC5;&#x987B;&#x4F7F;&#x7528;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x3002;</p>
<h2 id="&#x591A;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;">&#x591A;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</h2>
<p>&#x524D;&#x9762;&#x5DF2;&#x7ECF;&#x4E86;&#x89E3;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x6A21;&#x578B;&#x548C;Logistic&#x56DE;&#x5F52;&#x6A21;&#x578B;&#xFF0C;&#x5206;&#x522B;&#x5904;&#x7406;&#x56DE;&#x5F52;&#x95EE;&#x9898;&#x548C;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x3002;</p>
<p>&#x4E0B;&#x9762;&#x4E86;&#x89E3;&#x7B2C;&#x4E00;&#x4E2A;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x6A21;&#x578B;&#xFF1A;&#x591A;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch 
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F

<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline
</code></pre>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_decision_boundary</span><span class="hljs-params">(model, x, y)</span>:</span>
  <span class="hljs-comment"># set min and max values and give it some padding</span>
  x_min, x_max = x[:, <span class="hljs-number">0</span>].min() - <span class="hljs-number">1</span>, x[:, <span class="hljs-number">0</span>].max() + <span class="hljs-number">1</span>
  y_min, y_max = x[:, <span class="hljs-number">1</span>].min() - <span class="hljs-number">1</span>, x[:, <span class="hljs-number">1</span>].max() + <span class="hljs-number">1</span>
  h = <span class="hljs-number">0.01</span>
  <span class="hljs-comment"># Generate a grid of points with distance h between them</span>
  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
  <span class="hljs-comment"># predict the function value for the whole grid</span>
  Z = model(np.c_[xx.ravel(), yy.ravel()])
  Z = Z.reshape(xx.shape)
  <span class="hljs-comment"># plot the contour and training examples</span>
  plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)
  plt.ylabel(<span class="hljs-string">&apos;x2&apos;</span>)
  plt.xlabel(<span class="hljs-string">&apos;x1&apos;</span>)
  plt.scatter(x[:, <span class="hljs-number">0</span>], x[:, <span class="hljs-number">1</span>], c=y.reshape(<span class="hljs-number">-1</span>), s=<span class="hljs-number">40</span>, cmap=plt.cm.Spectral)
</code></pre>
<p>&#x8FD9;&#x6B21;&#x4F9D;&#x7136;&#x5904;&#x7406;&#x4E8C;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#xFF0C;&#x4F46;&#x6BD4;&#x524D;&#x9762;&#x7684;logistic&#x56DE;&#x5F52;&#x66F4;&#x590D;&#x6742;</p>
<p>numpy.linspace()</p>
<pre><code class="lang-numpy.linspace(start,stop,num=50,endpoint=True,retstep=False,dtype=None)```">- start&#xFF1A;scalar&#x7C7B;&#x578B;&#xFF08;&#x4E2A;&#x4EBA;&#x7406;&#x89E3;&#x662F;&#x6807;&#x91CF;&#x7684;&#x610F;&#x601D;&#xFF0C;&#x8FD9;&#x4E0D;&#x662F;&#x4E00;&#x4E2A;&#x5177;&#x4F53;&#x7684;&#x6570;&#x636E;&#x7C7B;&#x578B;&#xFF0C;&#x800C;&#x662F;&#x6307;&#x67D0;&#x4E00;&#x4E9B;&#x6570;&#x636E;&#x7C7B;&#x578B;&#xFF0C;&#x6BD4;&#x5982;int,float,bool,long,str&#x7B49;&#x7B49;&#x90FD;&#x5C5E;&#x4E8E;sclar&#x7C7B;&#x578B;&#xFF09;&#x3002;&#x8FD9;&#x4E2A;&#x6570;&#x53C2;&#x6570;&#x8868;&#x793A;&#x8FD9;&#x4E2A;&#x5E8F;&#x5217;&#x7684;&#x5F00;&#x59CB;&#x503C;&#x3002;
- stop&#xFF1A;scalar&#x7C7B;&#x578B;&#x3002;&#x5982;&#x679C;endpoint=True&#x3002;&#x90A3;&#x4E48;stop&#x5C31;&#x662F;&#x5E8F;&#x5217;&#x7684;&#x7EC8;&#x6B62;&#x6570;&#x503C;&#x3002;&#x5F53;endpoint=False&#x65F6;&#xFF0C;&#x8FD4;&#x56DE;&#x503C;&#x4E2D;&#x4E0D;&#x5305;&#x542B;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x7AEF;&#x70B9;&#xFF0C;&#x5E76;&#x4E14;&#x6B65;&#x957F;&#x4F1A;&#x6539;&#x53D8;&#x3002;
- num&#xFF1A;int&#x578B;&#xFF0C;&#x53EF;&#x9009;&#x53C2;&#x6570;&#xFF0C;&#x9ED8;&#x8BA4;&#x503C;&#x4E3A;50&#x3002;&#x8868;&#x793A;&#x8981;&#x751F;&#x6210;&#x7684;&#x6837;&#x672C;&#x6570;&#xFF0C;&#x5FC5;&#x987B;&#x662F;&#x975E;&#x8D1F;&#x503C;&#x3002;
- endpoint&#xFF1A;bool&#x7C7B;&#x578B;&#x3002;&#x53EF;&#x9009;&#x53C2;&#x6570;&#xFF0C;&#x9ED8;&#x8BA4;&#x503C;&#x4E3A;True&#xFF0C;&#x8FD9;&#x65F6;stop&#x5C31;&#x662F;&#x6700;&#x540E;&#x7684;&#x6837;&#x672C;&#x3002;&#x4E3A;False&#x65F6;&#xFF0C;&#x4E0D;&#x5305;&#x542B;stop&#x7684;&#x503C;&#x3002;
- retstep&#xFF1A;bool&#x7C7B;&#x578B;&#x3002;&#x53EF;&#x9009;&#x53C2;&#x6570;&#xFF0C;&#x9ED8;&#x8BA4;&#x503C;&#x4E3A;True&#xFF0C;&#x8FD9;&#x65F6;&#x8FD4;&#x56DE;&#x503C;&#x662F;(samples,step)&#xFF0C;&#x524D;&#x9762;&#x7684;&#x662F;&#x6570;&#x7EC4;&#xFF0C;&#x540E;&#x9762;&#x662F;&#x6B65;&#x957F;&#x3002;
- dtype&#xFF1A;&#x8868;&#x793A;&#x8F93;&#x51FA;&#x7684;&#x6570;&#x7EC4;&#x7684;&#x6570;&#x636E;&#x7C7B;&#x578B;&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;&#x7ED9;&#x51FA;&#x5C31;&#x4ECE;&#x5176;&#x4ED6;&#x8F93;&#x5165;&#x4E2D;&#x63A8;&#x65AD;&#x8F93;&#x51FA;&#x7684;&#x7C7B;&#x578B;

&#x51FD;&#x6570;&#x8FD4;&#x56DE;&#x503C;
- samples&#xFF1A;ndarray&#x7C7B;&#x578B;&#x3002;&#x5728;[start&#xFF0C;stop]&#x95ED;&#x533A;&#x95F4;&#xFF0C;&#x6216;&#x8005;[start&#xFF0C;stop)&#x534A;&#x95ED;&#x5408;&#x533A;&#x95F4;&#x4E2D;&#xFF0C;&#x6570;&#x91CF;&#x4E3A;num&#xFF0C;&#x6B65;&#x957F;&#x76F8;&#x7B49;&#x7684;&#x6837;&#x672C;&#x3002;&#x81F3;&#x4E8E;&#x5305;&#x4E0D;&#x5305;&#x542B;stop&#x53D6;&#x51B3;&#x4E8E;endpoint&#x53C2;&#x6570;&#x7684;&#x53D6;&#x503C;&#x3002;
- step&#xFF1A;float&#x7C7B;&#x578B;&#x3002;&#x53EF;&#x9009;&#x3002;&#x53EA;&#x6709;restep&#x53C2;&#x6570;&#x53D6;&#x503C;&#x4E3A;True&#x65F6;&#x624D;&#x4F1A;&#x8FD4;&#x56DE;&#x8FD9;&#x4E2A;&#x8FD4;&#x56DE;&#x503C;&#xFF0C;&#x8868;&#x793A;&#x6837;&#x672C;&#x4E2D;&#x6B65;&#x957F;&#x3002;

np.c_ &#x548C; np.r_
- np.r_&#x5728;&#x5217;&#x7684;&#x65B9;&#x5411;&#x5408;&#x5E76;&#x4E24;&#x4E2A;&#x77E9;&#x9635;&#xFF0C;&#x5C31;&#x662F;&#x628A;&#x4E24;&#x77E9;&#x9635;&#x4E0A;&#x4E0B;&#x5408;&#x5E76;&#xFF0C;&#x8981;&#x6C42;&#x5217;&#x6570;&#x76F8;&#x7B49;&#x3002;
- np.c_&#x5728;&#x884C;&#x7684;&#x65B9;&#x5411;&#x5408;&#x5E76;&#x4E24;&#x4E2A;&#x77E9;&#x9635;&#xFF0C;&#x5C31;&#x662F;&#x628A;&#x4E24;&#x77E9;&#x9635;&#x5DE6;&#x53F3;&#x5408;&#x5E76;&#xFF0C;&#x8981;&#x6C42;&#x884C;&#x6570;&#x76F8;&#x7B49;&#x3002;


```python
np.random.seed(1) # &#x8BBE;&#x8BA1;&#x968F;&#x673A;&#x79CD;&#x5B50;
m = 400 # &#x6837;&#x672C;&#x6570;&#x91CF;
N = int(m/2) # &#x6BCF;&#x4E00;&#x7C7B;&#x70B9;&#x7684;&#x4E2A;&#x6570;
D = 2 # &#x7EF4;&#x5EA6;
x = np.zeros((m, D))
y = np.zeros((m, 1), dtype=&apos;uint8&apos;) # label &#x5411;&#x91CF;&#xFF0C;0&#x8868;&#x793A;&#x7EA2;&#x8272;&#xFF0C; 1&#x8868;&#x793A;&#x84DD;&#x8272;
a = 4

for j in range(2):
  ix = range(N*j, N*(j+1))
  t = np.linspace(j*3.12, (j+1)*3.12, N) + np.random.randn(N)*0.2 # theta
  r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius &#x56FE;&#x7684;&#x534A;&#x5F84;&#x957F;
  x[ix] = np.c_[r*np.sin(t), r*np.cos(t)]
  y[ix] = j
</code></pre>
<pre><code class="lang-python">plt.scatter(x[:, <span class="hljs-number">0</span>], x[:, <span class="hljs-number">1</span>], c=y.reshape(<span class="hljs-number">-1</span>), s=<span class="hljs-number">40</span>, cmap=plt.cm.Spectral)
</code></pre>
<pre><code>&lt;matplotlib.collections.PathCollection at 0x7fbb01786f28&gt;
</code></pre><p><img src="output_80_1.png" alt="png"></p>
<p>&#x5C1D;&#x8BD5;&#x4F7F;&#x7528;logistic&#x56DE;&#x5F52;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;</p>
<pre><code class="lang-python">x = torch.from_numpy(x).float()
y = torch.from_numpy(y).float()

w = nn.Parameter(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>))
b = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>))

optimizer = torch.optim.SGD([w, b], <span class="hljs-number">1e-1</span>)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">logistic_regression</span><span class="hljs-params">(x)</span>:</span>
  <span class="hljs-keyword">return</span> torch.mm(x, w) + b

criterion = nn.BCEWithLogitsLoss()

<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):
  <span class="hljs-comment"># forward pass</span>
  out = logistic_regression(Variable(x))
  <span class="hljs-comment"># loss</span>
  loss = criterion(out, Variable(y))
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()

  <span class="hljs-keyword">if</span> (e+<span class="hljs-number">1</span>) % <span class="hljs-number">20</span> == <span class="hljs-number">0</span>:
    print(<span class="hljs-string">&apos;epoch:{}, loss:{}&apos;</span>.format((e+<span class="hljs-number">1</span>), loss.item()))
</code></pre>
<pre><code>epoch:20, loss:0.6857785582542419
epoch:40, loss:0.6733670830726624
epoch:60, loss:0.6731525659561157
epoch:80, loss:0.6731471419334412
epoch:100, loss:0.6731464266777039
</code></pre><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_logistic</span><span class="hljs-params">(x)</span>:</span>
  x = Variable(torch.from_numpy(x).float())
  out = F.sigmoid(logistic_regression(x))
  out = (out &gt; <span class="hljs-number">0.5</span>) * <span class="hljs-number">1</span>
  <span class="hljs-keyword">return</span> out.data.numpy()
</code></pre>
<pre><code class="lang-python">plot_decision_boundary(<span class="hljs-keyword">lambda</span> x: plot_logistic(x), x.numpy(), y.numpy())
plt.title(<span class="hljs-string">&apos;logistic regression&apos;</span>)
</code></pre>
<pre><code>/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)





Text(0.5, 1.0, &apos;logistic regression&apos;)
</code></pre><p><img src="output_84_2.png" alt="png"></p>
<p>logistic&#x56DE;&#x5F52;&#x5E76;&#x4E0D;&#x80FD;&#x5F88;&#x597D;&#x533A;&#x5206;&#x8FD9;&#x4E2A;&#x590D;&#x6742;&#x7684;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x56E0;&#x4E3A;logistic&#x662F;&#x4E00;&#x4E2A;&#x7EBF;&#x6027;&#x5206;&#x7C7B;&#x5668;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5B9A;&#x4E49;&#x4E24;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x53C2;&#x6570;</span>
w1 = nn.Parameter(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>) * <span class="hljs-number">0.01</span>)
b1 = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>))

w2 = nn.Parameter(torch.randn(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>) * <span class="hljs-number">0.01</span>)
b2 = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>))

<span class="hljs-comment">#&#x3000;&#x5B9A;&#x4E49;&#x6A21;&#x578B;</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">two_network</span><span class="hljs-params">(x)</span>:</span>
  x1 = torch.mm(x, w1) + b1
  x1 = F.tanh(x1) <span class="hljs-comment"># &#x4F7F;&#x7528;PyTorch&#x81EA;&#x5E26;&#x7684;tanh&#x6FC0;&#x6D3B;&#x51FD;&#x6570;</span>
  x2 = torch.mm(x1, w2) + b2
  <span class="hljs-keyword">return</span> x2

optimizer = torch.optim.SGD([w1, w2, b1, b2], <span class="hljs-number">1.</span>)

criterion = nn.BCEWithLogitsLoss()
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BAD;&#x7EC3; 10000 &#x6B21;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">10000</span>):
  out = two_network(Variable(x))
  loss = criterion(out, Variable(y))
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()
  <span class="hljs-keyword">if</span> (e + <span class="hljs-number">1</span>) % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:
      print(<span class="hljs-string">&apos;epoch: {}, loss: {}&apos;</span>.format(e+<span class="hljs-number">1</span>, loss.item()))
</code></pre>
<pre><code>/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn(&quot;nn.functional.tanh is deprecated. Use torch.tanh instead.&quot;)


epoch: 1000, loss: 0.29250967502593994
epoch: 2000, loss: 0.27787667512893677
epoch: 3000, loss: 0.26922473311424255
epoch: 4000, loss: 0.2469901293516159
epoch: 5000, loss: 0.24106980860233307
epoch: 6000, loss: 0.23774310946464539
epoch: 7000, loss: 0.23549053072929382
epoch: 8000, loss: 0.2338249385356903
epoch: 9000, loss: 0.23253077268600464
epoch: 10000, loss: 0.2314915657043457
</code></pre><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_network</span><span class="hljs-params">(x)</span>:</span>
  x = Variable(torch.from_numpy(x).float())
  x1 = torch.mm(x, w1) + b1
  x1 = F.tanh(x1)
  x2 = torch.mm(x1, w2) + b2
  out = F.sigmoid(x2)
  out = (out &gt; <span class="hljs-number">0.5</span>) * <span class="hljs-number">1</span>
  <span class="hljs-keyword">return</span> out.data.numpy()
</code></pre>
<pre><code class="lang-python">plot_decision_boundary(<span class="hljs-keyword">lambda</span> x: plot_network(x), x.numpy(), y.numpy())
plt.title(<span class="hljs-string">&apos;two_layer_network&apos;</span>)
</code></pre>
<pre><code>/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn(&quot;nn.functional.tanh is deprecated. Use torch.tanh instead.&quot;)
/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)





Text(0.5, 1.0, &apos;two_layer_network&apos;)
</code></pre><p><img src="output_89_2.png" alt="png"></p>
<p>&#x591A;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x80FD;&#x591F;&#x6BD4;&#x8F83;&#x597D;&#x5730;&#x5206;&#x7C7B;&#x590D;&#x6742;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x56E0;&#x4E3A;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x7684;&#x5B58;&#x5728;&#xFF0C;&#x6210;&#x4E3A;&#x4E00;&#x4E2A;&#x975E;&#x7EBF;&#x6027;&#x7684;&#x5206;&#x7C7B;&#x5668;&#xFF0C;&#x6240;&#x4EE5;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x5206;&#x7C7B;&#x7684;&#x8FB9;&#x754C;&#x66F4;&#x52A0;&#x590D;&#x6742;</p>
<h3 id="sequential-&#x548C;-module">sequential &#x548C; module</h3>
<p>&#x5B66;&#x4E60;&#x8FC7;&#x6570;&#x636E;&#x5904;&#x7406;&#x3001;&#x6A21;&#x578B;&#x6784;&#x5EFA;&#x3001;loss&#x51FD;&#x6570;&#x8BBE;&#x8BA1;&#x7B49;&#x5185;&#x5BB9;&#xFF0C;&#x4F46;&#x662F;&#x5230;&#x76EE;&#x524D;&#x4E3A;&#x6B62;&#x8FD8;&#x6CA1;&#x6709;&#x51C6;&#x5907;&#x597D;&#x6784;&#x5EFA;&#x4E00;&#x4E2A;&#x5B8C;&#x6574;&#x7684;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7CFB;&#x7EDF;&#xFF0C;&#x4E00;&#x4E2A;&#x5B8C;&#x6210;&#x7684;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7CFB;&#x7EDF;&#x9700;&#x8981;&#x4E0D;&#x65AD;&#x5730;&#x8BFB;&#x5199;&#x6A21;&#x578B;&#x3002;&#x5728;&#x5B9E;&#x73B0;&#x5E94;&#x7528;&#x4E2D;&#xFF0C;&#x4E00;&#x822C;&#x4F1A;&#x5C06;&#x6A21;&#x578B;&#x5728;&#x672C;&#x5730;&#x8BAD;&#x7EC3;&#xFF0C;&#x7136;&#x540E;&#x4FDD;&#x5B58;&#x6A21;&#x578B;&#xFF0C;&#x63A5;&#x7740;&#x8BB2;&#x6A21;&#x578B;&#x90E8;&#x7F72;&#x5728;&#x4E0D;&#x540C;&#x7684;&#x5730;&#x65B9;&#x8FDB;&#x884C;&#x5E94;&#x7528;&#xFF0C;&#x4E0B;&#x9762;&#x8BB2;&#x89E3;&#x5982;&#x4F55;&#x4FDD;&#x5B58;PyTorch&#x7684;&#x6A21;&#x578B;&#x3002;</p>
<p>Pytorch&#x4E2D;&#x7684;&#x6A21;&#x5757;&#xFF1A;Sequential &#x548C; Module</p>
<p>&#x5BF9;&#x4E8E;&#x524D;&#x9762;&#x7684;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x6A21;&#x578B;&#x3001;Logistic&#x56DE;&#x5F52;&#x6A21;&#x578B;&#x548C;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x5728;&#x6784;&#x5EFA;&#x7684;&#x65F6;&#x5019;&#x5B9A;&#x4E49;&#x4E86;&#x9700;&#x8981;&#x7684;&#x53C2;&#x6570;&#x3002;&#x8FD9;&#x5BF9;&#x4E8E;&#x6BD4;&#x8F83;&#x5C0F;&#x7684;&#x6A21;&#x578B;&#x662F;&#x53EF;&#x884C;&#x7684;&#xFF0C;&#x4F46;&#x5BF9;&#x4E8E;&#x5927;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x6BD4;&#x5982;100&#x5C42;&#x7684;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;Sequential &#x548C; Module&#x6A21;&#x5757;&#x6765;&#x5E2E;&#x52A9;&#x89E3;&#x51B3;&#x4E0A;&#x8FF0;&#x95EE;&#x9898;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># Sequential</span>
seq_net = nn.Sequential(
    nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>), <span class="hljs-comment">#  PyTorch&#x4E2D;&#x7684;&#x7EBF;&#x6027;&#x5C42;</span>
    nn.Tanh(), <span class="hljs-comment"># &#x6FC0;&#x6D3B;&#x51FD;&#x6570;</span>
    nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># &#x8F93;&#x51FA;&#x5C42;</span>
)
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5E8F;&#x5217;&#x6A21;&#x5757;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x7D22;&#x5F15;&#x8BBF;&#x95EE;&#x6BCF;&#x4E00;&#x5C42;</span>
seq_net[<span class="hljs-number">0</span>] <span class="hljs-comment"># &#x7B2C;&#x4E00;&#x5C42;</span>
</code></pre>
<pre><code>Linear(in_features=2, out_features=4, bias=True)
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x6253;&#x5370;&#x51FA;&#x7B2C;&#x4E00;&#x5C42;&#x7684;&#x6743;&#x91CD;</span>
w0 = seq_net[<span class="hljs-number">0</span>].weight
print(w0)
</code></pre>
<pre><code>Parameter containing:
tensor([[ 0.6230, -0.3289],
        [ 0.1439,  0.1668],
        [ 0.7027,  0.1755],
        [-0.3346, -0.2292]], requires_grad=True)
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x901A;&#x8FC7; parameters &#x53EF;&#x4EE5;&#x83B7;&#x5F97;&#x6A21;&#x578B;&#x7684;&#x53C2;&#x6570;</span>
param = seq_net.parameters()

<span class="hljs-comment"># &#x5B9A;&#x4E49;&#x4F18;&#x5316;&#x5668;</span>
optim = torch.optim.SGD(param, <span class="hljs-number">1.</span>)
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BAD;&#x7EC3; 10000 &#x6B21;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">10000</span>):
  out = seq_net(Variable(x))
  loss = criterion(out, Variable(y))
  optim.zero_grad()
  loss.backward()
  optim.step()
  <span class="hljs-keyword">if</span> (e+<span class="hljs-number">1</span>) % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:
    print(<span class="hljs-string">&apos;epoch:{}, Loss:{:.5f}&apos;</span>.format((e+<span class="hljs-number">1</span>), loss.item()))
</code></pre>
<pre><code>epoch:1000, Loss:0.29159
epoch:2000, Loss:0.27866
epoch:3000, Loss:0.27085
epoch:4000, Loss:0.26570
epoch:5000, Loss:0.26212
epoch:6000, Loss:0.25951
epoch:7000, Loss:0.25752
epoch:8000, Loss:0.25595
epoch:9000, Loss:0.25469
epoch:10000, Loss:0.25364
</code></pre><p>&#x8BAD;&#x7EC3;10000&#x6B21;&#x4E4B;&#x540E;loss&#x6BD4;&#x4E4B;&#x524D;&#x7684;&#x66F4;&#x4F4E;&#xFF0C;&#x56E0;&#x4E3A;PyTorch&#x81EA;&#x5E26;&#x7684;&#x6A21;&#x5757;&#x66F4;&#x7A33;&#x5B9A;&#xFF0C;&#x540C;&#x65F6;&#x5728;&#x4E00;&#x4E9B;&#x521D;&#x59CB;&#x5316;&#x7684;&#x95EE;&#x9898;&#x5728;&#x91CC;&#x9762;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_seq</span><span class="hljs-params">(x)</span>:</span>
  out = F.sigmoid(seq_net(Variable(torch.from_numpy(x).float()))).data.numpy()
  out = (out &gt; <span class="hljs-number">0.5</span>) * <span class="hljs-number">1</span>
  <span class="hljs-keyword">return</span> out
</code></pre>
<pre><code class="lang-python">plot_decision_boundary(<span class="hljs-keyword">lambda</span> x: plot_seq(x), x.numpy(), y.numpy())
plt.title(<span class="hljs-string">&apos;sequential&apos;</span>)
</code></pre>
<pre><code>/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)





Text(0.5, 1.0, &apos;sequential&apos;)
</code></pre><p><img src="output_99_2.png" alt="png"></p>
<p>&#x4E0B;&#x9762;&#x8BB2;&#x89E3;&#x5982;&#x4F55;&#x4FDD;&#x5B58;&#x6A21;&#x578B;&#xFF0C;&#x4FDD;&#x5B58;&#x6A21;&#x578B;&#x5728;PyTorch&#x4E2D;&#x7684;&#x4E24;&#x79CD;&#x65B9;&#x5F0F;&#xFF0C;&#x4E00;&#x79CD;&#x662F;&#x5C06;&#x6A21;&#x578B;&#x7ED3;&#x6784;&#x548C;&#x53C2;&#x6570;&#x90FD;&#x4FDD;&#x5B58;&#x5728;&#x4E00;&#x8D77;&#xFF0C;&#x53E6;&#x4E00;&#x79CD;&#x662F;&#x53EA;&#x5C06;&#x53C2;&#x6570;&#x4FDD;&#x5B58;&#x4E0B;&#x6765;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5C06;&#x53C2;&#x6570;&#x548C;&#x6A21;&#x578B;&#x4FDD;&#x5B58;&#x5728;&#x4E00;&#x8D77;</span>
torch.save(seq_net, <span class="hljs-string">&apos;save_seq_net.pth&apos;</span>)
</code></pre>
<p>&#x4E0A;&#x9762;&#x5C31;&#x662F;&#x4FDD;&#x5B58;&#x6A21;&#x578B;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;<code>torch.save</code>&#x91CC;&#x9762;&#x9700;&#x8981;&#x4E24;&#x4E2A;&#x53C2;&#x6570;&#xFF1A;&#x8981;&#x4FDD;&#x5B58;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x53C2;&#x6570;&#x4FDD;&#x5B58;&#x7684;&#x8DEF;&#x5F84;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BFB;&#x53D6;&#x4FDD;&#x5B58;&#x7684;&#x6A21;&#x578B;</span>
seq_net1 = torch.load(<span class="hljs-string">&apos;save_seq_net.pth&apos;</span>)
seq_net1
</code></pre>
<pre><code>Sequential(
  (0): Linear(in_features=2, out_features=4, bias=True)
  (1): Tanh()
  (2): Linear(in_features=4, out_features=1, bias=True)
)
</code></pre><pre><code class="lang-python">print(seq_net1[<span class="hljs-number">0</span>].weight)
</code></pre>
<pre><code>Parameter containing:
tensor([[  9.9638, -12.3516],
        [  0.1162,   7.8367],
        [ 10.0949,  11.7157],
        [ -2.1773,  -5.5252]], requires_grad=True)
</code></pre><p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x91CD;&#x65B0;&#x8BFB;&#x5165;&#x4E86;&#x6A21;&#x578B;&#xFF0C;&#x5E76;&#x4E14;&#x5C06;&#x5176;&#x547D;&#x540D;&#x4E3A;seq_net1, &#x6253;&#x5370;&#x4E86;&#x7B2C;&#x4E00;&#x5C42;&#x53C2;&#x6570;</p>
<p>&#x4E0B;&#x9762;&#x770B;&#x7B2C;&#x4E8C;&#x79CD;&#x4FDD;&#x5B58;&#x6A21;&#x578B;&#x53C2;&#x6570;&#xFF0C;&#x53EA;&#x4FDD;&#x5B58;&#x53C2;&#x6570;&#x800C;&#x4E0D;&#x4FDD;&#x5B58;&#x6A21;&#x578B;&#x7ED3;&#x6784;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4FDD;&#x5B58;&#x6A21;&#x578B;&#x53C2;&#x6570;</span>
torch.save(seq_net.state_dict(), <span class="hljs-string">&apos;save_seq_net_params.pth&apos;</span>)
</code></pre>
<p>&#x901A;&#x8FC7;&#x4E0A;&#x9762;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x4FDD;&#x5B58;&#x4E86;&#x6A21;&#x578B;&#x7684;&#x53C2;&#x6570;&#xFF0C;&#x5982;&#x679C;&#x8981;&#x91CD;&#x65B0;&#x8BFB;&#x5165;&#x6A21;&#x578B;&#xFF0C;&#x9996;&#x5148;&#x9700;&#x8981;&#x91CD;&#x65B0;&#x5B9A;&#x4E49;&#x6A21;&#x578B;&#xFF0C;&#x63A5;&#x7740;&#x8BFB;&#x5165;&#x53C2;&#x6570;</p>
<pre><code class="lang-python">seq_net2 = nn.Sequential(
    nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>),
    nn.Tanh(),
    nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>)
)

seq_net2.load_state_dict(torch.load(<span class="hljs-string">&apos;save_seq_net_params.pth&apos;</span>))
</code></pre>
<pre><code>&lt;All keys matched successfully&gt;
</code></pre><pre><code class="lang-python">seq_net2
</code></pre>
<pre><code>Sequential(
  (0): Linear(in_features=2, out_features=4, bias=True)
  (1): Tanh()
  (2): Linear(in_features=4, out_features=1, bias=True)
)
</code></pre><pre><code class="lang-python">print(seq_net2[<span class="hljs-number">0</span>].weight)
</code></pre>
<pre><code>Parameter containing:
tensor([[  9.9638, -12.3516],
        [  0.1162,   7.8367],
        [ 10.0949,  11.7157],
        [ -2.1773,  -5.5252]], requires_grad=True)
</code></pre><p>&#x901A;&#x8FC7;&#x8FD9;&#x79CD;&#x65B9;&#x5F0F;&#x4E5F;&#x80FD;&#x91CD;&#x65B0;&#x8BFB;&#x5982;&#x6A21;&#x578B;&#xFF0C;&#x6253;&#x5370;&#x7B2C;&#x4E00;&#x5C42;&#x53C2;&#x6570;&#x5BF9;&#x6BD4;&#xFF0C;&#x53D1;&#x73B0;&#x548C;&#x524D;&#x9762;&#x7684;&#x529E;&#x6CD5;&#x4E00;&#x6837;&#x3002;&#x5BF9;&#x4E8E;&#x8FD9;&#x4E24;&#x79CD;&#x4FDD;&#x5B58;&#x548C;&#x8BFB;&#x53D6;&#x6A21;&#x578B;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x63A8;&#x8350;&#x4F7F;&#x7528;<code>&#x7B2C;&#x4E8C;&#x79CD;</code>&#xFF0C;&#x56E0;&#x4E3A;&#x53EF;&#x79FB;&#x690D;&#x6027;&#x66F4;&#x5F3A;</p>
<p>&#x4E0B;&#x9762;&#x4F7F;&#x7528;Module&#x5B9A;&#x4E49;&#x8FD9;&#x4E2A;&#x6A21;&#x578B;&#xFF0C;&#x4F7F;&#x7528;Module&#x7684;&#x6A21;&#x677F;</p>
<pre><code>class net_name(nn.Module):
  def __init__(self, define_some_parameters):
    super(net_name, self).__init__()
    self.layer1 = nn.Linear(num_input, num_hidden)
    self.layer2 = nn.Sequential(...)
    ...

  # &#x5B9A;&#x4E49;&#x9700;&#x8981;&#x7684;&#x7F51;&#x7EDC;&#x5C42;
  def forward(self, x): # &#x5B9A;&#x4E49;&#x524D;&#x5411;&#x4F20;&#x64AD;
  x1 = self.layer1(x)
  x2 = self.layer2(x)
  x = x1 + x2
  ...
  return x
</code></pre><p>&#x6CE8;&#x610F;&#xFF1A;Module&#x91CC;&#x9762;&#x4E5F;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;Sequential&#xFF0C; &#x540C;&#x6837;Module&#x975E;&#x5E38;&#x7075;&#x6D3B;&#xFF0C;&#x5177;&#x4F53;&#x4F53;&#x73B0;&#x5728;forward&#x4E2D;&#xFF0C;&#x5982;&#x4F55;&#x590D;&#x6742;&#x7684;&#x64CD;&#x4F5C;&#x90FD;&#x80FD;&#x76F4;&#x89C2;&#x5730;&#x5728;forward&#x91CC;&#x9762;&#x6267;&#x884C;</p>
<pre><code class="lang-python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">module_net</span><span class="hljs-params">(nn.Module)</span>:</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, num_input, num_hidden, num_output)</span>:</span>
    super(module_net, self).__init__()
    self.layer1 = nn.Linear(num_input, num_hidden)
    self.layer2 = nn.Tanh()
    self.layer3 = nn.Linear(num_hidden, num_output)

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
    x = self.layer1(x)
    x = self.layer2(x)
    x = self.layer3(x)

    <span class="hljs-keyword">return</span> x
</code></pre>
<pre><code class="lang-python">mo_net = module_net(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>)
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BBF;&#x95EE;&#x6A21;&#x578B;&#x4E2D;&#x7684;&#x67D0;&#x4E00;&#x5C42;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x901A;&#x8FC7;&#x540D;&#x5B57;</span>
<span class="hljs-comment"># &#x7B2C;&#x4E00;&#x5C42;</span>
l1 = mo_net.layer1
print(l1)
</code></pre>
<pre><code>Linear(in_features=2, out_features=4, bias=True)
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x6253;&#x5370;&#x51FA;&#x7B2C;&#x4E00;&#x5C42;&#x7684;&#x6743;&#x91CD;</span>
optim = torch.optim.SGD(mo_net.parameters(), <span class="hljs-number">1.</span>)
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BAD;&#x7EC3;10000&#x6B21;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">10000</span>):
  out = mo_net(Variable(x))
  loss = criterion(out, Variable(y))
  optim.zero_grad()
  loss.backward()
  optim.step()

  <span class="hljs-keyword">if</span> (e+<span class="hljs-number">1</span>) % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:
    print(<span class="hljs-string">&apos;epoch:{}, loss:{:.5f}&apos;</span>.format((e+<span class="hljs-number">1</span>), loss.item()))
</code></pre>
<pre><code>epoch:1000, loss:0.28638
epoch:2000, loss:0.27189
epoch:3000, loss:0.26486
epoch:4000, loss:0.26011
epoch:5000, loss:0.25672
epoch:6000, loss:0.25420
epoch:7000, loss:0.25227
epoch:8000, loss:0.25075
epoch:9000, loss:0.24954
epoch:10000, loss:0.24854
</code></pre><p>&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x76F8;&#x540C;&#x5F04;&#x7684;&#x7ED3;&#x679C;&#xFF0C; &#x4F7F;&#x7528;Sequential &#x548C; Module&#x6765;&#x5B9A;&#x4E49;&#x6A21;&#x578B;&#x66F4;&#x65B9;&#x4FBF;</p>
<p>&#x7EC3;&#x4E60;&#xFF1A;&#x6539;&#x53D8;&#x7F51;&#x7EDC;&#x7684;&#x9690;&#x85CF;&#x5C42;&#x795E;&#x7ECF;&#x5143;&#x4E2A;&#x6570;&#xFF0C; &#x6216;&#x8005;&#x5B9A;&#x4E49;5&#x5C42;&#x751A;&#x81F3;&#x66F4;&#x6DF1;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x589E;&#x52A0;&#x8BAD;&#x7EC3;&#x6B21;&#x6570;&#xFF0C;&#x6539;&#x53D8;&#x5B66;&#x4E60;&#x7387;</p>
<pre><code class="lang-python">my_net = nn.Sequential(
    nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">10</span>),
    nn.Tanh(),
    nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">100</span>),
    nn.Sigmoid(),
    nn.Linear(<span class="hljs-number">100</span>, <span class="hljs-number">1000</span>),
    nn.Tanh(),
    nn.Linear(<span class="hljs-number">1000</span>, <span class="hljs-number">100</span>),
    nn.Tanh(),
    nn.Linear(<span class="hljs-number">100</span>, <span class="hljs-number">10</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">1</span>)
)
optim = torch.optim.SGD(my_net.parameters(), <span class="hljs-number">0.1</span>)
</code></pre>
<pre><code class="lang-python"><span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">20000</span>):
  out = my_net(Variable(x))
  loss = criterion(out, Variable(y))
  optim.zero_grad()
  loss.backward()
  optim.step()

  <span class="hljs-keyword">if</span> (e+<span class="hljs-number">1</span>) % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:
    print(<span class="hljs-string">&apos;epoch:{}, Loss:{:.5f}&apos;</span>.format((e+<span class="hljs-number">1</span>), loss.item()))
</code></pre>
<pre><code>epoch:1000, Loss:0.34977
epoch:2000, Loss:0.29660
epoch:3000, Loss:0.25942
epoch:4000, Loss:0.21478
epoch:5000, Loss:0.19859
epoch:6000, Loss:0.19053
epoch:7000, Loss:0.18108
epoch:8000, Loss:0.17880
epoch:9000, Loss:0.17111
epoch:10000, Loss:0.17023
epoch:11000, Loss:0.16379
epoch:12000, Loss:0.15914
epoch:13000, Loss:0.15700
epoch:14000, Loss:0.15716
epoch:15000, Loss:0.15385
epoch:16000, Loss:0.15400
epoch:17000, Loss:0.14890
epoch:18000, Loss:0.14819
epoch:19000, Loss:0.14618
epoch:20000, Loss:0.15410
</code></pre><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_net</span><span class="hljs-params">(x)</span>:</span>
  out = F.sigmoid(my_net(Variable(torch.from_numpy(x).float()))).data.numpy()
  out = (out &gt; <span class="hljs-number">0.5</span>) * <span class="hljs-number">1</span>
  <span class="hljs-keyword">return</span> out 

plot_decision_boundary(<span class="hljs-keyword">lambda</span> x: plot_net(x), x.numpy(), y.numpy())
plt.title(<span class="hljs-string">&apos;sequential&apos;</span>)
</code></pre>
<pre><code>/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn(&quot;nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.&quot;)





Text(0.5, 1.0, &apos;sequential&apos;)
</code></pre><p><img src="output_122_2.png" alt="png"></p>
<h2 id="&#x6DF1;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;">&#x6DF1;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</h2>
<p>&#x4E0B;&#x9762;&#x4F7F;&#x7528;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7684;&#x5165;&#x95E8;&#x7EA7;&#x6570;&#x636E;&#x96C6;<code>MNIST</code>&#x624B;&#x5199;&#x5206;&#x7C7B;&#x8BF4;&#x660E;&#x66F4;&#x6DF1;&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x4F18;&#x826F;&#x8868;&#x73B0;</p>
<h3 id="mnist&#x6570;&#x636E;&#x96C6;">MNIST&#x6570;&#x636E;&#x96C6;</h3>
<p>mnist&#x6570;&#x636E;&#x96C6;&#x662F;&#x7F51;&#x7EDC;&#x4E0A;&#x4F5C;&#x4E3A;&#x4E00;&#x4E2A;&#x6D4B;&#x8BD5;&#x7684;&#x6807;&#x51C6;&#xFF0C;&#x6765;&#x81EA;&#x7F8E;&#x56FD;&#x56FD;&#x5BB6;&#x6807;&#x51C6;&#x6280;&#x672F;&#x7814;&#x7A76;&#x6240;&#xFF08;NIST&#xFF09;&#x3002;&#x8BAD;&#x7EC3;&#x96C6;&#xFF08;training set&#xFF09;&#x7531;&#x6765;&#x81EA;250&#x4E2A;&#x4E0D;&#x540C;&#x4EBA;&#x624B;&#x5199;&#x7684;&#x6570;&#x5B57;&#x6784;&#x6210;&#xFF0C;&#x4E00;&#x5171;60000&#x5F20;&#x56FE;&#x7247;&#x3002;&#x6D4B;&#x8BD5;&#x96C6;&#xFF08;test set&#xFF09;&#x4E5F;&#x662F;&#x540C;&#x6837;&#x6BD4;&#x4F8B;&#x7684;&#x624B;&#x5199;&#x6570;&#x636E;&#xFF0C;&#x4E00;&#x5171;&#x6709;10000&#x5F20;&#x56FE;&#x7247;&#xFF0C;&#x6BCF;&#x5F20;&#x56FE;&#x7247;&#x7684;&#x5927;&#x5C0F;&#x662F;28x28&#x7684;&#x7070;&#x5EA6;&#x56FE;&#x3002;</p>
<p>&#x6240;&#x4EE5;&#x63A5;&#x4E0B;&#x6765;&#x7684;&#x4EFB;&#x52A1;&#x5C31;&#x662F;&#x7ED9;&#x51FA;&#x4E00;&#x5F20;&#x56FE;&#x7247;&#xFF0C;&#x5E0C;&#x671B;&#x533A;&#x522B;&#x51FA;&#x5176;&#x662F;&#x5C5E;&#x4E8E;0-9&#x8FD9;&#x5341;&#x4E2A;&#x6570;&#x5B57;&#x4E2D;&#x7684;&#x54EA;&#x4E00;&#x4E2A;&#xFF1F;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;10&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x3002;</p>
<ul>
<li>&#x591A;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#xFF1A;&#x73B0;&#x5728;&#x5904;&#x7406;&#x7684;&#x95EE;&#x9898;&#x662F;&#x4E00;&#x4E2A;&#x6BD4;&#x4E8C;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x66F4;&#x4E3A;&#x590D;&#x6742;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x662F;&#x4E00;&#x4E2A;10&#x5206;&#x7C7B;&#x95EE;&#x9898;&#xFF0C;&#x5C5E;&#x4E8E;&#x591A;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#xFF0C;&#x5BF9;&#x4E8E;&#x591A;&#x5206;&#x7C7B;&#xFF0C;&#x4F7F;&#x7528;&#x7684;loss&#x51FD;&#x6570;&#x662F;<code>&#x4EA4;&#x53C9;&#x71B5;</code>&#x3002;</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># &#x76F4;&#x63A5;&#x4F7F;&#x7528;mnist&#x4E3E;&#x4F8B;&#x8BF4;&#x660E;&#x6DF1;&#x5EA6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torchvision.datasets <span class="hljs-keyword">import</span> mnist <span class="hljs-comment"># &#x5BFC;&#x5165;pytorch&#x5185;&#x7F6E;&#x7684;mnist&#x6570;&#x636E;</span>
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4F7F;&#x7528;&#x5185;&#x7F6E;&#x51FD;&#x6570;&#x4E0B;&#x8F7D;mnist&#x6570;&#x636E;&#x96C6;</span>
train_set = mnist.MNIST(<span class="hljs-string">&apos;./data&apos;</span>, train=<span class="hljs-keyword">True</span>, download=<span class="hljs-keyword">True</span>)
test_set = mnist.MNIST(<span class="hljs-string">&apos;./data&apos;</span>, train=<span class="hljs-keyword">False</span>, download=<span class="hljs-keyword">True</span>)
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x67E5;&#x770B;mnist&#x6570;&#x5B57;&#x7684;&#x6837;&#x5B50;</span>
a_data, a_label = train_set[<span class="hljs-number">0</span>]
a_data
</code></pre>
<p><img src="output_127_0.png" alt="png"></p>
<pre><code class="lang-python">a_label
</code></pre>
<pre><code>5
</code></pre><p>&#x8FD9;&#x91CC;&#x8BFB;&#x5165;&#x7684;&#x662F;PIL&#x5E93;&#x4E2D;&#x7684;&#x683C;&#x5F0F;&#xFF0C;&#x8981;&#x8F6C;&#x6362;&#x6210;numpy array</p>
<pre><code class="lang-python">a_data = np.array(a_data, dtype=<span class="hljs-string">&apos;float32&apos;</span>)
print(a_data.shape)
</code></pre>
<pre><code>(28, 28)
</code></pre><p>&#x8FD9;&#x91CC;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x56FE;&#x7247;&#x662F;&#x5927;&#x5C0F;&#x662F;28*28</p>
<pre><code class="lang-python">print(a_data)
</code></pre>
<pre><code>[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.
   18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.
  253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.
  253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.
  198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.
   11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.
    2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.
   70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.
  225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.
  240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.
  229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.
  253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.
  253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.
   80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]
</code></pre><p>&#x53EF;&#x4EE5;&#x5C06;&#x6570;&#x7EC4;&#x5C55;&#x793A;&#x5904;&#x7406;&#x554A;&#xFF0C;&#x91CC;&#x9762;&#x7684;0&#x5C31;&#x8868;&#x793A;&#x9ED1;&#x8272;&#xFF0C;255&#x8868;&#x793A;&#x767D;&#x8272;</p>
<p>&#x5BF9;&#x4E8E;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x7B2C;&#x4E00;&#x5C42;&#x7684;&#x8F93;&#x5165;&#x5C31;&#x662F;28x28=784&#xFF0C;&#x6240;&#x4EE5;&#x5FC5;&#x987B;&#x5C06;&#x5F97;&#x5230;&#x7684;&#x6570;&#x636E;&#x505A;&#x4E00;&#x4E2A;&#x53D8;&#x6362;&#xFF0C;&#x4F7F;&#x7528;reshape&#x5C06;&#x5B83;&#x4EEC;&#x62C9;&#x5E73;&#x6210;&#x4E00;&#x4E2A;&#x4E00;&#x7EF4;&#x5411;&#x91CF;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">data_tf</span><span class="hljs-params">(x)</span>:</span>
  x = np.array(x, dtype=<span class="hljs-string">&apos;float32&apos;</span>) / <span class="hljs-number">255</span>
  x = (x - <span class="hljs-number">0.5</span>) / <span class="hljs-number">0.5</span> <span class="hljs-comment"># &#x6807;&#x51C6;&#x5316;&#xFF0C;&#x8FD9;&#x4E2A;&#x6280;&#x5DE7;&#x5728;&#x5C06;&#x6765;&#x4F1A;&#x8BB2;&#x5230;</span>
  x = x.reshape((<span class="hljs-number">-1</span>,)) <span class="hljs-comment"># &#x62C9;&#x5E73;</span>
  x = torch.from_numpy(x)
  <span class="hljs-keyword">return</span> x

train_set = mnist.MNIST(<span class="hljs-string">&apos;./data&apos;</span>, train=<span class="hljs-keyword">True</span>, transform=data_tf, download=<span class="hljs-keyword">True</span>) <span class="hljs-comment"># &#x91CD;&#x65B0;&#x8F7D;&#x5165;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x7533;&#x660E;&#x5B9A;&#x4E49;&#x7684;&#x6570;&#x636E;&#x53D8;&#x6362;</span>
test_set = mnist.MNIST(<span class="hljs-string">&apos;./data&apos;</span>, train=<span class="hljs-keyword">False</span>, transform=data_tf, download=<span class="hljs-keyword">True</span>)
<span class="hljs-comment"># print(train_set[0])</span>
</code></pre>
<pre><code class="lang-python">a, a_label = train_set[<span class="hljs-number">0</span>]
print(a.shape)
print(a_label)
</code></pre>
<pre><code>torch.Size([784])
5
</code></pre><pre><code class="lang-python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-comment"># &#x4F7F;&#x7528;pytorch&#x81EA;&#x5E26;&#x7684;DateLoader&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;&#x6570;&#x636E;&#x8FED;&#x4EE3;&#x5668;</span>
train_data = DataLoader(train_set, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-keyword">True</span>)
test_data = DataLoader(test_set, batch_size=<span class="hljs-number">128</span>, shuffle=<span class="hljs-keyword">False</span>)
</code></pre>
<p>&#x4F7F;&#x7528;&#x8FD9;&#x6837;&#x7684;&#x6570;&#x636E;&#x8FED;&#x4EE3;&#x5668;&#x662F;&#x975E;&#x5E38;&#x6709;&#x5FC5;&#x8981;&#x7684;&#xFF0C;&#x5982;&#x679C;&#x6570;&#x636E;&#x91CF;&#x592A;&#x5927;&#xFF0C;&#x5C31;&#x65E0;&#x6CD5;&#x4E00;&#x6B21;&#x5C06;&#x4ED6;&#x4EEC;&#x8BFB;&#x5165;&#x5185;&#x5B58;&#xFF0C;&#x6240;&#x4EE5;&#x9700;&#x8981;&#x4F7F;&#x7528;python&#x8FED;&#x4EE3;&#x5668;&#xFF0C;&#x6BCF;&#x6B21;&#x751F;&#x6210;&#x4E00;&#x4E2A;&#x6279;&#x6B21;&#x7684;&#x6570;&#x636E;</p>
<pre><code class="lang-python">a, a_label = next(iter(train_data))
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x6253;&#x5370;&#x51FA;&#x4E00;&#x4E2A;&#x6279;&#x6B21;&#x7684;&#x6570;&#x636E;&#x5927;&#x5C0F;</span>
print(a.shape)
print(a_label.shape)
</code></pre>
<pre><code>torch.Size([64, 784])
torch.Size([64])
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x4F7F;&#x7528;Sequential &#x5B9A;&#x4E49;4&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</span>
net = nn.Sequential(
    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">400</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">400</span>, <span class="hljs-number">200</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">200</span>, <span class="hljs-number">100</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">100</span>,<span class="hljs-number">10</span>)
)
</code></pre>
<pre><code class="lang-python">net
</code></pre>
<pre><code>Sequential(
  (0): Linear(in_features=784, out_features=400, bias=True)
  (1): ReLU()
  (2): Linear(in_features=400, out_features=200, bias=True)
  (3): ReLU()
  (4): Linear(in_features=200, out_features=100, bias=True)
  (5): ReLU()
  (6): Linear(in_features=100, out_features=10, bias=True)
)
</code></pre><p>&#x4EA4;&#x53C9;&#x71B5;&#x5728;pytorch&#x4E2D;&#x5DF2;&#x7ECF;&#x5185;&#x7F6E;&#x4E86;&#xFF0C;&#x4EA4;&#x53C9;&#x71B5;&#x7684;&#x6570;&#x503C;&#x7A33;&#x5B9A;&#x6027;&#x66F4;&#x5DEE;&#xFF0C;&#x6240;&#x4EE5;&#x5185;&#x7F6E;&#x7684;&#x51FD;&#x6570;&#x5DF2;&#x7ECF;&#x5E2E;&#x52A9;&#x89E3;&#x51B3;&#x4E86;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;</p>
<pre><code class="lang-python">criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), <span class="hljs-number">1e-1</span>) <span class="hljs-comment"># &#x4F7F;&#x7528;&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#xFF0C; &#x5B66;&#x4E60;&#x7387;&#x4E3A;0.1</span>
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5F00;&#x59CB;&#x8BAD;&#x7EC3;</span>
losses = []
acces = []
eval_losses = []
eval_acces = []

<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">20</span>):
  train_loss = <span class="hljs-number">0</span>
  train_acc = <span class="hljs-number">0</span>
  net.train()
  <span class="hljs-keyword">for</span> im, label <span class="hljs-keyword">in</span> train_data:
    im = Variable(im)
    label = Variable(label)

    <span class="hljs-comment"># forward pass</span>
    out = net(im)

    <span class="hljs-comment">#loss</span>
    loss = criterion(out, label)

    <span class="hljs-comment"># backward pass</span>
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    <span class="hljs-comment"># record error</span>
    train_loss += loss.item()

    <span class="hljs-comment"># compute accuracy</span>
    _, pred = out.max(<span class="hljs-number">1</span>)
    num_correct = (pred == label).sum().item()
    acc = num_correct / im.shape[<span class="hljs-number">0</span>]
    train_acc += acc

  losses.append(train_loss / len(train_data))
  acces.append(train_acc /len(train_data))

  <span class="hljs-comment"># &#x6D4B;&#x8BD5;&#x96C6;&#x4E0A;&#x68C0;&#x9A8C;&#x6548;&#x679C;</span>
  eval_loss = <span class="hljs-number">0</span>
  eval_acc = <span class="hljs-number">0</span>

  net.eval() <span class="hljs-comment"># &#x5C06;&#x6A21;&#x578B;&#x6539;&#x4E3A;&#x9884;&#x6D4B;&#x6A21;&#x5F0F;</span>
  <span class="hljs-keyword">for</span> im, label <span class="hljs-keyword">in</span> test_data:
    im = Variable(im)
    label = Variable(label)
    out = net(im)
    loss = criterion(out, label)
    <span class="hljs-comment"># record error</span>
    eval_loss += loss.item()
    <span class="hljs-comment"># record accuracy</span>
    _, pred = out.max(<span class="hljs-number">1</span>)
    num_correct = (pred == label).sum().item()
    acc = num_correct / im.shape[<span class="hljs-number">0</span>]
    eval_acc += acc

  eval_losses.append(eval_loss / len(test_data))
  eval_acces.append(eval_acc / len(test_data))
  print(<span class="hljs-string">&apos;epoch:{}, Train Loss:{:.6f}, Train Acc:{:.6f}, Eval Loss:{:.6f}, Eval Acc:{:.6f}&apos;</span>
      .format(e, train_loss / len(train_data), train_acc / len(train_data), 
      eval_loss / len(test_data), eval_acc / len(test_data)))
</code></pre>
<pre><code>epoch:0, Train Loss:0.547004, Train Acc:0.825893, Eval Loss:0.180316, Eval Acc:0.944027
epoch:1, Train Loss:0.167217, Train Acc:0.947828, Eval Loss:0.138720, Eval Acc:0.956092
epoch:2, Train Loss:0.119038, Train Acc:0.963186, Eval Loss:0.101811, Eval Acc:0.967267
epoch:3, Train Loss:0.092637, Train Acc:0.970766, Eval Loss:0.095951, Eval Acc:0.968157
epoch:4, Train Loss:0.073375, Train Acc:0.976979, Eval Loss:0.081659, Eval Acc:0.973200
epoch:5, Train Loss:0.062949, Train Acc:0.979794, Eval Loss:0.095152, Eval Acc:0.970728
epoch:6, Train Loss:0.051058, Train Acc:0.983176, Eval Loss:0.081442, Eval Acc:0.975672
epoch:7, Train Loss:0.046242, Train Acc:0.985125, Eval Loss:0.074518, Eval Acc:0.976167
epoch:8, Train Loss:0.037689, Train Acc:0.987790, Eval Loss:0.070374, Eval Acc:0.979035
epoch:9, Train Loss:0.034902, Train Acc:0.989106, Eval Loss:0.082433, Eval Acc:0.973596
epoch:10, Train Loss:0.030452, Train Acc:0.990155, Eval Loss:0.084045, Eval Acc:0.974090
epoch:11, Train Loss:0.024437, Train Acc:0.992337, Eval Loss:0.106109, Eval Acc:0.970036
epoch:12, Train Loss:0.022535, Train Acc:0.992521, Eval Loss:0.087515, Eval Acc:0.974387
epoch:13, Train Loss:0.019464, Train Acc:0.993920, Eval Loss:0.074319, Eval Acc:0.979727
epoch:14, Train Loss:0.016294, Train Acc:0.995236, Eval Loss:0.069384, Eval Acc:0.981408
epoch:15, Train Loss:0.015273, Train Acc:0.994986, Eval Loss:0.087692, Eval Acc:0.977453
epoch:16, Train Loss:0.012653, Train Acc:0.996102, Eval Loss:0.089574, Eval Acc:0.975672
epoch:17, Train Loss:0.013279, Train Acc:0.995652, Eval Loss:0.070803, Eval Acc:0.981606
epoch:18, Train Loss:0.011036, Train Acc:0.996652, Eval Loss:0.105947, Eval Acc:0.973991
epoch:19, Train Loss:0.009937, Train Acc:0.996818, Eval Loss:0.072299, Eval Acc:0.981408
</code></pre><p>&#x753B;&#x51FA;loss&#x66F2;&#x7EBF;&#x548C;&#x51C6;&#x786E;&#x7387;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline
</code></pre>
<pre><code class="lang-python">plt.title(<span class="hljs-string">&apos;train loss&apos;</span>)
plt.plot(np.arange(len(losses)), losses)
</code></pre>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7fbb0029a080&gt;]
</code></pre><p><img src="output_147_1.png" alt="png"></p>
<pre><code class="lang-python">plt.plot(np.arange(len(acces)), acces)
plt.title(<span class="hljs-string">&apos;train acc&apos;</span>)
</code></pre>
<pre><code>Text(0.5, 1.0, &apos;train acc&apos;)
</code></pre><p><img src="output_148_1.png" alt="png"></p>
<pre><code class="lang-python">plt.plot(np.arange(len(eval_losses)), eval_losses)
plt.title(<span class="hljs-string">&apos;test loss&apos;</span>)
</code></pre>
<pre><code>Text(0.5, 1.0, &apos;test loss&apos;)
</code></pre><p><img src="output_149_1.png" alt="png"></p>
<pre><code class="lang-python">plt.plot(np.arange(len(eval_acces)), eval_acces)
plt.title(<span class="hljs-string">&apos;test acc&apos;</span>)
</code></pre>
<pre><code>Text(0.5, 1.0, &apos;test acc&apos;)
</code></pre><p><img src="output_150_1.png" alt="png"></p>
<h3 id="softmax&#x51FD;&#x6570;">softmax&#x51FD;&#x6570;</h3>
<p>softmax&#x51FD;&#x6570;&#x5BF9;&#x4E8E;&#x7F51;&#x7EDC;&#x7684;&#x8F93;&#x51FA;$z_1,z_2,&#xB7;&#xB7;&#xB7;,z_k$,&#x9996;&#x5148;&#x5BF9;&#x6BCF;&#x4E2A;&#x53D6;&#x6307;&#x6570;&#x53D8;&#x6210;$e^{z_1},e^{z_2},&#xB7;&#xB7;&#xB7;,e^{z_k}$,&#x90A3;&#x4E48;&#x6BCF;&#x4E00;&#x9879;&#x9664;&#x4EE5;&#x4ED6;&#x4EEC;&#x7684;&#x6C42;&#x548C;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mrow><msub><mi>z</mi><mi>i</mi></msub></mrow></msup></mrow><mrow><msubsup><mo>&#x2211;</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>k</mi></mrow></msubsup><msup><mi>e</mi><mrow><msub><mi>z</mi><mi>j</mi></msub></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">
z_i = \frac{e^{z_i}}{\sum_{j=1}^{k}e^{z_j}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.341392em;"></span><span class="strut bottom" style="height:2.5176179999999997em;vertical-align:-1.1762259999999998em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.04398em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.7401079999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mop"><span class="mop op-symbol small-op" style="top:-0.0000050000000000050004em;">&#x2211;</span><span class="msupsub"><span class="vlist"><span style="top:0.30001em;margin-left:0em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mathrm mtight">1</span></span></span></span><span style="top:-0.364em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord"><span class="mord mathit">e</span><span class="msupsub"><span class="vlist"><span style="top:-0.30507em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist"><span style="top:0.14300000000000002em;margin-right:0.07142857142857144em;margin-left:-0.04398em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord mathit mtight" style="margin-right:0.05724em;">j</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord"><span class="mord mathit">e</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist"><span style="top:0.143em;margin-right:0.07142857142857144em;margin-left:-0.04398em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-scriptstyle scriptscriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span></span>
&#x5982;&#x679C;&#x5BF9;&#x7ECF;&#x8FC7;softmax&#x51FD;&#x6570;&#x7684;&#x6240;&#x6709;&#x9879;&#x6C42;&#x548C;&#x5C31;&#x7B49;&#x4E8E;1&#xFF0C;&#x6240;&#x4EE5;&#x6BCF;&#x4E00;&#x9879;&#x90FD;&#x5206;&#x522B;&#x8868;&#x793A;&#x5C5E;&#x4E8E;&#x5176;&#x4E2D;&#x67D0;&#x4E00;&#x7C7B;&#x7684;&#x6982;&#x7387;&#x3002;</p>
<h3 id="&#x4EA4;&#x53C9;&#x71B5;">&#x4EA4;&#x53C9;&#x71B5;</h3>
<p>&#x4EA4;&#x53C9;&#x71B5;&#x8861;&#x91CF;&#x4E24;&#x4E2A;&#x5206;&#x5E03;&#x76F8;&#x4F3C;&#x6027;&#x7684;&#x4E00;&#x79CD;&#x5EA6;&#x91CF;&#x65B9;&#x5F0F;&#xFF0C;&#x524D;&#x9762;&#x7684;&#x4E8C;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x7684;loss&#x51FD;&#x6570;&#x5C31;&#x662F;&#x4EA4;&#x53C9;&#x71B5;&#x7684;&#x4E00;&#x79CD;&#x7279;&#x6B8A;&#x60C5;&#x51B5;&#xFF0C;&#x4EA4;&#x53C9;&#x71B5;&#x7684;&#x4E00;&#x822C;&#x516C;&#x5F0F;&#x4E3A;&#xFF1A;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi><mi>r</mi><mi>o</mi><mi>s</mi><mi>s</mi><mi mathvariant="normal">_</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>o</mi><mi>r</mi><mi>p</mi><mi>y</mi><mo>(</mo><mi>p</mi><mo separator="true">,</mo><mi>q</mi><mo>)</mo><mo>=</mo><msub><mi>E</mi><mi>q</mi></msub><mo>[</mo><mo>&#x2212;</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>q</mi><mo>]</mo><mo>=</mo><mo>&#x2212;</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>m</mi></mrow></mfrac><msub><mo>&#x2211;</mo><mi>x</mi></msub><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>q</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">cross\_entorpy(p,q)=E_q[-logq]=-\frac{1}{m}\sum_xp(x)logq(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.845108em;"></span><span class="strut bottom" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="base textstyle uncramped"><span class="mord mathit">c</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">o</span><span class="mord mathit">s</span><span class="mord mathit">s</span><span class="mord mathrm" style="margin-right:0.02778em;">_</span><span class="mord mathit">e</span><span class="mord mathit">n</span><span class="mord mathit">t</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">p</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathit">p</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.05764em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight" style="margin-right:0.03588em;">q</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mopen">[</span><span class="mord">&#x2212;</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mclose">]</span><span class="mrel">=</span><span class="mord">&#x2212;</span><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">m</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mop"><span class="mop op-symbol small-op" style="top:-0.0000050000000000050004em;">&#x2211;</span><span class="msupsub"><span class="vlist"><span style="top:0.30001em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">x</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit">p</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span></p>
<p>&#x5BF9;&#x4E8E;&#x4E8C;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x53EF;&#x4EE5;&#x5199;&#x6210;&#xFF1A;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>&#x2212;</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>m</mi></mrow></mfrac><msubsup><mo>&#x2211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi></mrow></msubsup><mo>(</mo><msup><mi>y</mi><mi>i</mi></msup><mi>l</mi><mi>o</mi><mi>g</mi><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo>(</mo><msup><mi>x</mi><mi>i</mi></msup><mo>)</mo><mo>+</mo><mo>(</mo><mn>1</mn><mo>&#x2212;</mo><msup><mi>y</mi><mi>i</mi></msup><mo>)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo>(</mo><mn>1</mn><mo>&#x2212;</mo><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo>(</mo><msup><mi>x</mi><mi>i</mi></msup><mo>)</mo><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">-\frac{1}{m}\sum_{i=1}^{m}(y^ilogsigmoid(x^i)+(1-y^i)log(1-sigmoid(x^i)))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.845108em;"></span><span class="strut bottom" style="height:1.190108em;vertical-align:-0.345em;"></span><span class="base textstyle uncramped"><span class="mord">&#x2212;</span><span class="mord reset-textstyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.345em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">m</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathrm mtight">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mop"><span class="mop op-symbol small-op" style="top:-0.0000050000000000050004em;">&#x2211;</span><span class="msupsub"><span class="vlist"><span style="top:0.30001em;margin-left:0em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">i</span><span class="mrel mtight">=</span><span class="mord mathrm mtight">1</span></span></span></span><span style="top:-0.364em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathit mtight">m</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">i</span><span class="mord mathit">d</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span><span class="mbin">+</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">&#x2212;</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">&#x2212;</span><span class="mord mathit">s</span><span class="mord mathit">i</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">i</span><span class="mord mathit">d</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></p>
<h2 id="&#x53C2;&#x6570;&#x521D;&#x59CB;&#x5316;">&#x53C2;&#x6570;&#x521D;&#x59CB;&#x5316;</h2>
<p>&#x53C2;&#x6570;&#x521D;&#x59CB;&#x5316;&#x5BF9;&#x6A21;&#x578B;&#x5177;&#x6709;&#x8F83;&#x5927;&#x7684;&#x5F71;&#x54CD;&#xFF0C;&#x4E0D;&#x540C;&#x7684;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x5F0F;&#x53EF;&#x80FD;&#x4F1A;&#x5BFC;&#x81F4;&#x622A;&#x7136;&#x4E0D;&#x540C;&#x7684;&#x7ED3;&#x679C;&#xFF0C;&#x6240;&#x5E78;&#x7684;&#x662F;&#x5F88;&#x591A;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7684;&#x5148;&#x9A71;&#x4EEC;&#x5DF2;&#x7ECF;&#x63A2;&#x7D22;&#x4E86;&#x5404;&#x79CD;&#x5404;&#x6837;&#x7684;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x5F0F;&#xFF0C;&#x6240;&#x4EE5;&#x53EA;&#x9700;&#x8981;&#x5B66;&#x4F1A;&#x5982;&#x4F55;&#x5BF9;&#x6A21;&#x578B;&#x8FDB;&#x884C;&#x521D;&#x59CB;&#x5316;&#x7684;&#x8D4B;&#x503C;&#x5373;&#x53EF;&#x3002;</p>
<p>PyTorch&#x7684;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x5F0F;&#x5E76;&#x6CA1;&#x6709;&#x90A3;&#x4E48;&#x663E;&#x7136;&#xFF0C;&#x5982;&#x679C;&#x4F7F;&#x7528;&#x6700;&#x539F;&#x59CB;&#x7684;&#x65B9;&#x5F0F;&#x521B;&#x5EFA;&#x6A21;&#x578B;&#xFF0C;&#x90A3;&#x4E48;&#x9700;&#x8981;&#x5B9A;&#x4E49;&#x6A21;&#x578B;&#x4E2D;&#x7684;&#x6240;&#x6709;&#x53C2;&#x6570;&#xFF0C;&#x5F53;&#x7136;&#x8FD9;&#x6837;&#x53EF;&#x4EE5;&#x975E;&#x5E38;&#x65B9;&#x4FBF;&#x5730;&#x5B9A;&#x4E49;&#x6BCF;&#x4E2A;&#x53D8;&#x91CF;&#xFF0C;&#x4F46;&#x662F;&#x5BF9;&#x4E8E;&#x590D;&#x6742;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x8FD9;&#x5E76;&#x4E0D;&#x5BB9;&#x6613;&#xFF0C;&#x800C;&#x4E14;&#x63A8;&#x5D07;Sequential&#x548C;Module&#x6765;&#x5B9A;&#x4E49;&#x6A21;&#x578B;&#xFF0C;&#x6240;&#x4EE5;&#x8FD9;&#x4E2A;&#x65F6;&#x5019;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x77E5;&#x9053;&#x5982;&#x4F55;&#x5B9A;&#x4E49;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x5F0F;&#x3002;</p>
<h3 id="&#x4F7F;&#x7528;numpy&#x6765;&#x521D;&#x59CB;&#x5316;">&#x4F7F;&#x7528;Numpy&#x6765;&#x521D;&#x59CB;&#x5316;</h3>
<p>&#x56E0;&#x4E3A;PyTorch&#x662F;&#x4E00;&#x4E2A;&#x975E;&#x5E38;&#x7075;&#x6D3B;&#x7684;&#x6846;&#x67B6;&#xFF0C;&#x7406;&#x8BBA;&#x4E0A;&#x80FD;&#x591F;&#x5BF9;&#x6240;&#x6709;&#x7684;Tensor&#x8FDB;&#x884C;&#x64CD;&#x4F5C;&#xFF0C;&#x6240;&#x4EE5;&#x80FD;&#x591F;&#x5B9A;&#x4E49;&#x65B0;&#x7684;Tensor&#x6765;&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x770B;&#x4E0B;&#x9762;&#x7684;&#x4F8B;&#x5B50;&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5B9A;&#x4E49;&#x4E00;&#x4E2A;Sequential&#x6A21;&#x578B;</span>
net1 = nn.Sequential(
    nn.Linear(<span class="hljs-number">30</span>, <span class="hljs-number">40</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">40</span>, <span class="hljs-number">50</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">50</span>, <span class="hljs-number">10</span>)
)
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BBF;&#x95EE;&#x7B2C;&#x4E00;&#x5C42;&#x53C2;&#x6570;</span>
w1 = net1[<span class="hljs-number">0</span>].weight
b1 = net1[<span class="hljs-number">0</span>].bias
</code></pre>
<pre><code class="lang-python">print(w1)
</code></pre>
<pre><code>Parameter containing:
tensor([[-0.0884, -0.1303,  0.0671,  ...,  0.0682,  0.0960,  0.0014],
        [ 0.0854, -0.0569,  0.1138,  ...,  0.1613,  0.1632, -0.1122],
        [ 0.0667, -0.1749,  0.0578,  ...,  0.0363, -0.1364,  0.1396],
        ...,
        [ 0.1552, -0.1819,  0.0636,  ...,  0.1096,  0.1583,  0.1209],
        [-0.0002,  0.0771, -0.0494,  ..., -0.0410, -0.1196, -0.0689],
        [ 0.0951, -0.1096,  0.0677,  ...,  0.0062,  0.0252,  0.1204]],
       requires_grad=True)
</code></pre><p>&#x6CE8;&#x610F;&#xFF1A;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;Parameter&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x4E00;&#x4E2A;&#x7279;&#x6B8A;&#x7684;Variable&#xFF0C;&#x53EF;&#x4EE5;&#x8BBF;&#x95EE;&#x5176;<code>.data</code>&#x5C5E;&#x6027;&#x5F97;&#x5230;&#x5176;&#x4E2D;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x7136;&#x540E;&#x76F4;&#x63A5;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;Tensor&#x5BF9;&#x5176;&#x8FDB;&#x884C;&#x66FF;&#x6362;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;PyTorch&#x4E2D;&#x7684;&#x4E00;&#x4E9B;&#x968F;&#x673A;&#x6570;&#x636E;&#x751F;&#x6210;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x6BD4;&#x5982;<code>torch.randn</code>&#xFF0C;&#x5982;&#x679C;&#x8981;&#x4F7F;&#x7528;&#x66F4;&#x591A;PyTorch&#x4E2D;&#x6CA1;&#x6709;&#x7684;&#x968F;&#x673A;&#x65B9;&#x5F0F;&#xFF0C;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;numpy</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x5B9A;&#x4E49;&#x4E00;&#x4E2A;Tensor&#x76F4;&#x63A5;&#x5BF9;&#x5176;&#x8FDB;&#x884C;&#x66FF;&#x6362;</span>
net1[<span class="hljs-number">0</span>].weight.data = torch.from_numpy(np.random.uniform(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>, size=(<span class="hljs-number">40</span>, <span class="hljs-number">30</span>)))
</code></pre>
<pre><code class="lang-python">print(net1[<span class="hljs-number">0</span>].weight)
</code></pre>
<pre><code>Parameter containing:
tensor([[3.4756, 3.2131, 4.6286,  ..., 3.8106, 4.9624, 3.2060],
        [3.6706, 3.3226, 4.8829,  ..., 4.7896, 3.0099, 3.8860],
        [4.6004, 3.9054, 3.6827,  ..., 4.0814, 4.3174, 4.9711],
        ...,
        [4.0881, 3.9852, 3.9660,  ..., 4.7572, 4.7191, 3.3212],
        [3.1108, 4.8833, 3.6874,  ..., 3.2712, 4.5573, 4.9746],
        [4.8011, 3.1646, 4.4107,  ..., 3.8570, 4.2904, 3.4093]],
       dtype=torch.float64, requires_grad=True)
</code></pre><p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x8FD9;&#x4E2A;&#x53C2;&#x6570;&#x7684;&#x503C;&#x5DF2;&#x7ECF;&#x88AB;&#x6539;&#x53D8;&#x4E86;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#x5DF2;&#x7ECF;&#x88AB;&#x5B9A;&#x4E49;&#x6210;&#x4E86;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x7684;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x5F0F;&#xFF0C;&#x5982;&#x679C;&#x6A21;&#x578B;&#x4E2D;&#x67D0;&#x4E00;&#x5C42;&#x9700;&#x8981;&#x624B;&#x52A8;&#x53BB;&#x4FEE;&#x6539;&#xFF0C;&#x90A3;&#x4E48;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x4F7F;&#x7528;&#x8FD9;&#x79CD;&#x65B9;&#x5F0F;&#x53BB;&#x8BBF;&#x95EE;&#xFF0C;&#x4F46;&#x662F;&#x66F4;&#x591A;&#x7684;&#x65F6;&#x5019;&#x662F;&#x6A21;&#x578B;&#x4E2D;&#x76F8;&#x540C;&#x7684;&#x7C7B;&#x578B;&#x7684;&#x5C42;&#x90FD;&#x9700;&#x8981;&#x521D;&#x59CB;&#x5316;&#x6210;&#x76F8;&#x540C;&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x8FD9;&#x4E2A;&#x65F6;&#x5019;&#x4E00;&#x79CD;&#x66F4;&#x9AD8;&#x6548;&#x7684;&#x65B9;&#x5F0F;&#x662F;&#x4F7F;&#x7528;&#x5FAA;&#x73AF;&#x53BB;&#x8BBF;&#x95EE;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net1:
  <span class="hljs-comment"># &#x5224;&#x65AD;&#x662F;&#x5426;&#x662F;&#x7EBF;&#x6027;&#x5C42;</span>
  <span class="hljs-keyword">if</span> isinstance(layer, nn.Linear): 
    param_shape = layer.weight.shape
    <span class="hljs-comment"># &#x5B9A;&#x4E49;&#x5747;&#x503C;&#x4E3A;0&#xFF0C;&#x6807;&#x51C6;&#x5DEE;&#x4E3A;0.5&#x7684;&#x6B63;&#x6001;&#x5206;&#x5E03;</span>
    layer.weight.data = torch.from_numpy(np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.5</span>, size=param_shape))
</code></pre>
<p>&#x5BF9;&#x4E8E;Module&#x7684;&#x53C2;&#x6570;&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x5176;&#x5B9E;&#x4E5F;&#x975E;&#x5E38;&#x7B80;&#x5355;&#xFF0C;&#x5982;&#x679C;&#x76F8;&#x5BF9;&#x5176;&#x4E2D;&#x7684;&#x67D0;&#x5C42;&#x8FDB;&#x884C;&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x5411;Sequential&#x4E00;&#x6837;&#x5BF9;&#x5176;Tensor&#x8FDB;&#x884C;&#x5B9A;&#x4E49;&#xFF0C;&#x5176;&#x552F;&#x4E00;&#x4E0D;&#x540C;&#x7684;&#x5730;&#x65B9;&#x5728;&#x4E8E;&#xFF0C;&#x5982;&#x679C;&#x8981;&#x7528;&#x5FAA;&#x73AF;&#x7684;&#x65B9;&#x5F0F;&#x8BBF;&#x95EE;&#xFF0C;&#x9700;&#x8981;&#x4ECB;&#x7ECD;&#x4E24;&#x4E2A;&#x5C5E;&#x6027;&#xFF1A;<code>children</code>&#x548C;<code>modules</code>&#xFF0C;&#x5982;&#x4E0B;&#x4EE3;&#x7801;&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">sim_net</span><span class="hljs-params">(nn.Module)</span>:</span>
  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
    super(sim_net, self).__init__()
    self.l1 = nn.Sequential(
        nn.Linear(<span class="hljs-number">30</span>, <span class="hljs-number">40</span>),
        nn.ReLU()
    )

    <span class="hljs-comment"># &#x76F4;&#x63A5;&#x5BF9;&#x67D0;&#x4E00;&#x5C42;&#x521D;&#x59CB;&#x5316;</span>
    self.l1[<span class="hljs-number">0</span>].weight.data = torch.randn(<span class="hljs-number">40</span>, <span class="hljs-number">30</span>) 

    self.l2 = nn.Sequential(
        nn.Linear(<span class="hljs-number">40</span>, <span class="hljs-number">50</span>),
        nn.ReLU()
    )

    self.l3 = nn.Sequential(
        nn.Linear(<span class="hljs-number">50</span>, <span class="hljs-number">10</span>),
        nn.ReLU()
    )

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
    x = self.l1(x)
    x = self.l2(x)
    x = self.l3(x)

    <span class="hljs-keyword">return</span> x
</code></pre>
<pre><code class="lang-python">net2 = sim_net()
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># &#x8BBF;&#x95EE;children</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> net2.children():
  print(i)
</code></pre>
<pre><code>Sequential(
  (0): Linear(in_features=30, out_features=40, bias=True)
  (1): ReLU()
)
Sequential(
  (0): Linear(in_features=40, out_features=50, bias=True)
  (1): ReLU()
)
Sequential(
  (0): Linear(in_features=50, out_features=10, bias=True)
  (1): ReLU()
)
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># &#x8BBF;&#x95EE; modules</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> net2.modules():
  print(i)
</code></pre>
<pre><code>sim_net(
  (l1): Sequential(
    (0): Linear(in_features=30, out_features=40, bias=True)
    (1): ReLU()
  )
  (l2): Sequential(
    (0): Linear(in_features=40, out_features=50, bias=True)
    (1): ReLU()
  )
  (l3): Sequential(
    (0): Linear(in_features=50, out_features=10, bias=True)
    (1): ReLU()
  )
)
Sequential(
  (0): Linear(in_features=30, out_features=40, bias=True)
  (1): ReLU()
)
Linear(in_features=30, out_features=40, bias=True)
ReLU()
Sequential(
  (0): Linear(in_features=40, out_features=50, bias=True)
  (1): ReLU()
)
Linear(in_features=40, out_features=50, bias=True)
ReLU()
Sequential(
  (0): Linear(in_features=50, out_features=10, bias=True)
  (1): ReLU()
)
Linear(in_features=50, out_features=10, bias=True)
ReLU()
</code></pre><p>children&#x53EA;&#x4F1A;&#x8BBF;&#x95EE;&#x5230;&#x6A21;&#x578B;&#x5B9A;&#x4E49;&#x4E2D;&#x7684;&#x7B2C;&#x4E00;&#x5C42;&#xFF0C;&#x56E0;&#x4E3A;&#x4E0A;&#x9762;&#x7684;&#x6A21;&#x578B;&#x4E2D;&#x5B9A;&#x4E49;&#x4E86;&#x4E09;&#x4E2A;Sequential&#xFF0C;&#x6240;&#x4EE5;&#x53EA;&#x4F1A;&#x8BBF;&#x95EE;&#x5230;&#x4E09;&#x4E2A;Sequential&#xFF0C;&#x800C;modules&#x4F1A;&#x8BBF;&#x95EE;&#x5230;&#x6700;&#x540E;&#x7684;&#x7ED3;&#x6784;&#xFF0C;&#x4E0D;&#x4EC5;&#x8BBF;&#x95EE;&#x5230;&#x4E09;&#x4E2A;Sequential&#xFF0C;&#x4E5F;&#x8BBF;&#x95EE;&#x5230;Sequential&#x91CC;&#x9762;&#xFF0C;&#x8FD9;&#x5C31;&#x5BF9;&#x8FDB;&#x884C;&#x521D;&#x59CB;&#x5316;&#x975E;&#x5E38;&#x65B9;&#x4FBF;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net2.modules():
  <span class="hljs-keyword">if</span> isinstance(layer, nn.Linear):
    param_shape = layer.weight.shape
    layer.weight.data = torch.from_numpy(np.random.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.5</span>, size=param_shape))
</code></pre>
<h3 id="torchnninit">torch.nn.init</h3>
<p>&#x56E0;&#x4E3A;PyTorch&#x7075;&#x6D3B;&#xFF0C;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x5BF9;Tensor&#x8FDB;&#x884C;&#x64CD;&#x4F5C;&#x4ECE;&#x800C;&#x521D;&#x59CB;&#x5316;&#xFF0C;PyTorch&#x4E5F;&#x63D0;&#x4F9B;&#x4E86;&#x521D;&#x59CB;&#x5316;&#x5E7B;&#x672F;&#x5E2E;&#x52A9;&#x5FEB;&#x901F;&#x521D;&#x59CB;&#x5316;&#xFF0C;&#x5C31;&#x662F;<code>torch.nn.init</code>&#xFF0C;&#x5176;&#x64CD;&#x4F5C;&#x5C42;&#x4ECD;&#x7136;&#x5728;Tensor&#x4E0A;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> init
</code></pre>
<pre><code class="lang-python">print(net1[<span class="hljs-number">0</span>].weight)
</code></pre>
<pre><code>Parameter containing:
tensor([[ 0.7664,  0.1675, -0.6040,  ...,  0.0413,  1.0752, -0.1997],
        [ 0.0341, -0.2025,  0.1932,  ...,  0.5444,  1.3712, -0.0785],
        [ 0.5624, -0.2112,  0.3186,  ..., -0.2817,  0.3877, -0.8069],
        ...,
        [-0.2750,  0.7170, -0.3966,  ..., -0.5197,  0.2198,  0.9150],
        [ 0.4788, -0.3406,  0.5768,  ..., -0.1726,  0.7243, -0.2217],
        [ 0.7366,  0.2561, -0.7186,  ..., -0.5430, -0.2312,  0.1506]],
       dtype=torch.float64, requires_grad=True)
</code></pre><pre><code class="lang-python"><span class="hljs-comment"># PyTorch&#x5185;&#x7F6E;&#x5B9E;&#x73B0;&#x7684;Xavier&#x521D;&#x59CB;&#x5316;&#x65B9;&#x6CD5;</span>
init.xavier_uniform(net1[<span class="hljs-number">0</span>].weight)
</code></pre>
<pre><code>/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.
  &quot;&quot;&quot;Entry point for launching an IPython kernel.





Parameter containing:
tensor([[-0.2523, -0.0460, -0.0095,  ..., -0.0832, -0.1733,  0.2891],
        [ 0.0526, -0.1737,  0.0494,  ...,  0.0343,  0.2338,  0.0275],
        [ 0.2188,  0.2772,  0.0862,  ..., -0.1143, -0.1922, -0.0708],
        ...,
        [-0.0488,  0.2613,  0.2029,  ..., -0.2213,  0.2130, -0.2892],
        [ 0.0247, -0.1785, -0.2241,  ..., -0.0573,  0.2720,  0.0521],
        [ 0.2721,  0.2237,  0.1489,  ...,  0.1257,  0.0344, -0.1194]],
       dtype=torch.float64, requires_grad=True)
</code></pre><pre><code class="lang-python">print(net1[<span class="hljs-number">0</span>].weight)
</code></pre>
<pre><code>Parameter containing:
tensor([[-0.2523, -0.0460, -0.0095,  ..., -0.0832, -0.1733,  0.2891],
        [ 0.0526, -0.1737,  0.0494,  ...,  0.0343,  0.2338,  0.0275],
        [ 0.2188,  0.2772,  0.0862,  ..., -0.1143, -0.1922, -0.0708],
        ...,
        [-0.0488,  0.2613,  0.2029,  ..., -0.2213,  0.2130, -0.2892],
        [ 0.0247, -0.1785, -0.2241,  ..., -0.0573,  0.2720,  0.0521],
        [ 0.2721,  0.2237,  0.1489,  ...,  0.1257,  0.0344, -0.1194]],
       dtype=torch.float64, requires_grad=True)
</code></pre><p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x53C2;&#x6570;&#x5DF2;&#x7ECF;&#x88AB;&#x4FEE;&#x6539;</p>
<p><code>torch.nn.init</code>&#x63D0;&#x4F9B;&#x4E86;&#x66F4;&#x591A;&#x7684;&#x5185;&#x7F6E;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x5F0F;&#xFF0C;&#x907F;&#x514D;&#x4E86;&#x91CD;&#x590D;&#x5B9E;&#x73B0;&#x4E00;&#x4E9B;&#x76F8;&#x540C;&#x7684;&#x64CD;&#x4F5C;&#x3002;
&#x4E0A;&#x9762;&#x8BB2;&#x4E86;&#x4E24;&#x79CD;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x6CD5;&#xFF0C;&#x5176;&#x5B9E;&#x5B83;&#x4EEC;&#x672C;&#x8D28;&#x4E0A;&#x662F;&#x4E00;&#x6837;&#x7684;&#xFF0C;&#x5C31;&#x662F;&#x53BB;&#x4FEE;&#x6539;&#x67D0;&#x4E00;&#x5C42;&#x53C2;&#x6570;&#x7684;&#x5B9E;&#x9645;&#x503C;&#xFF0C;&#x800C;<code>torch.nn.init</code>&#x63D0;&#x4F9B;&#x4E86;&#x66F4;&#x591A;&#x6210;&#x719F;&#x7684;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x76F8;&#x5173;&#x7684;&#x521D;&#x59CB;&#x5316;&#x65B9;&#x5F0F;&#xFF0C;&#x975E;&#x5E38;&#x65B9;&#x4FBF;&#x3002;</p>
<h2 id="&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;">&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;</h2>
<p>&#x524D;&#x9762;&#x4ECB;&#x7ECD;&#x4E86;&#x4E09;&#x4E2A;&#x6A21;&#x578B;&#xFF0C;&#x6574;&#x4E2A;&#x5904;&#x7406;&#x7684;&#x57FA;&#x672C;&#x6D41;&#x7A0B;&#x90FD;&#x662F;&#x5B9A;&#x4E49;&#x6A21;&#x578B;&#x3001;&#x8BFB;&#x5165;&#x6570;&#x636E;&#x3001;&#x7ED9;&#x51FA;&#x635F;&#x5931;&#x51FD;&#x6570;f&#xFF0C;&#x901A;&#x8FC7;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x66F4;&#x65B0;&#x3002;PyTorch&#x63D0;&#x4F9B;&#x4E86;&#x975E;&#x5E38;&#x7B80;&#x5355;&#x7684;&#x81EA;&#x52A8;&#x6C42;&#x5BFC;&#x7B97;&#x6CD5;&#xFF0C;&#x5BF9;&#x4E8E;&#x7B80;&#x5355;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x4E5F;&#x80FD;&#x624B;&#x52A8;&#x6C42;&#x51FA;&#x53C2;&#x6570;&#x7684;&#x68AF;&#x5EA6;&#xFF0C;&#x4F46;&#x662F;&#x5BF9;&#x4E8E;&#x590D;&#x6742;&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x96BE;&#x4EE5;&#x624B;&#x52A8;&#x5B9E;&#x73B0;&#x3002;&#x8FD9;&#x91CC;&#x5C31;&#x9700;&#x8981;&#x5F15;&#x5165;<strong>&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;</strong>&#xFF0C;&#x81EA;&#x52A8;&#x6C42;&#x5BFC;&#x7684;&#x672C;&#x8D28;&#x5C31;&#x662F;&#x4E00;&#x4E2A;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;&#x3002;</p>
<p>&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;&#x662F;&#x4E00;&#x4E2A;&#x6709;&#x6548;&#x6C42;&#x89E3;&#x68AF;&#x5EA6;&#x7684;&#x7B97;&#x6CD5;&#xFF0C;&#x672C;&#x8D28;&#x4E0A;&#x662F;&#x4E00;&#x4E2A;&#x94FE;&#x5F0F;&#x7684;&#x5E94;&#x7528;&#xFF0C;&#x7136;&#x800C;&#x8FD9;&#x4E2A;&#x5982;&#x6B64;&#x7B80;&#x5355;&#x800C;&#x5374;&#x663E;&#x800C;&#x6613;&#x89C1;&#x7684;&#x65B9;&#x6CD5;&#x5374;&#x662F;Roseblatt&#x63D0;&#x51FA;&#x611F;&#x77E5;&#x673A;&#x7B97;&#x6CD5;&#x540E;&#x5C06;&#x8FD1;30&#x5E74;&#x624D;&#x88AB;&#x53D1;&#x660E;&#x548C;&#x666E;&#x53CA;&#x7684;&#x3002;</p>
<h3 id="&#x94FE;&#x5F0F;&#x6CD5;&#x5219;">&#x94FE;&#x5F0F;&#x6CD5;&#x5219;</h3>
<p>&#x6C42;&#x5BFC;&#x7684;&#x94FE;&#x5F0F;&#x6CD5;&#x5219;&#xFF08;&#x9AD8;&#x6570;&#x57FA;&#x7840;&#x5185;&#x5BB9;&#xFF09;</p>
<h3 id="&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;">&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;</h3>
<ul>
<li>&#x672C;&#x8D28;&#x4E0A;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;&#x6307;&#x793A;&#x94FE;&#x5F0F;&#x6CD5;&#x5219;&#x7684;&#x4E00;&#x4E2A;&#x5E94;&#x7528;&#x3002;</li>
<li>&#x76F4;&#x89C2;&#x4E0A;&#x770B;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7B97;&#x6CD5;&#x662F;&#x4E00;&#x4E2A;&#x4F18;&#x96C5;&#x7684;&#x5C40;&#x90E8;&#x8FC7;&#x7A0B;&#xFF0C;&#x6BCF;&#x6B21;&#x6C42;&#x5BFC;&#x6307;&#x793A;&#x5BF9;&#x5F53;&#x524D;&#x7684;&#x8FD0;&#x7B97;&#x6C42;&#x5BFC;&#xFF0C;&#x6C42;&#x89E3;&#x6BCF;&#x5C42;&#x7F51;&#x7EDC;&#x7684;&#x53C2;&#x6570;&#x90FD;&#x662F;&#x901A;&#x8FC7;&#x94FE;&#x5F0F;&#x6CD5;&#x5219;&#x5C06;&#x524D;&#x9762;&#x7684;&#x7ED3;&#x679C;&#x6C42;&#x51FA;&#x6765;&#x4E0D;&#x65AD;&#x8FED;&#x4EE3;&#x5230;&#x8FD9;&#x4E00;&#x5C42;&#xFF0C;&#x6240;&#x4EE5;&#x8BF4;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x4F20;&#x64AD;&#x8FC7;&#x7A0B;&#x3002;</li>
</ul>
<h2 id="&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x4ECB;&#x7ECD;">&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x4ECB;&#x7ECD;</h2>
<p>&#x524D;&#x9762;&#x7684;&#x90E8;&#x5206;&#x5B9E;&#x9645;&#x4E0A;&#x5DF2;&#x7ECF;&#x4ECB;&#x7ECD;&#x4E86;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x6765;&#x4F18;&#x5316;&#x6A21;&#x578B;&#xFF0C;&#x540C;&#x65F6;&#x4E5F;&#x5DF2;&#x7ECF;&#x4F7F;&#x7528;&#x8FD9;&#x4E2A;&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x8FDB;&#x884C;&#x4E0D;&#x65AD;&#x8FED;&#x4EE3;&#x6765;&#x66F4;&#x65B0;&#x6A21;&#x578B;&#x7684;&#x53C2;&#x6570;&#xFF0C;&#x4F46;&#x662F;&#x8FD8;&#x4E0D;&#x592A;&#x660E;&#x767D;&#x7B97;&#x6CD5;&#x7684;&#x672C;&#x8D28;&#xFF0C;&#x4E0B;&#x9762;&#x5177;&#x4F53;&#x4ECB;&#x7ECD;&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x7684;&#x539F;&#x7406;&#x3002;</p>
<p>&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x5BF9;&#x4E8E;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x975E;&#x5E38;&#x91CD;&#x8981;&#xFF0C;&#x9996;&#x5148;&#xFF0C;&#x5B9E;&#x9645;&#x4E0A;&#x8BAD;&#x7EC3;&#x4E00;&#x4E2A;&#x6A21;&#x578B;&#x6240;&#x8017;&#x8D39;&#x7684;&#x65F6;&#x95F4;&#x975E;&#x5E38;&#x4E45;&#xFF0C;&#x6240;&#x4EE5;&#x4E00;&#x65E6;&#x9009;&#x7528;&#x4E86;&#x9519;&#x8BEF;&#x7684;&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#xFF0C;&#x4E0D;&#x4EC5;&#x5F71;&#x54CD;&#x4E86;&#x8BAD;&#x7EC3;&#x7684;&#x6548;&#x7387;&#xFF0C;&#x540C;&#x65F6;&#x4E5F;&#x5BF9;&#x6A21;&#x578B;&#x7684;&#x7ED3;&#x679C;&#x6709;&#x7740;&#x8F83;&#x5927;&#x7684;&#x5F71;&#x54CD;&#xFF1B;&#x5176;&#x5B9E;&#xFF0C;&#x5982;&#x679C;&#x6DF1;&#x5165;&#x7406;&#x89E3;&#x5404;&#x79CD;&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x7684;&#x672C;&#x8D28;&#xFF0C;&#x8FD9;&#x4E5F;&#x5229;&#x4E8E;&#x6211;&#x4EEC;&#x66F4;&#x6709;&#x9488;&#x5BF9;&#x6027;&#x5730;&#x8C03;&#x53C2;&#xFF0C;&#x4ECE;&#x800C;&#x4F7F;&#x6A21;&#x578B;&#x8868;&#x73B0;&#x66F4;&#x597D;&#x3002;</p>
<h3 id="&#x4F18;&#x5316;&#x4E0E;&#x673A;&#x5668;&#x5B66;&#x4E60;">&#x4F18;&#x5316;&#x4E0E;&#x673A;&#x5668;&#x5B66;&#x4E60;</h3>
<p>&#x4ECE;&#x524D;&#x9762;&#x7684;&#x6A21;&#x578B;&#x53EF;&#x77E5;&#xFF0C;&#x4E00;&#x4E2A;&#x673A;&#x5236;&#x5B66;&#x4E60;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x4F1A;&#x9884;&#x5148;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;&#x635F;&#x5931;&#x51FD;&#x6570;&#xFF0C;&#x7136;&#x540E;&#x901A;&#x8FC7;&#x6700;&#x5C0F;&#x5316;&#x8FD9;&#x4E2A;&#x635F;&#x5931;&#x51FD;&#x6570;&#x6765;&#x4F18;&#x5316;&#x6A21;&#x578B;&#xFF0C;&#x800C;&#x4E4B;&#x6240;&#x4EE5;&#x53EA;&#x8003;&#x8651;&#x6700;&#x5C0F;&#x5316;&#x662F;&#x56E0;&#x4E3A;&#x4E00;&#x4E2A;&#x6700;&#x5927;&#x5316;&#x95EE;&#x9898;&#x90FD;&#x80FD;&#x591F;&#x8F6C;&#x5316;&#x6210;&#x6700;&#x5C0F;&#x5316;&#x95EE;&#x9898;&#xFF0C;&#x53EA;&#x9700;&#x8981;&#x5728;&#x6700;&#x5927;&#x5316;&#x95EE;&#x9898;&#x524D;&#x9762;&#x589E;&#x52A0;&#x4E00;&#x4E2A;&#x8D1F;&#x53F7;&#xFF0C;&#x6240;&#x4EE5;&#x6211;&#x4EEC;&#x53EA;&#x9700;&#x8981;&#x5173;&#x6CE8;&#x5982;&#x4F55;&#x6700;&#x5C0F;&#x5316;&#x4E00;&#x4E2A;&#x635F;&#x5931;&#x51FD;&#x6570;&#x3002;</p>
<h3 id="&#x4F18;&#x5316;&#x95EE;&#x9898;&#x7684;&#x6311;&#x6218;">&#x4F18;&#x5316;&#x95EE;&#x9898;&#x7684;&#x6311;&#x6218;</h3>
<p>&#x5BF9;&#x4E8E;&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x51FD;&#x6570;&#x7684;&#x4F18;&#x5316;&#x76F8;&#x5F53;&#x8BF4;&#x662F;&#x5F88;&#x7B80;&#x5355;&#x7684;&#xFF0C;&#x4F46;&#x662F;&#x5BF9;&#x4E8E;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x800C;&#x8A00;&#xFF0C;&#x4F18;&#x5316;&#x5F80;&#x5F80;&#x662F;&#x975E;&#x5E38;&#x7B80;&#x5355;&#xFF0C;&#x56E0;&#x4E3A;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x4E2D;&#x7684;&#x6A21;&#x578B;&#x53C2;&#x6570;&#x5E9E;&#x5927;&#xFF0C;&#x6A21;&#x578B;&#x590D;&#x6742;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x5BF9;&#x4E8E;&#x635F;&#x5931;&#x51FD;&#x6570;&#x8FDB;&#x884C;&#x4F18;&#x5316;&#x5F80;&#x5F80;&#x6CA1;&#x6709;&#x663E;&#x5F0F;&#x89E3;&#xFF08;&#x89E3;&#x6790;&#x89E3;&#xFF09;&#xFF0C;&#x800C;&#x9700;&#x8981;&#x4F7F;&#x7528;&#x57FA;&#x4E8E;&#x6570;&#x503C;&#x65B9;&#x6CD5;&#x7684;&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x6765;&#x627E;&#x5230;&#x8FD1;&#x4F3C;&#x503C;&#x3002;&#x8FD9;&#x7C7B;&#x4F18;&#x5316;&#x95EE;&#x9898;&#x57FA;&#x672C;&#x4E0A;&#x662F;&#x76EE;&#x524D;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x7684;&#x4E3B;&#x6D41;&#xFF0C;&#x90FD;&#x662F;&#x57FA;&#x4E8E;&#x4E0D;&#x65AD;&#x8FDB;&#x884C;&#x8FED;&#x4EE3;&#x627E;&#x5230;&#x6700;&#x4F18;&#x89E3;&#xFF0C;&#x8FD9;&#x5C31;&#x4F1A;&#x5BFC;&#x81F4;&#x4E24;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x7B2C;&#x4E00;&#x4E2A;&#x5C31;&#x662F;&#x6C42;&#x5F97;&#x4E00;&#x4E2A;&#x8F83;&#x4F18;&#x7684;&#x89E3;&#x6240;&#x9700;&#x8981;&#x7684;&#x65F6;&#x95F4;&#x76F8;&#x5BF9;&#x8F83;&#x957F;&#xFF0C;&#x540C;&#x65F6;&#x975E;&#x5E38;&#x6709;&#x53EF;&#x80FD;&#x627E;&#x5230;&#x6700;&#x4F18;&#x89E3;&#x800C;&#x975E;&#x5168;&#x5C40;&#x53D8;&#x91CF;&#x3002;</p>
<p>&#x4E0B;&#x9762;&#x4E3E;&#x4E24;&#x4E2A;&#x6700;&#x4F18;&#x89E3;&#x7684;&#x4F8B;&#x5B50;&#xFF0C;&#x4E00;&#x4E2A;&#x662F;&#x5C40;&#x90E8;&#x6700;&#x5C0F;&#x70B9;&#xFF0C;&#x4E00;&#x4E2A;&#x662F;&#x978D;&#x70B9;&#x3002;</p>
<h4 id="&#x5C40;&#x90E8;&#x6700;&#x5C0F;&#x70B9;">&#x5C40;&#x90E8;&#x6700;&#x5C0F;&#x70B9;</h4>
<p>&#x5BF9;&#x4E8E;&#x4E00;&#x4E2A;&#x51FD;&#x6570;&#x6765;&#x8BB2;&#xFF0C;&#x5168;&#x5C40;&#x6700;&#x5C0F;&#x70B9;&#x5C31;&#x662F;&#x8FD9;&#x4E2A;&#x70B9;&#x5728;&#x6574;&#x4E2A;&#x51FD;&#x6570;&#x7684;&#xFF0C;&#x800C;&#x5C40;&#x90E8;&#x6700;&#x5C0F;&#x70B9;&#x5C31;&#x662F;&#x8FD9;&#x4E2A;&#x70B9;&#x5728;&#x67D0;&#x4E2A;&#x5C40;&#x90E8;&#x6700;&#x5C0F;&#x70B9;&#x3002;</p>
<p>&#x56E0;&#x4E3A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x5C31;&#x662F;&#x57FA;&#x4E8E;&#x635F;&#x5931;&#x51FD;&#x6570;&#x7684;&#x68AF;&#x5EA6;&#x66F4;&#x65B0;&#xFF0C;&#x5982;&#x679C;&#x5230;&#x5C40;&#x90E8;&#x6700;&#x5C0F;&#x70B9;&#xFF0C;&#x68AF;&#x5EA6;&#x5C31;&#x4E3A;0&#xFF0C;&#x5C31;&#x5B58;&#x5728;&#x9677;&#x5165;&#x5C40;&#x90E8;&#x6700;&#x5C0F;&#x70B9;&#x7684;&#x60C5;&#x51B5;&#x3002;</p>
<p>&#x5982;&#xFF1A;$f(x)=2x-0.5x^2-\frac{2}{3}x^3+\frac{1}{4}x^4$</p>
<p>&#x5176;&#xFF08;-2&#xFF0C;3&#xFF09;&#x4E4B;&#x95F4;&#x7684;&#x56FE;&#x50CF;&#x5982;&#x4E0B;&#xFF0C;&#x53EF;&#x4EE5;&#x770B;&#x5230;-1&#x662F;&#x5B83;&#x7684;&#x6700;&#x5C0F;&#x70B9;&#xFF0C;&#x800C;2&#x662F;&#x5C40;&#x90E8;&#x6700;&#x5C0F;&#x70B9;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline

x = np.linspace(<span class="hljs-number">-2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">100</span>)
y = (<span class="hljs-number">2</span>*x) - (<span class="hljs-number">0.5</span>*(x**<span class="hljs-number">2</span>)) - ((<span class="hljs-number">2</span>/<span class="hljs-number">3</span>)*(x**<span class="hljs-number">3</span>)) + ((<span class="hljs-number">1</span>/<span class="hljs-number">4</span>)*(x**<span class="hljs-number">4</span>))

plt.plot(x, y, <span class="hljs-string">&apos;b-&apos;</span>)
</code></pre>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7f92edb3dfd0&gt;]
</code></pre><p><img src="output_184_1.png" alt="png"></p>
<h4 id="&#x978D;&#x70B9;">&#x978D;&#x70B9;</h4>
<p>&#x51FD;&#x6570;&#x5728;&#x978D;&#x70B9;&#x5904;&#x7684;&#x5BFC;&#x6570;&#x4E5F;&#x4E3A;0&#xFF0C;&#x4F46;&#x662F;&#x978D;&#x70B9;&#x5E76;&#x4E0D;&#x662F;&#x5468;&#x56F4;&#x6240;&#x6709;&#x70B9;&#x4E2D;&#x7684;&#x6700;&#x5C0F;&#x70B9;&#xFF0C;&#x6307;&#x793A;&#x68AF;&#x5EA6;&#x4E3A;0&#x4F7F;&#x5F97;&#x6A21;&#x578B;&#x96BE;&#x4EE5;&#x66F4;&#x65B0;&#x6240;&#x6709;&#x5BFC;&#x6570;&#x7684;&#x60C5;&#x51B5;&#x3002;&#x5728;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x4E2D;&#xFF0C;&#x56E0;&#x4E3A;&#x635F;&#x5931;&#x51FD;&#x6570;&#x975E;&#x5E38;&#x590D;&#x6742;&#xFF0C;&#x6240;&#x4EE5;&#x57FA;&#x672C;&#x4E0A;&#x78B0;&#x5230;&#x90FD;&#x662F;&#x978D;&#x70B9;&#x3002;
&#x6BD4;&#x5982;&#xFF1A;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>=</mo><msup><mi>x</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">y=x^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mrel">=</span><span class="mord"><span class="mord mathit">x</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathrm mtight">3</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span>
&#x5176;&#x5728;x=0&#x7684;&#x5730;&#x65B9;&#x68AF;&#x5EA6;&#x4E3A;0&#xFF0C;&#x662F;&#x4E00;&#x4E2A;&#x978D;&#x70B9;&#x3002;</p>
<pre><code class="lang-python">x = np.linspace(<span class="hljs-number">-2.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">100</span>)
y = x ** <span class="hljs-number">3</span>

plt.plot(x, y, <span class="hljs-string">&apos;b-&apos;</span>)
plt.plot(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-string">&apos;ro&apos;</span>)
</code></pre>
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7f92edd0dcc0&gt;]
</code></pre><p><img src="output_186_1.png" alt="png"></p>
<p>&#x7EA2;&#x70B9;&#x6240;&#x5728;&#x7684;&#x4F4D;&#x7F6E;&#x5C31;&#x662F;&#x978D;&#x70B9;&#xFF0C;&#x978D;&#x70B9;&#x68AF;&#x5EA6;&#x4E3A;0&#xFF0C;&#x5982;&#x679C;&#x9677;&#x5165;&#x978D;&#x70B9;&#xFF0C;&#x5F80;&#x5F80;&#x65E0;&#x6CD5;&#x5F97;&#x5230;&#x8F83;&#x597D;&#x7684;&#x7ED3;&#x679C;&#x3002;</p>
<h3 id="&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x2014;&#x2014;&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;">&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x2014;&#x2014;&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;</h3>
<p>&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x524D;&#x9762;&#x4E00;&#x76F4;&#x5728;&#x4F7F;&#x7528;&#x7684;&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#xFF0C;&#x4F46;&#x662F;&#x4F7F;&#x7528;&#x4E0B;&#x5C71;&#x7684;&#x4F8B;&#x5B50;&#x6765;&#x8BF4;&#x660E;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x7684;&#x539F;&#x7406;&#xFF0C;&#x5C31;&#x662F;&#x6BCF;&#x6B21;&#x90FD;&#x9009;&#x53D6;&#x4E0B;&#x964D;&#x6700;&#x5FEB;&#x7684;&#x65B9;&#x5411;&#xFF0C;&#x4E0B;&#x9762;&#x8BF4;&#x660E;&#x4E00;&#x4E0B;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x7684;&#x6570;&#x5B66;&#x539F;&#x7406;&#xFF1A;</p>
<ul>
<li>&#x5BF9;&#x4E8E;&#x635F;&#x5931;&#x51FD;&#x6570;$L(\theta)$&#xFF0C;&#x4F7F;&#x7528;&#x5176;&#x68AF;&#x5EA6;$\nabla L(\theta)$&#x6765;&#x66F4;&#x65B0;&#x53C2;&#x6570;$\theta$&#xFF0C;&#x5B66;&#x4E60;&#x7387;$\eta$,&#x90A3;&#x4E48;&#x66F4;&#x65B0;&#x516C;&#x5F0F;&#x4E3A;&#xFF1A;</li>
</ul>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>&#x3B8;</mi><mi>i</mi></msup><mo>=</mo><msup><mi>&#x3B8;</mi><mrow><mi>i</mi><mo>&#x2212;</mo><mn>1</mn></mrow></msup><mo>&#x2212;</mo><mi>&#x3B7;</mi><mi mathvariant="normal">&#x2207;</mi><mi>L</mi><mo>(</mo><msup><mi>&#x3B8;</mi><mrow><mi>i</mi><mo>&#x2212;</mo><mn>1</mn></mrow></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">\theta^i = \theta^{i-1} - \eta\nabla L(\theta^{i-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.824664em;"></span><span class="strut bottom" style="height:1.0746639999999998em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathit mtight">i</span><span class="mbin mtight">&#x2212;</span><span class="mord mathrm mtight">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">&#x2212;</span><span class="mord mathit" style="margin-right:0.03588em;">&#x3B7;</span><span class="mord mathrm">&#x2207;</span><span class="mord mathit">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathit mtight">i</span><span class="mbin mtight">&#x2212;</span><span class="mord mathrm mtight">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span></span></span></span></p>
<ul>
<li><p>&#x91CD;&#x65B0;&#x8868;&#x8FF0;&#x4E00;&#x4E0B;&#x95EE;&#x9898;&#xFF0C;&#x6211;&#x4EEC;&#x5E0C;&#x671B;&#x6C42;&#x89E3;:
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>&#x3B8;</mi><mo>&#x2217;</mo></msup><mo>=</mo><mi>a</mi><mi>r</mi><msub><mi>g</mi><mrow><mi>&#x3B8;</mi></mrow></msub><mi>m</mi><mi>i</mi><mi>n</mi><mi>L</mi><mo>(</mo><mi>&#x3B8;</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\theta^*=arg_{\theta}minL(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mbin mtight">&#x2217;</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight" style="margin-right:0.02778em;">&#x3B8;</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit">m</span><span class="mord mathit">i</span><span class="mord mathit">n</span><span class="mord mathit">L</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="mclose">)</span></span></span></span></p>
</li>
<li><p>&#x5C31;&#x662F;&#x5E0C;&#x671B;&#x66F4;&#x65B0;&#x53C2;&#x6570;&#x540E;&#x6709;&#x4EE5;&#x4E0B;&#x7ED3;&#x679C;&#xFF1A;
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mo>(</mo><msub><mi>&#x3B8;</mi><mn>0</mn></msub><mo>)</mo><mo>&gt;</mo><mo>(</mo><msub><mi>&#x3B8;</mi><mn>1</mn></msub><mo>)</mo><mo>&gt;</mo><mo>(</mo><msub><mi>&#x3B8;</mi><mn>2</mn></msub><mo>)</mo><mo>&gt;</mo><mo>&#x2219;</mo><mo>&#x2219;</mo><mo>&#x2219;</mo></mrow><annotation encoding="application/x-tex">L(\theta_0)&gt;(\theta_1)&gt;(\theta_2)&gt;\bullet\bullet\bullet</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span><span class="mrel">&gt;</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span><span class="mrel">&gt;</span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span><span class="mrel">&gt;</span><span class="mord">&#x2219;</span><span class="mbin">&#x2219;</span><span class="mord">&#x2219;</span></span></span></span></p>
</li>
</ul>
<p><strong>&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x7684;&#x95EE;&#x9898;&#xFF1A;</strong>
&#x5728;&#x51FD;&#x6570;&#x7684;&#x7AD6;&#x76F4;&#x65B9;&#x5411;&#xFF0C;&#x68AF;&#x5EA6;&#x975E;&#x5E38;&#x5927;&#xFF0C;&#x5728;&#x6C34;&#x5E73;&#x65B9;&#x5411;&#xFF0C;&#x68AF;&#x5EA6;&#x76F8;&#x5BF9;&#x8F83;&#x5C0F;&#xFF0C;&#x6240;&#x4EE5;&#x5728;&#x8BBE;&#x7F6E;&#x5B66;&#x4E60;&#x7387;&#x7684;&#x65F6;&#x5019;&#x4E0D;&#x80FD;&#x8BBE;&#x7F6E;&#x592A;&#x5927;&#xFF0C;&#x4E3A;&#x4E86;&#x9632;&#x6B62;&#x7AD6;&#x76F4;&#x65B9;&#x5411;&#x53C2;&#x6570;&#x66F4;&#x65B0;&#x592A;&#x5FEB;&#xFF0C;&#x8FD9;&#x6837;&#x8F83;&#x5C0F;&#x7684;&#x5B66;&#x4E60;&#x7387;&#x53C8;&#x5BFC;&#x81F4;&#x6C34;&#x5E73;&#x65B9;&#x5411;&#x4E0A;&#x53C2;&#x6570;&#x5728;&#x66F4;&#x65B0;&#x7684;&#x65F6;&#x5019;&#x8FC7;&#x4E8E;&#x7F13;&#x6162;&#xFF0C;&#x6240;&#x4EE5;&#x5BFC;&#x81F4;&#x6700;&#x7EC8;&#x6536;&#x655B;&#x975E;&#x5E38;&#x6162;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># &#x4ECE;0&#x5F00;&#x59CB;&#x5B9E;&#x73B0;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torchvision.datasets <span class="hljs-keyword">import</span> MNIST <span class="hljs-comment"># &#x5BFC;&#x5165;pytorch&#x4E2D;&#x5185;&#x7F6E;&#x7684;mnist&#x6570;&#x636E;&#x96C6;</span>
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">data_tf</span><span class="hljs-params">(x)</span>:</span>
  <span class="hljs-comment"># &#x5C06;&#x6570;&#x636E;&#x53D8;&#x5230;0~1&#x4E4B;&#x95F4;</span>
  x = np.array(x, dtype=<span class="hljs-string">&apos;float32&apos;</span>) / <span class="hljs-number">255</span>

  <span class="hljs-comment"># &#x6807;&#x51C6;&#x5316;</span>
  x = (x - <span class="hljs-number">0.5</span>) / <span class="hljs-number">0.5</span>

  <span class="hljs-comment"># &#x62C9;&#x5E73;</span>
  x = x.reshape((<span class="hljs-number">-1</span>,))
  x = torch.from_numpy(x)

  <span class="hljs-keyword">return</span> x

<span class="hljs-comment"># &#x8F7D;&#x5165;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x7533;&#x660E;&#x5B9A;&#x4E49;&#x7684;&#x6570;&#x636E;&#x53D8;&#x6362;</span>
train_set = MNIST(<span class="hljs-string">&apos;./data&apos;</span>, train=<span class="hljs-keyword">True</span>, transform=data_tf, download=<span class="hljs-keyword">True</span>)
test_set = MNIST(<span class="hljs-string">&apos;./data&apos;</span>, train=<span class="hljs-keyword">False</span>, transform=data_tf, download=<span class="hljs-keyword">True</span>)

<span class="hljs-comment"># &#x5B9A;&#x4E49;loss&#x51FD;&#x6570;</span>
criterion = nn.CrossEntropyLoss()
</code></pre>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sgd_update</span><span class="hljs-params">(parameters, lr)</span>:</span>
  <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> parameters:
    param.data = param.data - lr * param.grad.data
</code></pre>
<p>&#x53EF;&#x4EE5;&#x5C06;batch size&#x5148;&#x8BBE;&#x7F6E;&#x4E3A;1&#xFF0C;&#x770B;&#x770B;&#x4EC0;&#x4E48;&#x4EC0;&#x4E48;&#x6548;&#x679C;</p>
<pre><code class="lang-python">train_data = DataLoader(train_set, batch_size=<span class="hljs-number">1</span>, shuffle=<span class="hljs-keyword">True</span>)
<span class="hljs-comment"># &#x4F7F;&#x7528;Sequential&#x5B9A;&#x4E49;3&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</span>
net = nn.Sequential(
    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">200</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">200</span>, <span class="hljs-number">10</span>)
)

<span class="hljs-comment"># &#x5F00;&#x59CB;&#x8BAD;&#x7EC3;</span>
loss1 = []
idx = <span class="hljs-number">0</span>

start = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x5F00;&#x59CB;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):
  train_loss = <span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> im, label <span class="hljs-keyword">in</span> train_data:
    im = Variable(im)
    label = Variable(label)

    <span class="hljs-comment"># forward pass</span>
    out = net(im)
    loss = criterion(out, label)

    <span class="hljs-comment"># backward pass</span>
    net.zero_grad()
    loss.backward()
    sgd_update(net.parameters(), <span class="hljs-number">1e-2</span>) <span class="hljs-comment"># &#x4F7F;&#x7528;&#x5B66;&#x4E60;&#x7387;&#x4E3A;0.01</span>

    <span class="hljs-comment"># &#x8BB0;&#x5F55;&#x8BEF;&#x5DEE;</span>
    train_loss += loss.item()
    <span class="hljs-keyword">if</span> idx % <span class="hljs-number">30</span> == <span class="hljs-number">0</span>:
      loss1.append(loss.item())

    idx += <span class="hljs-number">1</span>

  print(<span class="hljs-string">&apos;epoch:{}, Train Loss:{:.6f}&apos;</span>.format(e, train_loss / len(train_data)))

end = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x7ED3;&#x675F;</span>
print(<span class="hljs-string">&apos;&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;{:.5f}s&apos;</span>.format(end - start))
</code></pre>
<pre><code>epoch:0, Train Loss:0.350013
epoch:1, Train Loss:0.213540
epoch:2, Train Loss:0.173738
epoch:3, Train Loss:0.154615
epoch:4, Train Loss:0.141261
&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;413.57024s
</code></pre><pre><code class="lang-python">x_axis = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, len(loss1), endpoint=<span class="hljs-keyword">True</span>)
plt.semilogy(x_axis, loss1, label=<span class="hljs-string">&apos;batch_size=1&apos;</span>)
plt.legend(loc=<span class="hljs-string">&apos;best&apos;</span>)
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f9c40bc13c8&gt;
</code></pre><p><img src="output_194_1.png" alt="png"></p>
<p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x3002;loss&#x5728;&#x5267;&#x70C8;&#x9707;&#x8361;&#xFF0C;&#x56E0;&#x4E3A;&#x6BCF;&#x4E00;&#x6B21;&#x90FD;&#x53EA;&#x5BF9;&#x4E00;&#x4E2A;&#x6837;&#x672C;&#x70B9;&#x505A;&#x8BA1;&#x7B97;&#xFF0C;&#x6BCF;&#x4E00;&#x5C42;&#x7684;&#x68AF;&#x5EA6;&#x90FD;&#x5177;&#x6709;&#x5F88;&#x9AD8;&#x7684;&#x968F;&#x673A;&#x6027;&#xFF0C;&#x800C;&#x4E14;&#x8017;&#x8D39;&#x4E86;&#x5927;&#x91CF;&#x7684;&#x65F6;&#x95F4;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-comment"># batch_size = 64</span>
train_data = DataLoader(train_set, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-keyword">True</span>)
<span class="hljs-comment"># &#x4F7F;&#x7528;Sequential&#x5B9A;&#x4E49;3&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</span>
net = nn.Sequential(
    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">200</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">200</span>, <span class="hljs-number">10</span>)
)

<span class="hljs-comment"># &#x5F00;&#x59CB;&#x8BAD;&#x7EC3;</span>
loss2 = []
idx = <span class="hljs-number">0</span>

start = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x5F00;&#x59CB;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):
  train_loss = <span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> im, label <span class="hljs-keyword">in</span> train_data:
    im = Variable(im)
    label = Variable(label)

    <span class="hljs-comment"># forward pass</span>
    out = net(im)
    loss = criterion(out, label)

    <span class="hljs-comment"># backward pass</span>
    net.zero_grad()
    loss.backward()
    sgd_update(net.parameters(), <span class="hljs-number">1e-2</span>) <span class="hljs-comment"># &#x4F7F;&#x7528;&#x5B66;&#x4E60;&#x7387;&#x4E3A;0.01</span>

    <span class="hljs-comment"># &#x8BB0;&#x5F55;&#x8BEF;&#x5DEE;</span>
    train_loss += loss.item()
    <span class="hljs-keyword">if</span> idx % <span class="hljs-number">30</span> == <span class="hljs-number">0</span>:
      loss2.append(loss.item())

    idx += <span class="hljs-number">1</span>

  print(<span class="hljs-string">&apos;epoch:{}, Train Loss:{:.6f}&apos;</span>.format(e, train_loss / len(train_data)))

end = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x7ED3;&#x675F;</span>
print(<span class="hljs-string">&apos;&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;{:.5f}s&apos;</span>.format(end - start))
</code></pre>
<pre><code>epoch:0, Train Loss:0.738503
epoch:1, Train Loss:0.365645
epoch:2, Train Loss:0.319686
epoch:3, Train Loss:0.291246
epoch:4, Train Loss:0.268030
&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;35.22056s
</code></pre><pre><code class="lang-python">x_axis = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, len(loss2), endpoint=<span class="hljs-keyword">True</span>)
plt.semilogy(x_axis, loss2, label=<span class="hljs-string">&apos;batch_size=64&apos;</span>)
plt.legend(loc=<span class="hljs-string">&apos;best&apos;</span>)
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7f9c380e7cf8&gt;
</code></pre><p><img src="output_197_1.png" alt="png"></p>
<p>&#x901A;&#x8FC7;&#x4E0A;&#x9762;&#x7ED3;&#x679C;&#x53EF;&#x4EE5;&#x770B;&#x51FA;loss&#x6CA1;&#x6709;batch&#x7B49;&#x4E8E;1&#x9707;&#x8361;&#x90A3;&#x4E48;&#x5267;&#x70C8;&#xFF0C;&#x540C;&#x65F6;&#x4E5F;&#x53EF;&#x4EE5;&#x964D;&#x5230;&#x4E00;&#x5B9A;&#x7684;&#x7A0B;&#x5EA6;&#xFF0C;&#x65F6;&#x95F4;&#x4E0A;&#x4E5F;&#x6BD4;&#x4E4B;&#x524D;&#x5FEB;&#x4E50;&#x5F88;&#x591A;&#xFF0C;&#x56E0;&#x4E3A;&#x6309;&#x7167;batch&#x7684;&#x6570;&#x636E;&#x91CF;&#x8BA1;&#x7B97;&#x4E0A;&#x66F4;&#x5FEB;&#xFF0C;&#x540C;&#x65F6;&#x68AF;&#x5EA6;&#x5BF9;&#x6BD4;batch_size=1&#x7684;&#x60C5;&#x51B5;&#x4E5F;&#x66F4;&#x63A5;&#x8FD1;&#x771F;&#x5B9E;&#x7684;&#x68AF;&#x5EA6;&#xFF0C;&#x6240;&#x4EE5;batcu_size&#x7684;&#x503C;&#x8D8A;&#x5927;&#xFF0C;&#x68AF;&#x5EA6;&#x66F4;&#x7A33;&#x5B9A;&#xFF0C;&#x800C;batch_size&#x8D8A;&#x5C0F;&#xFF0C;&#x68AF;&#x5EA6;&#x5177;&#x6709;&#x8D8A;&#x9AD8;&#x7684;&#x968F;&#x673A;&#x6027;&#xFF0C;&#x8FD9;&#x91CC;batch_size=64&#xFF0C;&#x53EF;&#x4EE5;&#x770B;&#x5230;loss&#x4ECD;&#x7136;&#x5B58;&#x5728;&#x9707;&#x8361;&#xFF0C;&#x4F46;&#x8FD9;&#x5E76;&#x4E48;&#x6709;&#x5173;&#x7CFB;&#xFF0C;&#x5982;&#x679C;batch_size&#x592A;&#x5927;&#xFF0C;&#x5BF9;&#x4E8E;&#x5185;&#x5B58;&#x7684;&#x9700;&#x6C42;&#x5C31;&#x66F4;&#x9AD8;&#xFF0C;&#x540C;&#x65F6;&#x4E5F;&#x4E0D;&#x5229;&#x4E8E;&#x8DF3;&#x51FA;&#x5C40;&#x90E8;&#x6781;&#x5C0F;&#x70B9;&#xFF0C;&#x6240;&#x4EE5;&#x73B0;&#x5728;&#x666E;&#x904D;&#x4F7F;&#x7528;batch&#x7684;&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#xFF0C;&#x800C;batch&#x7684;&#x5927;&#x5C0F;&#x57FA;&#x4E8E;&#x5B9E;&#x9645;&#x60C5;&#x51B5;&#x8FDB;&#x884C;&#x8003;&#x8651;&#x3002;</p>
<p>&#x4E0B;&#x9762;&#x8C03;&#x9AD8;&#x5B66;&#x4E60;&#x7387;&#xFF0C;&#x770B;&#x770B;&#x6709;&#x4EC0;&#x4E48;&#x6837;&#x7684;&#x7ED3;&#x679C;&#x3002;</p>
<pre><code class="lang-python">train_data = DataLoader(train_set, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-keyword">True</span>)
<span class="hljs-comment"># &#x4F7F;&#x7528;Sequential&#x5B9A;&#x4E49;3&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</span>
net = nn.Sequential(
    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">200</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">200</span>, <span class="hljs-number">10</span>)
)

<span class="hljs-comment"># &#x5F00;&#x59CB;&#x8BAD;&#x7EC3;</span>
loss3 = []
idx = <span class="hljs-number">0</span>

start = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x5F00;&#x59CB;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):
  train_loss = <span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> im, label <span class="hljs-keyword">in</span> train_data:
    im = Variable(im)
    label = Variable(label)

    <span class="hljs-comment"># forward pass</span>
    out = net(im)
    loss = criterion(out, label)

    <span class="hljs-comment"># backward pass</span>
    net.zero_grad()
    loss.backward()
    sgd_update(net.parameters(), <span class="hljs-number">1</span>) <span class="hljs-comment"># &#x4F7F;&#x7528;&#x5B66;&#x4E60;&#x7387;&#x4E3A;1</span>

    <span class="hljs-comment"># &#x8BB0;&#x5F55;&#x8BEF;&#x5DEE;</span>
    train_loss += loss.item()
    <span class="hljs-keyword">if</span> idx % <span class="hljs-number">30</span> == <span class="hljs-number">0</span>:
      loss3.append(loss.item())

    idx += <span class="hljs-number">1</span>

  print(<span class="hljs-string">&apos;epoch:{}, Train Loss:{:.6f}&apos;</span>.format(e, train_loss / len(train_data)))

end = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x7ED3;&#x675F;</span>
print(<span class="hljs-string">&apos;&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;{:.5f}s&apos;</span>.format(end - start))
</code></pre>
<pre><code>epoch:0, Train Loss:2.444475
epoch:1, Train Loss:2.306518
epoch:2, Train Loss:2.304941
epoch:3, Train Loss:2.304975
epoch:4, Train Loss:2.305141
&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;34.25221s
</code></pre><pre><code class="lang-python">x_axis = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, len(loss3), endpoint=<span class="hljs-keyword">True</span>)
plt.semilogy(x_axis, loss3, label=<span class="hljs-string">&apos;lr = 1&apos;</span>)
plt.legend(loc=<span class="hljs-string">&apos;best&apos;</span>)
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fe813b96438&gt;
</code></pre><p><img src="output_200_1.png" alt="png"></p>
<p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#xFF0C;&#x5B66;&#x4E60;&#x7387;&#x592A;&#x5927;&#x4F1A;&#x4F7F;&#x635F;&#x5931;&#x51FD;&#x6570;&#x4E0D;&#x65AD;&#x56DE;&#x8DF3;&#xFF0C;&#x4ECE;&#x800C;&#x65E0;&#x6CD5;&#x8BA9;&#x635F;&#x5931;&#x51FD;&#x6570;&#x8F83;&#x597D;&#x964D;&#x4F4E;&#xFF0C;&#x6240;&#x4EE5;&#x4E00;&#x822C;&#x4F7F;&#x7528;&#x6BD4;&#x8F83;&#x5C0F;&#x7684;&#x5B66;&#x4E60;&#x7387;&#x3002;</p>
<p>&#x5B9E;&#x9645;&#x4E0A;&#x5E76;&#x4E0D;&#x9700;&#x8981;&#x81EA;&#x5DF1;&#x9020;&#x8F6E;&#x5B50;&#xFF0C;&#x56E0;&#x4E3A;pytorch&#x4E2D;&#x5DF2;&#x7ECF;&#x5185;&#x7F6E;&#x4E86;&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#xFF0C;&#x800C;&#x4E14;&#x4E4B;&#x524D;&#x4E00;&#x76F4;&#x5728;&#x4F7F;&#x7528;&#xFF0C;&#x4E0B;&#x9762;&#x4F7F;&#x7528;pytorch&#x81EA;&#x5E26;&#x7684;&#x4F18;&#x5316;&#x5668;&#x6765;&#x5B9E;&#x73B0;&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#xFF1A;</p>
<pre><code class="lang-python">train_data = DataLoader(train_set, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-keyword">True</span>)
<span class="hljs-comment"># &#x4F7F;&#x7528;Sequential&#x5B9A;&#x4E49;3&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</span>
net = nn.Sequential(
    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">200</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">200</span>, <span class="hljs-number">10</span>)
)

optimizer = torch.optim.SGD(net.parameters(), <span class="hljs-number">1e-2</span>)
<span class="hljs-comment"># &#x5F00;&#x59CB;&#x8BAD;&#x7EC3;</span>
start = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x5F00;&#x59CB;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):
  train_loss = <span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> im, label <span class="hljs-keyword">in</span> train_data:
    im = Variable(im)
    label = Variable(label)

    <span class="hljs-comment"># forward pass</span>
    out = net(im)
    loss = criterion(out, label)

    <span class="hljs-comment"># backward pass</span>
    net.zero_grad()
    loss.backward()
    optimizer.step()

    <span class="hljs-comment"># &#x8BB0;&#x5F55;&#x8BEF;&#x5DEE;</span>
    train_loss += loss.item()

  print(<span class="hljs-string">&apos;epoch:{}, Train Loss:{:.6f}&apos;</span>.format(e, train_loss / len(train_data)))

end = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x7ED3;&#x675F;</span>
print(<span class="hljs-string">&apos;&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;{:.5f}s&apos;</span>.format(end - start))
</code></pre>
<pre><code>epoch:0, Train Loss:0.742786
epoch:1, Train Loss:0.364865
epoch:2, Train Loss:0.319970
epoch:3, Train Loss:0.292502
epoch:4, Train Loss:0.270560
&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;33.03524s
</code></pre><h3 id="&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x2014;&#x2014;&#x52A8;&#x91CF;&#x6CD5;">&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x2014;&#x2014;&#x52A8;&#x91CF;&#x6CD5;</h3>
<p>&#x52A8;&#x91CF;&#x6CD5;&#xFF08;&#x53C8;&#x79F0;&#x4E3A;&#x81EA;&#x9002;&#x5E94;&#x5B66;&#x4E60;&#x7387;&#x4F18;&#x5316;&#x7B97;&#x6CD5;&#x3002;&#xFF09;&#x7684;&#x63D0;&#x51FA;&#x662F;&#x4E3A;&#x4E86;&#x89E3;&#x51B3;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x7684;&#x95EE;&#x9898;&#x7684;&#xFF0C;&#x5728;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x4E0B;&#x505A;&#x4E86;&#x4E00;&#x4E9B;&#x4FEE;&#x6539;&#xFF1A;</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>&#x3BD;</mi><mi>i</mi></msub><mo>=</mo><mi>&#x3B3;</mi><msub><mi>&#x3BD;</mi><mrow><mi>i</mi><mo>&#x2212;</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>&#x3B7;</mi><mi mathvariant="normal">&#x2207;</mi><mi>L</mi><mo>(</mo><mi>&#x3B8;</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\nu_i=\gamma \nu_{i-1}+\eta \nabla L(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">i</span><span class="mbin mtight">&#x2212;</span><span class="mord mathrm mtight">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.03588em;">&#x3B7;</span><span class="mord mathrm">&#x2207;</span><span class="mord mathit">L</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="mclose">)</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>&#x3B8;</mi><mi>i</mi></msub><mo>=</mo><msub><mi>&#x3B8;</mi><mrow><mi>i</mi><mo>&#x2212;</mo><mn>1</mn></mrow></msub><mo>&#x2212;</mo><msub><mi>&#x3BD;</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\theta_i=\theta_{i-1}-\nu_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.902771em;vertical-align:-0.208331em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">&#x3B8;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">i</span><span class="mbin mtight">&#x2212;</span><span class="mord mathrm mtight">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">&#x2212;</span><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathit mtight">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span></span></span></span>
&#x5176;&#x4E2D;$\nu_i$&#x662F;&#x5F53;&#x524D;&#x901F;&#x5EA6;&#xFF0C;$\gamma$&#x662F;&#x52A8;&#x91CF;&#x53C2;&#x6570;&#xFF0C;&#x662F;&#x4E00;&#x4E2A;&#x5C0F;&#x4E8E;1&#x7684;&#x6B63;&#x6570;&#xFF0C;$\eta$&#x662F;&#x5B66;&#x4E60;&#x7387;&#x3002;</p>
<p>&#x76F8;&#x5F53;&#x4E8E;&#x6BCF;&#x6B21;&#x5728;&#x8FDB;&#x884C;&#x53C2;&#x6570;&#x66F4;&#x65B0;&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x90FD;&#x4F1A;&#x5C06;&#x4E4B;&#x524D;&#x7684;&#x901F;&#x5EA6;&#x8003;&#x8651;&#x8FDB;&#x6765;&#xFF0C;&#x6BCF;&#x4E2A;&#x53C2;&#x6570;&#x5728;&#x5404;&#x4E2A;&#x65B9;&#x5411;&#x4E0A;&#x7684;&#x79FB;&#x52A8;&#x5E45;&#x5EA6;&#x4E0D;&#x4EC5;&#x4EC5;&#x53D6;&#x51B3;&#x4E0E;&#x5F53;&#x524D;&#x7684;&#x68AF;&#x5EA6;&#xFF0C;&#x8FD8;&#x53D6;&#x51B3;&#x4E8E;&#x8FC7;&#x53BB;&#x5404;&#x4E2A;&#x68AF;&#x5EA6;&#x5728;&#x5404;&#x4E2A;&#x65B9;&#x5411;&#x4E0A;&#x662F;&#x5426;&#x4E00;&#x81F4;&#xFF0C;&#x5982;&#x679C;&#x4E00;&#x4E2A;&#x68AF;&#x5EA6;&#x4E00;&#x76F4;&#x6CBF;&#x7740;&#x5F53;&#x524D;&#x65B9;&#x5411;&#x8FDB;&#x884C;&#x66F4;&#x65B0;&#xFF0C;&#x90A3;&#x4E48;&#x66F4;&#x65B0;&#x7684;&#x5E45;&#x5EA6;&#x5C31;&#x4F1A;&#x8D8A;&#x6765;&#x8D8A;&#x5927;&#xFF0C;&#x5982;&#x679C;&#x4E00;&#x4E2A;&#x68AF;&#x5EA6;&#x5728;&#x4E00;&#x4E2A;&#x65B9;&#x5411;&#x4E0A;&#x4E0D;&#x65AD;&#x53D8;&#x5316;&#xFF0C;&#x90A3;&#x4E48;&#x5176;&#x66F4;&#x65B0;&#x5E45;&#x5EA6;&#x5C31;&#x4F1A;&#x88AB;&#x8870;&#x51CF;&#xFF0C;&#x8FD9;&#x6837;&#x5C31;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x8F83;&#x5927;&#x7684;&#x5B66;&#x4E60;&#x7387;&#xFF0C;&#x4F7F;&#x5F97;&#x6536;&#x655B;&#x66F4;&#x5FEB;&#x3002;</p>
<p>&#x6BD4;&#x5982;&#xFF1A;&#x68AF;&#x5EA6;&#x6BCF;&#x6B21;&#x90FD;&#x7B49;&#x4E8E;g&#xFF0C;&#x800C;&#x4E14;&#x65B9;&#x5411;&#x90FD;&#x76F8;&#x540C;&#xFF0C;&#x90A3;&#x4E48;&#x52A8;&#x91CF;&#x6CD5;&#x5728;&#x8BE5;&#x65B9;&#x5411;&#x4E0A;&#x4F7F;&#x53C2;&#x6570;&#x52A0;&#x901F;&#x79FB;&#x52A8;&#xFF0C;&#x6709;&#x4E0B;&#x5217;&#x516C;&#x5F0F;&#xFF1A;
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>&#x3BD;</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">
\nu_0=0
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.79444em;vertical-align:-0.15em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mord mathrm">0</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>&#x3BD;</mi><mn>1</mn></msub><mo>=</mo><mi>&#x3B3;</mi><msub><mi>&#x3BD;</mi><mn>0</mn></msub><mo>+</mo><mi>&#x3B7;</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">
\nu_1=\gamma \nu_0+\eta g
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.58333em;"></span><span class="strut bottom" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.03588em;">&#x3B7;</span><span class="mord mathit" style="margin-right:0.03588em;">g</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>&#x3BD;</mi><mn>2</mn></msub><mo>=</mo><mi>&#x3B3;</mi><msub><mi>&#x3BD;</mi><mn>1</mn></msub><mo>+</mo><mi>&#x3B7;</mi><mi>g</mi><mo>=</mo><mo>(</mo><mn>1</mn><mo>+</mo><mi>&#x3B3;</mi><mo>)</mo><mi>&#x3B7;</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">
\nu_2=\gamma \nu_1+\eta g=(1+\gamma)\eta g
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.03588em;">&#x3B7;</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mrel">=</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="mclose">)</span><span class="mord mathit" style="margin-right:0.03588em;">&#x3B7;</span><span class="mord mathit" style="margin-right:0.03588em;">g</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>&#x3BD;</mi><mn>2</mn></msub><mo>=</mo><mi>&#x3B3;</mi><msub><mi>&#x3BD;</mi><mn>2</mn></msub><mo>+</mo><mi>&#x3B7;</mi><mi>g</mi><mo>=</mo><mo>(</mo><mn>1</mn><mo>+</mo><mi>&#x3B3;</mi><mo>+</mo><msup><mi>&#x3B3;</mi><mn>2</mn></msup><mo>)</mo><mi>&#x3B7;</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">
\nu_2=\gamma \nu_2+\eta g=(1+\gamma+\gamma^2)\eta g
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8641079999999999em;"></span><span class="strut bottom" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.03588em;">&#x3B7;</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mrel">=</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="mbin">+</span><span class="mord"><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="msupsub"><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mclose">)</span><span class="mord mathit" style="margin-right:0.03588em;">&#x3B7;</span><span class="mord mathit" style="margin-right:0.03588em;">g</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>&#x3BD;</mi><mrow><mo>+</mo><mi mathvariant="normal">&#x221E;</mi></mrow></msub><mo>=</mo><mo>(</mo><mn>1</mn><mo>+</mo><mi>&#x3B3;</mi><mo>+</mo><msup><mi>&#x3B3;</mi><mn>2</mn></msup><mo>+</mo><msup><mi>&#x3B3;</mi><mn>3</mn></msup><mo>+</mo><mo>&#x2219;</mo><mo>&#x2219;</mo><mo>&#x2219;</mo><mo>)</mo><mi>&#x3B7;</mi><mi>g</mi><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mn>1</mn><mo>&#x2212;</mo><mi>&#x3B3;</mi></mrow></mfrac><mi>&#x3B7;</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">
\nu_{+\infty}=(1+\gamma+\gamma^2+\gamma^3+\bullet\bullet\bullet)\eta g=\frac{1}{1-\gamma}\eta g
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.20188em;vertical-align:-0.8804400000000001em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.06366em;">&#x3BD;</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.06366em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mtight">+</span><span class="mord mathrm mtight">&#x221E;</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mopen">(</span><span class="mord mathrm">1</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="mbin">+</span><span class="mord"><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="msupsub"><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathrm mtight">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">+</span><span class="mord"><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="msupsub"><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord mathrm mtight">3</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mbin">+</span><span class="mord">&#x2219;</span><span class="mbin">&#x2219;</span><span class="mord">&#x2219;</span><span class="mclose">)</span><span class="mord mathit" style="margin-right:0.03588em;">&#x3B7;</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="mopen sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.6860000000000002em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm">1</span><span class="mbin">&#x2212;</span><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span><span class="mclose sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mord mathit" style="margin-right:0.03588em;">&#x3B7;</span><span class="mord mathit" style="margin-right:0.03588em;">g</span></span></span></span></span></p>
<p>&#x5982;&#x679C;&#x6211;&#x4EEC;&#x628A;$\gamma$&#x5B9A;&#x4E3A;0.9&#xFF0C;&#x90A3;&#x4E48;&#x66F4;&#x65B0;&#x5E45;&#x5EA6;&#x7684;&#x5CF0;&#x503C;&#x5C31;&#x662F;&#x539F;&#x672C;&#x68AF;&#x5EA6;&#x6210;&#x5B66;&#x4E60;&#x7387;&#x7684;10&#x500D;&#x3002;</p>
<p>&#x52A8;&#x91CF;&#x6CD5;&#x5C31;&#x4EFF;&#x4F5B;&#x5728;&#x9AD8;&#x5761;&#x4E0A;&#x63A8;&#x4E00;&#x4E2A;&#x7403;&#xFF0C;&#x7403;&#x5728;&#x5411;&#x4E0B;&#x6EDA;&#x52A8;&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#x79EF;&#x7D2F;&#x4E86;&#x52A8;&#x91CF;&#xFF0C;&#x5728;&#x9014;&#x4E2D;&#x4E5F;&#x53D8;&#x5F97;&#x8D8A;&#x6765;&#x8D8A;&#x5FEB;&#xFF0C;&#x6700;&#x540E;&#x8FBE;&#x5230;&#x4E86;&#x5CF0;&#x503C;&#xFF0C;&#x5BF9;&#x5E94;&#x4E8E;&#x7B97;&#x6CD5;&#x4E2D;&#x5C31;&#x662F;&#xFF0C;&#x52A8;&#x91CF;&#x9879;&#x4F1A;&#x6CBF;&#x7740;&#x68AF;&#x5EA6;&#x6307;&#x5411;&#x65B9;&#x5411;&#x76F8;&#x540C;&#x7684;&#x65B9;&#x5411;&#x4E0D;&#x65AD;&#x589E;&#x5927;&#xFF0C;&#x5BF9;&#x4E8E;&#x68AF;&#x5EA6;&#x65B9;&#x5411;&#x6539;&#x53D8;&#x7684;&#x65B9;&#x5411;&#x9010;&#x6E10;&#x51CF;&#x5C0F;&#xFF0C;&#x5F97;&#x5230;&#x4E86;&#x66F4;&#x5FEB;&#x7684;&#x6536;&#x655B;&#x901F;&#x5EA6;&#x4EE5;&#x53CA;&#x66F4;&#x5C0F;&#x7684;&#x9707;&#x8361;&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sgd_momentum</span><span class="hljs-params">(parameters, vs, lr, gamma)</span>:</span>
  <span class="hljs-keyword">for</span> param, v <span class="hljs-keyword">in</span> zip(parameters, vs):
    v[:] = gamma * v + lr * param.grad.data
    param.data = param.data - v
</code></pre>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torchvision.datasets <span class="hljs-keyword">import</span> MNIST
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
%matplotlib inline

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">data_tf</span><span class="hljs-params">(x)</span>:</span>
  x = np.array(x, dtype=<span class="hljs-string">&apos;float32&apos;</span>) / <span class="hljs-number">255</span>
  x = (x - <span class="hljs-number">0.5</span>) / <span class="hljs-number">0.5</span>
  x = x.reshape((<span class="hljs-number">-1</span>,))
  x = torch.from_numpy(x)

  <span class="hljs-keyword">return</span> x

train_set = MNIST(<span class="hljs-string">&apos;./data&apos;</span>, train=<span class="hljs-keyword">True</span>, transform=data_tf, download=<span class="hljs-keyword">True</span>)
test_set = MNIST(<span class="hljs-string">&apos;./data&apos;</span>, train=<span class="hljs-keyword">False</span>, transform=data_tf, download=<span class="hljs-keyword">True</span>)

criterion = nn.CrossEntropyLoss()
</code></pre>
<pre><code class="lang-python">train_data = DataLoader(train_set, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-keyword">True</span>)
<span class="hljs-comment"># &#x4F7F;&#x7528;Sequential&#x5B9A;&#x4E49;3&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</span>
net = nn.Sequential(
    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">200</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">200</span>, <span class="hljs-number">10</span>)
)
<span class="hljs-comment"># &#x5C06;&#x901F;&#x5EA6;&#x521D;&#x59CB;&#x5316;&#x4E3A;&#x548C;&#x53C2;&#x6570;&#x76F8;&#x540C;&#x7684;&#x96F6;&#x5F20;&#x91CF;</span>
vs = []
<span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> net.parameters():
  vs.append(torch.zeros_like(param.data))
<span class="hljs-comment"># &#x5F00;&#x59CB;&#x8BAD;&#x7EC3;</span>
losses = []
start = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x5F00;&#x59CB;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):
  train_loss = <span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> im, label <span class="hljs-keyword">in</span> train_data:
    im = Variable(im)
    label = Variable(label)

    <span class="hljs-comment"># forward pass</span>
    out = net(im)
    loss = criterion(out, label)

    <span class="hljs-comment"># backward pass</span>
    net.zero_grad()
    loss.backward()
    <span class="hljs-comment"># &#x4F7F;&#x7528;&#x52A8;&#x91CF;&#x53C2;&#x6570;&#x4E3A;0.9&#xFF0C;&#x5B66;&#x4E60;&#x7387;&#x4E3A;0.01</span>
    sgd_momentum(net.parameters(), vs, <span class="hljs-number">1e-2</span>, <span class="hljs-number">0.9</span>)

    <span class="hljs-comment"># &#x8BB0;&#x5F55;&#x8BEF;&#x5DEE;</span>
    train_loss += loss.item()

    losses.append(loss.item())

  print(<span class="hljs-string">&apos;epoch:{}, Train Loss:{:.6f}&apos;</span>.format(e, train_loss / len(train_data)))

end = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x7ED3;&#x675F;</span>
print(<span class="hljs-string">&apos;&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;{:.5f}s&apos;</span>.format(end - start))
</code></pre>
<pre><code>epoch:0, Train Loss:0.365374
epoch:1, Train Loss:0.172683
epoch:2, Train Loss:0.124859
epoch:3, Train Loss:0.099659
epoch:4, Train Loss:0.082579
&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;36.90882s
</code></pre><p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#xFF0C;&#x6709;&#x4E86;&#x52A8;&#x91CF;&#x4E4B;&#x540E;loss&#x4E0B;&#x964D;&#x975E;&#x5E38;&#x5FEB;&#xFF0C;&#x4F46;&#x4E00;&#x5B9A;&#x8981;&#x5C0F;&#x5FC3;&#x5B66;&#x4E60;&#x7387;&#x548C;&#x52A8;&#x91CF;&#x53C2;&#x6570;&#xFF0C;&#x8FD9;&#x4E24;&#x4E2A;&#x503C;&#x4F1A;&#x76F4;&#x63A5;&#x5F71;&#x54CD;&#x5230;&#x53C2;&#x6570;&#x6BCF;&#x6B21;&#x66F4;&#x65B0;&#x7684;&#x5E45;&#x5EA6;&#x3002;</p>
<p>&#x5F53;&#x7136;&#xFF0C;pytorch&#x5185;&#x7F6E;&#x4E86;&#x52A8;&#x91CF;&#x6CD5;&#x7684;&#x5B9E;&#x73B0;&#xFF0C;&#x975E;&#x5E38;&#x7B80;&#x5355;&#xFF0C;&#x76F4;&#x63A5;&#x8BBE;&#x7F6E;torch.optim.SGD(momentum=0.9)&#x5373;&#x53EF;&#xFF0C;&#x4E0B;&#x9762;&#x5B9E;&#x73B0;&#x4E00;&#x4E0B;&#xFF1A;</p>
<pre><code class="lang-python">train_data = DataLoader(train_set, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-keyword">True</span>)
<span class="hljs-comment"># &#x4F7F;&#x7528;Sequential&#x5B9A;&#x4E49;3&#x5C42;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;</span>
net = nn.Sequential(
    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">200</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">200</span>, <span class="hljs-number">10</span>)
)

optimizer = torch.optim.SGD(net.parameters(), <span class="hljs-number">1e-2</span>, momentum=<span class="hljs-number">0.9</span>)

<span class="hljs-comment"># &#x5F00;&#x59CB;&#x8BAD;&#x7EC3;</span>
losses = []
idx = <span class="hljs-number">0</span>
start = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x5F00;&#x59CB;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):
  train_loss = <span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> im, label <span class="hljs-keyword">in</span> train_data:
    im = Variable(im)
    label = Variable(label)

    <span class="hljs-comment"># forward pass</span>
    out = net(im)
    loss = criterion(out, label)

    <span class="hljs-comment"># backward pass</span>
    net.zero_grad()
    loss.backward()
    optimizer.step()

    <span class="hljs-comment"># &#x8BB0;&#x5F55;&#x8BEF;&#x5DEE;</span>
    train_loss += loss.item()
    <span class="hljs-keyword">if</span> idx % <span class="hljs-number">30</span> == <span class="hljs-number">0</span>:
      losses.append(loss.item())

    idx += <span class="hljs-number">1</span>

  print(<span class="hljs-string">&apos;epoch:{}, Train Loss:{:.6f}&apos;</span>.format(e, train_loss / len(train_data)))

end = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x7ED3;&#x675F;</span>
print(<span class="hljs-string">&apos;&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;{:.5f}s&apos;</span>.format(end - start))
</code></pre>
<pre><code>epoch:0, Train Loss:0.365096
epoch:1, Train Loss:0.172153
epoch:2, Train Loss:0.125373
epoch:3, Train Loss:0.098389
epoch:4, Train Loss:0.083676
&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;33.90899s
</code></pre><pre><code class="lang-python">x_axis = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, len(losses), endpoint=<span class="hljs-keyword">True</span>)
plt.semilogy(x_axis, losses, label=<span class="hljs-string">&apos;momentum=0.9&apos;</span>)
plt.legend(loc=<span class="hljs-string">&apos;best&apos;</span>)
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fe813569e10&gt;
</code></pre><p><img src="output_209_1.png" alt="png"></p>
<p>&#x53EF;&#x4EE5;&#x5BF9;&#x6BD4;&#x4E00;&#x4E0B;&#x4E0D;&#x52A0;&#x52A8;&#x91CF;&#x7684;&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;</p>
<pre><code class="lang-python">net = nn.Sequential(
    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">200</span>),
    nn.ReLU(),
    nn.Linear(<span class="hljs-number">200</span>, <span class="hljs-number">10</span>)
)

optimizer = torch.optim.SGD(net.parameters(), <span class="hljs-number">1e-2</span>) <span class="hljs-comment"># &#x4E0D;&#x52A0;&#x52A8;&#x91CF;</span>
<span class="hljs-comment"># &#x5F00;&#x59CB;&#x8BAD;&#x7EC3;</span>
losses1 = []
idx = <span class="hljs-number">0</span>
start = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x5F00;&#x59CB;</span>
<span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):
  train_loss = <span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> im, label <span class="hljs-keyword">in</span> train_data:
    im = Variable(im)
    label = Variable(label)

    <span class="hljs-comment"># forward pass</span>
    out = net(im)
    loss = criterion(out, label)

    <span class="hljs-comment"># backward pass</span>
    net.zero_grad()
    loss.backward()
    optimizer.step()

    <span class="hljs-comment"># &#x8BB0;&#x5F55;&#x8BEF;&#x5DEE;</span>
    train_loss += loss.item()

    <span class="hljs-keyword">if</span> idx % <span class="hljs-number">30</span> == <span class="hljs-number">0</span>:
      losses1.append(loss.item())

    idx +=<span class="hljs-number">1</span> 

  print(<span class="hljs-string">&apos;epoch:{}, Train Loss:{:.6f}&apos;</span>.format(e, train_loss / len(train_data)))

end = time.time() <span class="hljs-comment"># &#x8BA1;&#x65F6;&#x7ED3;&#x675F;</span>
print(<span class="hljs-string">&apos;&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;{:.5f}s&apos;</span>.format(end - start))
</code></pre>
<pre><code>epoch:0, Train Loss:0.755641
epoch:1, Train Loss:0.367042
epoch:2, Train Loss:0.322289
epoch:3, Train Loss:0.295568
epoch:4, Train Loss:0.273279
&#x4F7F;&#x7528;&#x65F6;&#x95F4;&#x662F;&#xFF1A;32.97103s
</code></pre><pre><code class="lang-python">x_axis = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, len(losses), endpoint=<span class="hljs-keyword">True</span>)
plt.semilogy(x_axis, losses, label=<span class="hljs-string">&apos;momentum=0.9&apos;</span>)
plt.semilogy(x_axis, losses1, label=<span class="hljs-string">&apos;no momentum&apos;</span>)
plt.legend(loc=<span class="hljs-string">&apos;best&apos;</span>)
</code></pre>
<pre><code>&lt;matplotlib.legend.Legend at 0x7fe80a387f28&gt;
</code></pre><p><img src="output_212_1.png" alt="png"></p>
<p>&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x52A0;&#x4E86;&#x52A8;&#x91CF;&#x4E4B;&#x540E;&#x7684;loss&#x4E0B;&#x964D;&#x7A0B;&#x5EA6;&#x66F4;&#x4F4E;&#x4E86;&#xFF0C;&#x53EF;&#x4EE5;&#x5C06;&#x52A8;&#x91CF;&#x7406;&#x89E3;&#x4E3A;&#x4E00;&#x79CD;&#x60EF;&#x6027;&#x4F5C;&#x7528;&#xFF0C;&#x6240;&#x4EE5;&#x6BCF;&#x6B21;&#x66F4;&#x65B0;&#x7684;&#x5E45;&#x5EA6;&#x90FD;&#x4F1A;&#x6BD4;&#x4E0D;&#x52A0;&#x52A8;&#x91CF;&#x7684;&#x60C5;&#x51B5;&#x66F4;&#x597D;&#x3002;</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="pytorch_first_second_and_third_class_notes.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page: 第一章 深度学习">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"第二章 神经网络","level":"1.3","depth":1,"previous":{"title":"第一章 深度学习","level":"1.2","depth":1,"path":"pytorch_first_second_and_third_class_notes.md","ref":"pytorch_first_second_and_third_class_notes.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["katex"],"pluginsConfig":{"katex":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"PyTorch_fourth_class_note.md","mtime":"2020-05-06T08:37:55.437Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-05-06T11:50:58.171Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

